---
tags: ["Research", "Training", "Generative AI"]
date: 2025-10-09
author: "Dario Ferrero"
youtube_url: "https://youtu.be/ptma9gAcr3U?si=0RFpk-wKztL6rwwB"
---

# Weniger ist Mehr: Die Revolution geht weiter mit dem TRM-Modell
![piccoli-vs-grandi.jpg](piccoli-vs-grandi.jpg)


*In der Welt der künstlichen Intelligenz, wo die goldene Regel "größer ist besser" zu sein schien, entsteht eine Gegenerzählung, die an das Finale von *Attack on Titan* erinnert: Manchmal sind es die kleineren Titanen, die die wahre Macht verbergen. Samsung AI hat über sein SAIL-Labor in Montreal gerade ein [wissenschaftliches Paper](https://arxiv.org/html/2510.04871v1) veröffentlicht, das einen Wendepunkt in unserer Denkweise über maschinelle Intelligenz markieren könnte.*

Es heißt Tiny Recursive Model, kurz TRM, und mit seinen mickrigen 7 Millionen Parametern tut es das, was unmöglich schien: Giganten mit Hunderten von Milliarden von Parametern bei komplexen Denkaufgaben systematisch zu schlagen.

Um diese Zahlen ins rechte Licht zu rücken: Wir sprechen von einem Modell, das zehntausendmal kleiner ist als GPT-4o oder Gemini 2.5 Pro und es schafft, bei Benchmarks, die als die schwierigsten für künstliche Intelligenz gelten, überlegene Leistungen zu erzielen. Beim berühmten ARC-AGI-Test, den François Chollet entwickelt hat, um echte intelligente Verallgemeinerung statt bloßer Auswendiglernen zu messen, erreicht TRM eine Genauigkeit von 45 % in der ersten Version und 8 % in der zweiten – Zahlen, die Modelle wie DeepSeek-R1, o3-mini von OpenAI und sogar Gemini 2.5 Pro übertreffen. Und das bei einem infinitesimalen Bruchteil des Rechenaufwands.

Aber die Geschichte von TRM beginnt nicht hier. Um wirklich zu verstehen, was diesen Ansatz revolutionär macht, müssen wir einen Schritt zurückgehen und einen Trend betrachten, den wir in den letzten Monaten auf AITalk.it genau verfolgt haben: das Aufkommen einer völlig anderen Philosophie im Design künstlicher Intelligenz, die Klugheit über rohe Gewalt stellt.

## Die rebellische DNA: Von HRM zu TRM

Wie [wir vor einigen Monaten berichteten](https://aitalk.it/it/articolo-hrm.html), hatte das kleine singapurische Startup Sapient Intelligence die Branche bereits mit seinem Hierarchical Reasoning Model erschüttert. HRM hatte es geschafft, riesige Modelle mit nur 27 Millionen Parametern zu schlagen, dank einer Architektur, die direkt von der hierarchischen Funktionsweise des menschlichen Gehirns inspiriert war. Die Grundidee war revolutionär: Anstatt alles in einem einzigen linearen Durchgang zu verarbeiten, wie es traditionelle Transformer tun, verwendete HRM zwei neuronale Netze, die mit unterschiedlichen Frequenzen schlussfolgerten, ein schnelles und ein langsames, und rekursiv über das Problem iterierten, bis sie zur richtigen Lösung konvergierten.

TRM, entwickelt von Alexia Jolicoeur-Martineau und dem Team von Samsung SAIL Montreal, [erkennt im Paper explizit an](https://arxiv.org/html/2510.04871v1), eine direkte Weiterentwicklung von HRM zu sein. Aber es ist eine Weiterentwicklung, die das tut, was jede gute Fortsetzung tun sollte: Sie nimmt die erfolgreichen Konzepte und treibt sie auf die Spitze, indem sie alles Überflüssige eliminiert. Wie das [Originalpaper](https://arxiv.org/html/2510.04871v1) erklärt, hatte eine unabhängige Analyse der ARC Prize Foundation ergeben, dass bei HRM der eigentliche Leistungsmotor die "tiefe Supervision" war, also die Fähigkeit, die Antwort durch mehrere Supervisionsschritte iterativ zu verbessern, während das hierarchische Denken auf zwei getrennten Netzen nur marginal beitrug.

Ausgehend von dieser Erkenntnis vereinfacht TRM die Architektur radikal. Weg mit den komplexen biologischen Rechtfertigungen, weg mit den Fixpunktsätzen, weg mit der zweistufigen Hierarchie. Übrig bleibt die reine Essenz des rekursiven Denkens: ein einziges winziges Netzwerk aus nur zwei Schichten, das über sich selbst iteriert und dabei sowohl sein "latentes Denken" als auch die endgültige Antwort schrittweise verfeinert. Es ist, als ob man anstelle eines Expertenteams, das auf verschiedenen Abstraktionsebenen arbeitet, ein einziges Genie hat, das sich intensiv auf das Problem konzentriert, sein eigenes Denken ständig überprüft und die Lösung verfeinert, bis sie perfekt ist.

Der Mechanismus ist in seiner Einfachheit elegant. TRM beginnt mit einer kodierten Frage, generiert einen ersten Lösungsentwurf und tritt dann in den von den Forschern so genannten "vollständigen rekursiven Prozess" ein. Für eine vordefinierte Anzahl von Iterationen aktualisiert das Netzwerk wiederholt seinen internen latenten Zustand, den wir uns als eine Art mentales "Notizbuch" vorstellen können, in dem das Modell Hypothesen formuliert, interne Konsistenzen überprüft und ein immer tieferes Verständnis des Problems aufbaut. Nach diesen Iterationen über das latente Denken aktualisiert das Netzwerk die endgültige Antwort auf der Grundlage dieses verfeinerten Verständnisses. Und dann beginnt es von vorne und verbessert sowohl das Denken als auch die Antwort weiter.

Was diesen Ansatz besonders leistungsfähig macht, ist, dass TRM sein Denken nicht wie Modelle, die auf der "Chain-of-Thought" basieren, durch Sprache externalisieren muss. Es muss nicht "Schritt eins, Schritt zwei, Schritt drei" in explizitem Text schreiben, mit allen Risiken von Kaskadenfehlern, die dies mit sich bringt. Sein Denken findet in einem internen, parallelen und komprimierten latenten Raum statt, in dem es gleichzeitig mehrere Hypothesen und Beziehungen aufrechterhalten kann, ohne alles in eine Sequenz von Token linearisieren zu müssen. Es ist der Unterschied zwischen dem Nachdenken über die Lösung eines Problems und dem lauten Erklären jedes einzelnen Schrittes des eigenen Denkprozesses, während man ihn durchführt.
![flow-trm.jpg](flow-trm.jpg)
[Bild aus dem offiziellen Paper](https://arxiv.org/html/2510.04871v1)

## Die Zahlen, die Gewissheiten erschüttern

Die im [Samsung-Paper](https://arxiv.org/html/2510.04871v1) berichteten Ergebnisse lassen keinen Raum für zweideutige Interpretationen. Bei extrem schwierigen Sudoku-Rätseln, die selbst erfahrene menschliche Löser in Schwierigkeiten bringen, erreicht TRM eine Genauigkeit von 87,4 % gegenüber 55 % seines Vorgängers HRM und 0 % der traditionellen LLMs mit Chain-of-Thought. Null Prozent. Nicht einmal DeepSeek-R1 mit seinen 671 Milliarden Parametern schaffte es, ein einziges schwieriges Sudoku zu lösen.

Auf dem Maze-Hard-Datensatz, der aus besonders verschlungenen 30x30-Labyrinthen besteht, bei denen der kürzeste Weg mehr als 110 Zellen beträgt, findet TRM in 85,3 % der Fälle die optimale Lösung und verbessert damit die 74,5 % von HRM. Wiederum erzielen die riesigen LLMs eine glatte Null. Es ist nicht so, dass sie knapp scheitern, sie kommen einfach nicht einmal in die Nähe einer korrekten Lösung.

Aber bei den ARC-AGI-Benchmarks wird der Vergleich wirklich gnadenlos. [ARC-AGI](https://arcprize.org/), der von François Chollet geschaffene Benchmark zur Messung echter allgemeiner Intelligenz anstelle der Fähigkeit, Muster aus Trainingsdaten zu speichern, ist so konzipiert, dass er für einen Menschen einfach, für die aktuelle KI aber teuflisch schwierig ist. Jedes Rätsel ist einzigartig und erfordert visuelle Abstraktion, kausales Denken und Verallgemeinerung auf nie zuvor gesehene Situationen. Bei ARC-AGI-1 erreicht TRM eine Genauigkeit von 44,6 % und übertrifft damit nicht nur die 40,3 % von HRM, sondern auch die 37 % von Gemini 2.5 Pro mit massivem Testzeit-Computing, die 34,5 % von o3-mini-high und die 28,6 % von Claude 3.7 Sonnet mit einem 16K-Token-Kontext.

Bei ARC-AGI-2, der noch schwierigeren Version des Benchmarks, die dieses Jahr veröffentlicht wurde, erzielt TRM 7,8 % gegenüber 5 % von HRM, 4,9 % von Gemini 2.5 Pro und 3 % von o3-mini-high. Zahlen, die absolut gesehen niedrig erscheinen, aber enorme Leistungssprünge in einem Test darstellen, bei dem selbst die fortschrittlichsten Modelle Schwierigkeiten haben, die einstellige Prozentmarke zu überschreiten.

Um fair und vollständig zu sein, müssen wir erwähnen, dass wirklich hochmoderne Modelle wie Grok-4-thinking 66,7 % bei ARC-AGI-1 und 16 % bei ARC-AGI-2 erreichen, während die auf Grok-4 basierende Bespoke-Version sogar 79,6 % und 29,4 % erreicht. Aber wir sprechen hier von einem Modell mit 1,7 Billionen Parametern, über zweihundertvierzigtausendmal größer als TRM. Das ist, als würde man einen Smart Fortwo mit einem Sattelschlepper vergleichen und feststellen, dass der Smart auf bestimmten besonders kurvigen Strecken trotzdem als Erster ankommt.

Der eigentliche Geniestreich betrifft jedoch die Trainingseffizienz. Wo große LLMs riesige Datensätze aus dem gesamten Internet und monatelange Verarbeitung auf Clustern von Tausenden von GPUs erfordern, wird TRM mit nur tausend Beispielen pro Problem trainiert. Bei Sudoku-Extreme dauert das vollständige Training weniger als 36 Stunden auf einer einzigen 40-GB-L40S-GPU. Für ARC-AGI dauert es etwa drei Tage auf vier H100s. Wir sprechen hier von Ressourcen, die für ein Universitätslabor oder ein gut finanziertes Startup zugänglich sind, nicht von Infrastrukturen, die zig Millionen Dollar kosten.
![puzzle-trm.jpg](puzzle-trm.jpg)
[Bild aus dem offiziellen Paper](https://arxiv.org/html/2510.04871v1)

## Die verteilte Intelligenz: Eine Untergrundbewegung

TRM ist kein Einzelfall, sondern Teil einer breiteren Bewegung, die am Rande der KI-Industrie entsteht. Wie wir in den letzten Monaten dokumentiert haben, gibt es bei Startups mit begrenzten Budgets und unabhängigen Forschern einen wachsenden Trend, nach Lösungen zu suchen, die architektonische Klugheit über reine Rechenleistung stellen.

Nehmen wir den Fall von DeepConf, [einer Technik, die von Jiawei Zhao](https://aitalk.it/it/AI-deepconf.html) während seines Praktikums bei Meta im Jahr 2024 entdeckt wurde. Zhao zeigte, dass man, wenn man einem LLM nicht nur eine einzige Antwort abverlangt, sondern es mehrere alternative Antworten generieren lässt, diese dann strukturiert miteinander diskutieren lässt und schließlich die Schlussfolgerungen zusammenfasst, enorme Leistungssteigerungen bei komplexen Denkaufgaben erzielt. Das zugrunde liegende Prinzip ist dem von TRM ähnlich: iterieren, reflektieren, verfeinern. Es kommt nicht nur darauf an, wie groß Ihr Modell ist, sondern wie Sie es verwenden.

Noch faszinierender ist der Fall von [MemVid](https://aitalk.it/it/memvid-ai-memory.html), einem experimentellen Projekt, das ein völlig anderes Problem mit der gleichen Grundphilosophie angeht. Anstatt immer größere und teurere Vektordatenbanken zu bauen, um das Langzeitgedächtnis von KIs zu verwalten, kodiert MemVid Informationen in QR-Codes und komprimiert sie in MP4-Videodateien. Das klingt verrückt, funktioniert aber außerordentlich gut, indem es dreißig Jahre Optimierungen von Videocodecs nutzt, um Kompressionsverhältnisse zu erreichen, die 50-100 Mal besser sind als bei herkömmlichen Datenbanken, während semantische Suchen unter einer Sekunde bleiben. Wiederum geht es nicht darum, mehr Rechenleistung auf das Problem zu werfen, sondern eine elegantere und intelligentere Lösung zu finden.

Was all diese Ansätze gemeinsam haben, ist eine grundlegend andere Vision davon, was es bedeutet, künstliche Intelligenz zu bauen. Die Mainstream-Industrie, die von Giganten wie OpenAI, Google und Anthropic dominiert wird, hat jahrelang dem "Scaling"-Paradigma gefolgt: mehr Parameter, mehr Daten, mehr Rechenleistung. Das berühmte "Scaling Law" legte nahe, dass sich die Leistung vorhersagbar verbessern würde, indem man einfach den Maßstab erhöht. Und es hat funktioniert, eine Zeit lang. Aber jetzt sehen wir immer deutlichere abnehmende Erträge, zusammen mit ökologischen und wirtschaftlichen Kosten, die unhaltbar werden.

Die Bewegung hin zur Effizienz geht hingegen von einer anderen Prämisse aus: Intelligenz ist nicht nur eine Frage der verarbeiteten Informationsmenge, sondern der Qualität der Verarbeitung. Es ist der Unterschied zwischen dem hastigen Lesen von tausend Büchern und dem aufmerksamen Lesen von zehn, bei dem man kritisch über jeden Abschnitt nachdenkt, Verbindungen herstellt und seine eigenen Schlussfolgerungen überarbeitet. TRM, DeepConf, MemVid und Dutzende anderer aufstrebender Projekte erforschen alle Variationen zu diesem Thema: Iteration, Reflexion, architektonische Optimierung.

## Die Architektur des miniaturisierten Denkens

Um wirklich zu verstehen, warum TRM so gut funktioniert, obwohl es so klein ist, müssen wir uns die technischen Details der Architektur ansehen. Wie das [Originalpaper](https://arxiv.org/html/2510.04871v1) detailliert erklärt, besteht TRM aus vier wesentlichen Elementen: einem Einbettungsmodul, das die Eingabe in Vektordarstellungen umwandelt, einem einzigen rekursiven Netzwerk aus nur zwei Transformer-Schichten, einem latenten "Notizbuch", in dem das interne Denken stattfindet, und einem Ausgabemodul, das die verfeinerten Darstellungen in die endgültige Antwort umwandelt.

Der Schlüssel ist der vollständige rekursive Prozess. Im Gegensatz zu HRM, das sich auf den Satz der impliziten Funktion mit einer Ein-Schritt-Approximation stützte, um die Rückpropagierung nur durch die letzten beiden Schritte zu rechtfertigen, propagiert TRM durch den gesamten rekursiven Prozess zurück. Dies eliminiert die problematischen theoretischen Annahmen von HRM, das nicht garantieren konnte, tatsächlich einen Fixpunkt erreicht zu haben, und liefert genauere Gradienten für das Lernen.

Der Prozess funktioniert so: Ausgehend von der eingebetteten Frage und einer anfänglichen Antwort führt TRM *n* Iterationen über seine latente Variable *z* durch, die sein "internes Denken" darstellt. In jeder Iteration nimmt das Netzwerk die Eingabefrage *x*, die aktuelle Antwort *y* und das aktuelle Denken *z* auf und erzeugt ein aktualisiertes Denken. Dies geschieht *n* Mal hintereinander, sagen wir 6 Mal, wodurch das Modell ein immer verfeinertes Verständnis aufbauen kann. Dann erzeugt das Netzwerk unter Verwendung dieses verfeinerten Denkens *z* und der aktuellen Antwort *y* eine neue, verbesserte Antwort *y*. Dies stellt einen "vollständigen rekursiven Prozess" dar.

Aber das ist noch nicht alles. Durch "tiefe Supervision" kann TRM bis zu 16 dieser vollständigen rekursiven Prozesse nacheinander ausführen, wobei es jedes Mal von der verbesserten Antwort des vorherigen Schritts ausgeht und weiter verfeinert. Es ist, als würde ein Schüler ein Problem lösen, seine Arbeit überprüfen, Korrekturen vornehmen, erneut überprüfen, weitere Korrekturen vornehmen und so weiter, bis er sich der Lösung vollkommen sicher ist. Mit *n*=6 latenten Denkiterationen und 16 Supervisionsschritten führt TRM effektiv etwa 42 Rekursionen emulierter Tiefe durch und erreicht so eine Denkfähigkeit, die normalerweise ein viel tieferes und komplexeres Netzwerk erfordern würde.

Eine der kontraintuitivsten Erkenntnisse, die im Paper berichtet werden, betrifft genau die Größe des Netzwerks. Die Forscher fanden heraus, dass eine Erhöhung der Anzahl der Schichten die Leistung aufgrund von Überanpassung an die kleinen Datensätze, die für Denkaufgaben typisch sind, verschlechtert. Durch die Reduzierung von vier auf zwei Schichten und die Kompensation mit mehr Rekursionen erzielten sie eine Verbesserung von 79,5 % auf 87,4 % bei Sudoku-Extreme und halbierten gleichzeitig die Anzahl der Parameter. Weniger ist wirklich mehr, wenn man sehr wenige Daten hat und eine echte Verallgemeinerung anstelle von Auswendiglernen anstrebt.

Ebenso interessant ist die Entscheidung, den Aufmerksamkeitsmechanismus für Aufgaben mit kleinen und festen Kontextlängen zu eliminieren. Inspiriert vom MLP-Mixer ersetzt TRM die Selbstaufmerksamkeit durch einfache mehrschichtige Perzeptrone, die auf die Sequenzdimension angewendet werden. Bei 9x9-Gittern wie im Sudoku führt dies zu einer Verbesserung von 74,7 % auf 87,4 %. Bei Aufgaben mit größeren Kontexten wie 30x30-Labyrinthen oder ARC-AGI bleibt die Selbstaufmerksamkeit jedoch überlegen, was zeigt, dass es keine universelle Lösung gibt, sondern die Architektur an das spezifische Problem angepasst werden muss.

## Die Achillesferse und die wahren Herausforderungen

Es wäre unehrlich, TRM als universelles Allheilmittel darzustellen, ohne seine erheblichen Einschränkungen zu diskutieren. Die erste und offensichtlichste betrifft den Anwendungsbereich: TRM ist speziell für strukturierte Denkprobleme mit festen Ein- und Ausgabeformen konzipiert. Es kann nicht natürlich chatten, keinen kreativen Text generieren und keine offenen Fragen wie ChatGPT beantworten. Es ist ein chirurgischer Spezialist, kein Alleskönner.

Die zweite Einschränkung betrifft die rechnerische Skalierbarkeit während des Trainings. Die Rückpropagierung durch 42 Rekursionen erfordert viel Speicher, und das [Paper](https://arxiv.org/html/2510.04871v1) dokumentiert ehrlich, wie eine zu starke Erhöhung der Anzahl der Rekursionen selbst auf 80-GB-GPUs schnell zu "Out Of Memory"-Fehlern führt. Dies setzt der Tiefe des Denkens, die TRM erreichen kann, eine praktische Grenze, zumindest mit den aktuellen Trainingstechniken.

Eine dritte Sorge betrifft die Verallgemeinerung über die Trainingsdomänen hinaus. Ja, TRM verallgemeinert hervorragend innerhalb seiner Domäne und löst nie zuvor gesehene Sudokus oder Labyrinthe mit großer Genauigkeit. Aber was passiert, wenn man ihm eine völlig andere Art von Rätsel vorlegt oder versucht, es auf eine Aufgabe anzuwenden, die nicht in die Kategorie "strukturiertes Denken" fällt? Das Paper liefert keine endgültigen Antworten auf diese Fragen, und es ist plausibel anzunehmen, dass wahrscheinlich erhebliche Neutrainings erforderlich wären.

Darüber hinaus ist TRM von Natur aus deterministisch: Bei einer gegebenen Frage erzeugt es eine einzige Antwort. In vielen realen Kontexten haben Fragen mehrere gültige Antworten oder erfordern eine kreative Erforschung des Lösungsraums. Wie die Autoren selbst in den Schlussfolgerungen des Papers anmerken, würde die Erweiterung von TRM auf generative Aufgaben erhebliche architektonische Änderungen erfordern.

Es gibt auch ein subtileres, aber wichtiges Problem: TRM erfordert immer noch ein überwachtes Training mit gekennzeichneten Beispielen für jede neue Aufgabe. Es kann kein "Few-Shot-Learning" auf die Weise durchführen, wie es große LLMs tun, bei denen man ein neues Problem mit einigen Beispielen beschreiben kann und das Modell sofort versteht, was zu tun ist. Das bedeutet, dass für jeden neuen Anwendungsbereich Daten gesammelt, geeignete Augmentationen entworfen und ein dediziertes Training durchgeführt werden müssen.

Auf praktischer Ebene gibt es auch die Frage der Infrastruktur und des Ökosystems. Große LLMs profitieren von jahrelanger Entwicklung von Werkzeugen, Bibliotheken, Best Practices und einer riesigen Entwicklergemeinschaft. TRM ist ein junges Open-Source-Projekt mit all den Herausforderungen, die dies in Bezug auf Dokumentation, Support, Debugging und Integration mit anderen Systemen mit sich bringt.

## Der wirtschaftliche Kontext: Warum jetzt?

Um zu verstehen, warum Ansätze wie TRM gerade jetzt aufkommen, müssen wir uns die wirtschaftliche Realität der KI im Jahr 2025 ansehen. Die Kosten für das Training und den Einsatz großer Sprachmodelle sind für jeden, der kein Technologieriese ist, unerschwinglich geworden. Wie wir im Artikel über [MemVid](https://aitalk.it/it/memvid-ai-memory.html) besprochen haben, kostet der Bau selbst eines kleinen KI-Rechenzentrums zwischen 10 und 50 Millionen Dollar, ganz zu schweigen von den wiederkehrenden Betriebskosten. Die Vektordatenbanken, die zur Verwaltung des Langzeitgedächtnisses dieser Systeme erforderlich sind, sind zu milliardenschweren Industrien geworden, wobei der Markt im Jahr 2024 2,2 Milliarden Dollar erreichte.

Diese Kapitalkonzentration schafft de facto eine KI-Oligarchie, in der sich nur fünf oder sechs Unternehmen weltweit leisten können, auf höchstem Niveau zu konkurrieren. OpenAI hat Milliarden gesammelt, Anthropic ebenso, und Google und Meta können auf die Gewinne ihrer Kerngeschäfte zurückgreifen. Aber für die Tausenden von Startups, Universitätslabors und unabhängigen Forschern ist der Wettlauf um die Skalierung einfach unerreichbar.

TRM und ähnliche Ansätze stellen eine Demokratisierung der fortgeschrittenen KI dar. Mit einigen zehntausend Dollar an Cloud-Ressourcen kann ein kleines Team jetzt Modelle trainieren, die die Giganten bei spezifischen Aufgaben schlagen. Dies senkt die Eintrittsbarrieren drastisch und ermöglicht die Erforschung einer viel vielfältigeren Landschaft von Architekturen und Ansätzen.

Es gibt auch eine ökologische Dimension, die nicht ignoriert werden kann. Die Rechenzentren, die die größten Modelle trainieren, verbrauchen den Strom kleiner Städte mit Kohlenstoff-Fußabdrücken, die in Tausenden von Tonnen gemessen werden. Ein Modell wie TRM, das in weniger als zwei Tagen auf einer einzigen GPU trainiert werden kann, hat eine buchstäblich zehntausendmal geringere Umweltbelastung. In einer Zeit wachsenden Bewusstseins für die Klimakrise ist dies keine marginale Überlegung.

## Die Anwendungen, die die Regeln ändern

Wo könnte es sinnvoll sein, TRM in der realen Welt einzusetzen? Die Antwort liegt in Bereichen, in denen tiefes strukturiertes Denken entscheidend ist, Daten knapp sind und Rechenressourcen begrenzt sind.

Das erste Feld, das einem in den Sinn kommt, ist die Robotik, insbesondere für Edge-Geräte, die komplexe Entscheidungen in Echtzeit treffen müssen, ohne sich auf ständige Cloud-Verbindungen verlassen zu können. Ein Industrieroboter, der optimale Bewegungsabläufe planen muss, oder eine autonome Drohne, die durch komplexe Umgebungen navigieren muss, könnten enorm von einem Modell wie TRM profitieren, das mit minimalen Rechenressourcen "tief denken" kann.

Im medizinischen Bereich erfordern Aufgaben wie die Diagnose seltener Krankheiten oder die Planung komplexer Therapiestrategien genau die Art von abstraktem Denken und Verallgemeinerung, in der TRM überragend ist. Wie [wir im Artikel über HRM erwähnten](https://aitalk.it/it/articolo-hrm.html), haben ähnliche Modelle bereits eine Genauigkeit von 97 % bei saisonalen Klimavorhersagen gezeigt, was darauf hindeutet, dass derselbe Ansatz für medizinische Vorhersagen auf der Grundlage komplexer Muster funktionieren könnte.

Die Bildung könnte faszinierende Anwendungen sehen. Stellen Sie sich personalisierte Tutorensysteme vor, die wirklich "verstehen" können, wo ein Schüler in Mathematik oder Physik stecken bleibt, nicht nur, indem sie die richtige Antwort geben, sondern indem sie das Denken durch logische Schritte führen. TRM, mit seiner Fähigkeit, über komplexe Probleme zu iterieren, und seiner relativen Transparenz im Vergleich zu den Black Boxes der riesigen LLMs, könnte für diese Art von Anwendungen ideal sein.

Im Bereich der Cybersicherheit erfordern Aufgaben wie die Analyse von bösartigem Code, die Erkennung ausgeklügelter Angriffsmuster oder die formale Überprüfung kryptografischer Protokolle ein tiefes Denken über komplexe Strukturen. Dies sind genau die Kontexte, in denen ein kleines, aber intelligentes Modell einen Giganten schlägt, der das ganze Internet gesehen hat, aber nicht wirklich denken kann.

Schließlich gibt es die ganze Welt der eingebetteten KI: IoT-Geräte, Industriesensoren, autonome Fahrzeuge, bei denen die Idee, ständig Daten zur Verarbeitung in die Cloud zu senden, aufgrund von Latenz, Kosten oder Datenschutzbeschränkungen unpraktisch ist. Wie wir bei MemVid und jetzt bei TRM gesehen haben, eröffnet effiziente KI völlig neue Szenarien für verteilte Intelligenz am Rande des Netzwerks.
![sudoku-trm.jpg](sudoku-trm.jpg)
[Bild aus dem offiziellen Paper](https://arxiv.org/html/2510.04871v1)

## Die Debatte: Spezialisten gegen Generalisten

Das Aufkommen von Ansätzen wie TRM entfacht eine grundlegende Debatte in der KI neu: Ist es besser, gigantische, generalistische Modelle zu haben, die alles anständig machen, oder ein Ökosystem von spezialisierten Modellen, die in ihren spezifischen Bereichen überragen?

Das aktuelle Paradigma begünstigt Generalisten. OpenAI, Anthropic und Google setzen alle auf immer größere und leistungsfähigere Modelle, die "alles" können: Code schreiben, Bilder analysieren, natürliche Gespräche führen, mathematische Probleme lösen und so weiter. Die Idee ist, dass mit genügend Parametern und genügend Daten eine Art allgemeine Intelligenz entsteht, die sich an jede Aufgabe anpassen kann.

Aber diese Strategie hat enorme Kosten. Jedes Mal, wenn GPT-5 oder Claude 4.5 herauskommen, benötigen sie um Größenordnungen mehr Ressourcen für das Training. Die überwiegende Mehrheit dieser Ressourcen fließt in die marginale Verbesserung der Leistung bei Aufgaben, die uns vielleicht nicht einmal interessieren. Wenn Sie GPT-4 hauptsächlich zur Analyse wissenschaftlicher Daten verwenden, bezahlen Sie trotzdem für das gesamte Training, das darauf verwendet wurde, ihm das Dichten, das Spielen von textbasierten Rollenspielen und tausend andere Dinge beizubringen.

Der Ansatz der Spezialisten, den TRM repräsentiert, schlägt stattdessen eine modulare Architektur vor: kleine, für spezifische Aufgaben optimierte Modelle, die bei Bedarf zu komplexeren Systemen kombiniert werden können. Wollen Sie einen kompletten KI-Assistenten? Verwenden Sie einen kleinen LLM für das Sprachverständnis und die Konversation, einen TRM für komplexes Denken, ein spezialisiertes Modell für die Bildverarbeitung, ein anderes für die Codegenerierung. Jede Komponente erledigt ihre Aufgabe außergewöhnlich gut, und zusammen decken sie ein breites Spektrum an Fähigkeiten ab.

Dieser modulare Ansatz hat erhebliche Vorteile, die über die reine Effizienz hinausgehen. Er ermöglicht unabhängige Komponenten-Updates, einfacheres Debugging, da Sie genau wissen, welches Modul ausfällt, und eine überlegene Transparenz, da der Informationsfluss zwischen spezialisierten Modulen nachvollziehbarer ist als das undurchschaubare Denken eines monolithischen Giganten.

Es gibt jedoch auch einen Nachteil: Generalistische Modelle zeigen emergente Fähigkeiten, die aus der Interaktion all ihrer Teile entstehen. Phänomene wie das "Transfer Learning", bei dem in einem Bereich erworbenes Wissen in völlig anderen Bereichen hilft, oder die Fähigkeit zur "Chain-of-Thought", bei der das Modell spontan lernt, Schritt für Schritt zu denken, scheinen eine gewisse Größe zu erfordern. Wenn man zu sehr fragmentiert, könnte man diese emergente Magie verlieren.

Mein Gefühl ist, dass wir eine Konvergenz zwischen den beiden Ansätzen sehen werden. Große Generalisten werden weiterhin für Anwendungen existieren, bei denen sie wirklich benötigt werden, aber die meisten realen Implementierungen werden wahrscheinlich Hybridsysteme verwenden: kleine spezialisierte Modelle für kritische Aufgaben, bei denen die Effizienz zählt, koordiniert von größeren Modellen, wenn für Aufgaben, die extreme Flexibilität erfordern, erforderlich.

## Jenseits der Benchmarks: Was noch fehlt

So beeindruckend die Ergebnisse von TRM bei den Benchmarks auch sind, es ist wichtig, eine kritische Perspektive darauf zu bewahren, was uns diese Zahlen wirklich sagen und was sie auslassen. Benchmarks wie ARC-AGI sind, so gut sie auch konzipiert sind, kontrollierte und künstliche Umgebungen. Das Denken in der realen Welt ist oft viel komplexer, mehrdeutiger und kontextabhängiger.

Eine grundlegende Einschränkung ist die mangelnde Robustheit gegenüber gegnerischen Eingaben. Veröffentlichte Benchmarks haben wohldefinierte Formate, aber in der realen Welt sind die Eingaben oft verrauscht, unvollständig oder absichtlich irreführend. Ein in der Produktion eingesetztes KI-System muss mit Benutzern umgehen, die schlecht formulierte Fragen stellen, mit Daten mit Fehlern und mit Grenzfällen, die niemand vorhergesehen hatte. Wir haben noch keine Daten darüber, wie sich TRM in diesen Szenarien verhält.

Dann gibt es die Frage des kontinuierlichen Lernens. TRM wird auf einem statischen Datensatz trainiert und dann eingefroren. Aber die reale Welt verändert sich ständig: Neue Arten von Problemen tauchen auf, die Regeln der Domänen entwickeln sich, Standards ändern sich. Große LLMs können durch Techniken wie RLHF feinabgestimmt oder aktualisiert werden, aber es ist unklar, wie leicht sich TRM ohne vollständige Neutrainings anpassen kann.

Die Erklärbarkeit der Entscheidungen ist ein weiterer Graubereich. Ja, TRM ist transparenter als die Giganten, da wir beobachten können, wie sich sein latenter Zustand durch die Rekursionen entwickelt. Aber dieser latente Zustand bleibt ein mehrdimensionaler Vektor in einem Raum, der nicht direkt interpretierbaren menschlichen Konzepten entspricht. Wenn TRM einen Fehler macht, wie leicht können wir verstehen, warum und das Problem beheben?

An der Sicherheitsfront werfen kleine und effiziente Modelle wie TRM neue Fragen auf. Wenn es möglich wird, hochleistungsfähige Modelle mit bescheidenen Ressourcen zu trainieren, senkt dies auch die Hürden für böswillige Akteure drastisch. Eine Gruppe mit schädlichen Absichten könnte einen TRM trainieren, der auf Aufgaben wie das Finden von Software-Schwachstellen, das Generieren von Exploits oder das Optimieren von Angriffsstrategien spezialisiert ist. Die Demokratisierung der KI ist wünschenswert, bringt aber Verantwortlichkeiten mit sich, denen sich die Gemeinschaft noch vollständig stellen muss.

Schließlich gibt es die Frage der Bewertung selbst. Aktuelle Benchmarks messen, so schwierig sie auch sind, hauptsächlich abstrakte Denkfähigkeiten bei wohldefinierten Problemen. Aber ein großer Teil der menschlichen Intelligenz besteht darin, Mehrdeutigkeiten zu bewältigen, mit Unsicherheit umzugehen, Wissen aus verschiedenen Bereichen zu integrieren und über offene Systeme ohne klare Grenzen nachzudenken. Wie viel dieser nuancierteren Intelligenz kann TRM erfassen? Das Paper liefert keine Antworten, und es wird wahrscheinlich Jahre der Forschung dauern, um dies herauszufinden.

## Die Forschungsfront: Was kommt als Nächstes?

Mit Blick auf die unmittelbare Zukunft gibt es mehrere vielversprechende Richtungen, die die Forschung an rekursiven Architekturen wie TRM einschlagen könnte. Die erste und offensichtlichste betrifft die Erweiterung auf generative Aufgaben. Wie im [Samsung-Paper](https://arxiv.org/html/2510.04871v1) erwähnt, erzeugt TRM derzeit deterministische Ausgaben, aber viele reale Probleme erfordern die Erforschung des Lösungsraums, die Generierung mehrerer Alternativen und die probabilistische Bewertung von Optionen. Die Integration von Abtastmechanismen und Unsicherheitsbewertung in TRM könnte völlig neue Anwendungen eröffnen.

Eine zweite Grenze betrifft das Transferlernen zwischen Domänen. Derzeit wird TRM für jede Aufgabe separat trainiert, aber es gibt Hinweise im Paper, die interessante Möglichkeiten andeuten. Die Tatsache, dass dieselbe Architektur bei Sudoku, Labyrinthen und ARC-AGI-Rätseln, die oberflächlich sehr unterschiedlich sind, außergewöhnlich gut funktioniert, deutet darauf hin, dass TRM etwas Grundlegenderes über abstraktes Denken lernt. Man könnte sich ein Vortraining auf einem breiten Spektrum von Denkaufgaben vorstellen, gefolgt von einem schnellen Feinabstimmen auf spezifische Domänen.

Die dritte Richtung betrifft die Integration mit symbolischen Systemen. TRM operiert vollständig im subsymbolischen Bereich neuronaler Netze, aber viele komplexe Denkprobleme in der realen Welt würden von der Integration mit logischen Inferenzmaschinen, Constraint-Solvern oder symbolischen Planern profitieren. Hybridsysteme, die die Fähigkeit von TRM, Muster aus Daten zu lernen, mit der Präzision und Überprüfbarkeit des symbolischen Denkens kombinieren, könnten extrem leistungsfähig sein.

An der Effizienzfront gibt es noch Verbesserungspotenzial. Das Paper erwähnt, dass eine Erhöhung der Anzahl der Rekursionen schnell zu Speicherproblemen führt, aber Techniken wie Gradient Checkpointing, Quantisierung oder speichereffizientere Architekturen könnten noch tiefere Rekursionen auf derselben Hardware ermöglichen. Ebenso könnten Optimierungen auf Kompilierungsebene und spezialisierte Hardware für rekursive Operationen das Training und die Inferenz weiter beschleunigen.

Eine besonders faszinierende Richtung betrifft das Meta-Lernen: TRM trainieren, zu lernen, wie man lernt. Anstatt manuell für jede neue Aufgabe zu trainieren, könnten wir uns ein System vorstellen, das bei einigen hundert Beispielen eines völlig neuen Problems automatisch die optimale Architektur, die erforderliche Anzahl von Rekursionen und die geeigneten Augmentationsstrategien bestimmt. Dies würde wahrscheinlich eine höhere Abstraktionsebene erfordern, vielleicht ein "Meta-TRM", das darüber nachdenkt, wie TRM für spezifische Aufgaben konfiguriert werden kann.

## Die Lektion aus *One Punch Man*: Wenn grundlegendes Training reines Talent schlägt

Es gibt eine Metapher aus der Popkultur, die mir beim Nachdenken über TRM in den Sinn kommt. In *One Punch Man* erlangt der Protagonist Saitama buchstäblich unbesiegbare Stärke nicht durch besondere Kräfte oder fortschrittliche Technologien, sondern durch ein absurd einfaches und sich wiederholendes Trainingsprogramm: hundert Liegestütze, hundert Sit-ups, hundert Kniebeugen und zehn Kilometer Laufen, jeden einzelnen Tag. Die anderen Helden mit ihren exotischen und komplexen Kräften sehen ihn verblüfft an, aber Saitama übertrifft sie alle genau durch diese methodische und obsessive Wiederholung.

TRM ist ein bisschen so. Wo die KI-Giganten Milliarden von Parametern und immer ausgefeiltere Architekturen anhäufen, nimmt TRM ein winziges zweischichtiges Netzwerk und lässt es immer und immer wieder über sich selbst rekursieren, mit fast zenartiger Geduld. Keine komplizierten Theoreme, keine ausgearbeiteten biologischen Rechtfertigungen, nur disziplinierte Rekursion und tiefe Supervision. Und es funktioniert besser.

Diese Lektion hat Auswirkungen, die über die spezifische Architektur von TRM hinausgehen. Sie legt nahe, dass wir im Bereich der KI, wie in vielen anderen auch, möglicherweise einen Punkt abnehmender Erträge aus der bloßen Anhäufung von Komplexität erreicht haben. Architektonische Eleganz, ein tiefes Verständnis der Lernmechanismen und eine intelligente Optimierung könnten weitere Gewinne bringen als nur "alles größer zu machen".

## Auf dem Weg zu einer Ökologie der künstlichen Intelligenz

Eine der interessantesten Perspektiven, die durch TRM und ähnliche Ansätze eröffnet werden, ist die Idee einer Ökologie der künstlichen Intelligenz anstelle einer von wenigen Giganten dominierten Monokultur. In der Natur sind die robustesten und anpassungsfähigsten Ökosysteme nicht die, die von einem einzigen Super-Prädator dominiert werden, sondern die, die durch Vielfalt gekennzeichnet sind: unzählige Arten, jede für ihre eigene Nische optimiert, die in komplexen Netzwerken von Symbiose und Wettbewerb interagieren.

Wir könnten uns eine ähnliche Zukunft für die KI vorstellen. Anstatt einer Industrie, in der fünf Unternehmen fünf riesige Modelle kontrollieren, die versuchen, alles zu tun, könnten wir Tausende von spezialisierten Modellen haben, von denen jedes in seinem eigenen Bereich hervorragend ist. TRM für abstraktes Denken, MemVid für effizientes Speichermanagement, spezialisierte Modelle für Bildverarbeitung, für natürliche Sprache, für Planung, für kontinuierliches Lernen. Diese Modelle könnten von einer globalen Gemeinschaft von Forschern entwickelt werden, offen, überprüfbar und zusammensetzbar.

Dieses Paradigma hätte enorme Vorteile. Erstens würde es die Machtkonzentration verringern, die wir in der KI sehen, wo einige wenige Konzerne de facto den Zugang zu fortgeschrittener künstlicher Intelligenz kontrollieren. Zweitens würde es eine viel schnellere Innovation ermöglichen, da kleine Teams Verbesserungen an spezifischen Komponenten beitragen könnten, ohne im Training gigantischer Modelle konkurrieren zu müssen. Drittens würde es die allgemeine Robustheit des Systems verbessern, da der Ausfall einer Komponente nicht den gesamten Stack gefährden würde.

Natürlich würde dies Koordinationsinfrastrukturen, Interoperabilitätsstandards und Governance-Mechanismen erfordern, die derzeit nicht existieren. Aber Open-Source-Projekte wie [TRM auf GitHub](https://github.com/SamsungSAILMontreal/TinyRecursiveModels) legen den Grundstein für diese Vision und zeigen, dass es möglich ist, fortgeschrittene KI offen zu entwickeln und zu teilen.

## Der Weg nach vorne: Vorhersagen und Hoffnungen

Mit Blick auf die nächsten Jahre ist es vernünftig zu erwarten, dass wir eine Explosion von Variationen und Verbesserungen zum Thema rekursives Denken sehen werden. TRM hat gezeigt, dass der Ansatz gangbar und leistungsfähig ist, aber wie jede bedeutende Innovation wirft er mehr Fragen auf, als er beantwortet. Andere Labore erforschen bereits Variationen: rekursive Modelle mit unterschiedlichen Aufmerksamkeitsmechanismen, Architekturen, die dynamisch lernen, wie viele Rekursionen für jedes Problem zu verwenden sind, Systeme, die Rekursion mit dem Abruf externer Informationen kombinieren.

Auf industrieller Seite erwarte ich eine relativ schnelle Einführung in spezifischen Bereichen, in denen die Vorteile von TRM überwältigend sind. Robotik, autonome Fahrzeuge, eingebettete Systeme und Edge-Anwendungen, bei denen die Effizienz entscheidend ist, sind offensichtliche Kandidaten. Wir könnten auch Startups sehen, die "TRM-as-a-Service" für spezifische Denkaufgaben anbieten und mit den Giganten genau bei der Fähigkeit konkurrieren, mehr mit weniger zu erreichen.

In der akademischen Welt bietet TRM einen neuen Rahmen zur Erforschung grundlegender Fragen zum Lernen und zur Verallgemeinerung. Warum funktioniert Rekursion so gut? Was lernt TRM tatsächlich im latenten Raum während seiner Iterationen? Wie können wir die Klasse von Problemen, für die dieser Ansatz optimal ist, formal charakterisieren? Dies sind Forschungsthemen, die Doktoranden und Postdocs jahrelang beschäftigen werden.

Es gibt auch eine geopolitische Dimension zu berücksichtigen. Die Konzentration fortgeschrittener KI in einigen wenigen amerikanischen und chinesischen Unternehmen hat [in Europa](https://aitalk.it/it/apply-ai-eu-strategy.html) und anderen Regionen Bedenken hervorgerufen. Ansätze wie TRM, die die Eintrittsbarrieren drastisch senken, könnten es Ländern mit weniger Rechenressourcen ermöglichen, dennoch fortgeschrittene KI-Fähigkeiten zu entwickeln. Dies könnte die globale KI-Landschaft teilweise neu ausbalancieren, mit Auswirkungen auf den wirtschaftlichen Wettbewerb, die nationale Sicherheit und die internationale Governance der Technologie.

## Abschließende Gedanken: Intelligenz als Prozess, nicht als Produkt

TRM erinnert uns an eine grundlegende Wahrheit, die die KI-Industrie in ihrem Wettlauf um die Skalierung vielleicht vergessen hatte: Intelligenz ist keine Frage der Größe, sondern des Prozesses. Es spielt keine Rolle, wie groß Ihr Modell ist oder wie viele Parameter es enthält. Was zählt, ist, wie es Informationen verarbeitet, wie es über sein eigenes Denken iteriert, wie es seine eigenen Schlussfolgerungen schrittweise verfeinert.

Diese Einsicht findet Anklang bei unserer menschlichen Erfahrung. Die intelligentesten Menschen, die wir kennen, sind nicht unbedingt diejenigen mit den größten Gehirnen oder den meisten Neuronen. Es sind diejenigen, die methodisch denken, die Probleme aus mehreren Blickwinkeln betrachten, die ihre eigenen Schlussfolgerungen überprüfen, die aus ihren eigenen Fehlern lernen. Mit anderen Worten, es sind diejenigen, die effektiv über ihren eigenen Denkprozess iterieren.

Wenn es eine Lehre gibt, die wir aus dem Aufkommen von TRM, DeepConf, MemVid und dem breiteren Trend zur Effizienz in der KI ziehen können, dann ist es, dass die Zukunft nicht unbedingt den Größten gehören wird, sondern den Klügsten. Die Industrie erwacht langsam zu der Erkenntnis, dass das Werfen von mehr Ressourcen auf Probleme abnehmende Erträge hat und dass intelligente architektonische Innovation qualitative Sprünge hervorbringen kann, die bloßes Skalieren niemals erreichen wird.

Wie der kleine Saitama aus *One Punch Man*, der kosmische Monster mit seinem grundlegenden Training besiegt, oder wie der winzige Luke Skywalker, der lernt, dass die Macht nichts mit der Größe zu tun hat, zeigt uns TRM, dass in der KI immer noch das alte Sprichwort gilt: Es kommt nicht darauf an, wie groß du bist, sondern wie du das nutzt, was du hast.

Und in einer Welt, in der Rechen- und Umweltressourcen immer stärker unter Druck geraten, in der die Konzentration technologischer Macht legitime demokratische Bedenken aufwirft und in der der Zugang zu fortgeschrittener künstlicher Intelligenz über den Erfolg oder Misserfolg ganzer Volkswirtschaften entscheiden könnte, könnte diese Lektion nicht zu einem günstigeren Zeitpunkt kommen.

Das Paper von Samsung SAIL Montreal ist nicht nur eine technische Innovation. Es ist ein Manifest für eine andere Art, über künstliche Intelligenz nachzudenken, eine, die Eleganz über rohe Gewalt, Zugänglichkeit über Konzentration, Nachhaltigkeit über wahlloses Wachstum stellt. Wenn sich dieser Ansatz durchsetzt, und alle Anzeichen deuten darauf hin, könnten wir auf TRM als den Wendepunkt zurückblicken, an dem die KI-Industrie endlich gelernt hat, dass kleiner tatsächlich intelligenter sein kann.