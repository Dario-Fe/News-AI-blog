---
tags: ["Generative AI", "Applications", "Business"]
date: 2025-11-12
author: "Dario Ferrero"
---

# Kimi K2 Thinking: China toma la delantera
![kimi-k2-thinking.jpg](kimi-k2-thinking.jpg)

*Moonshot AI reescribe las reglas de la inteligencia artificial con Kimi K2 Thinking: un modelo de código abierto de un billón de parámetros que desafía a GPT-5 y Claude, y que costó menos de 5 millones de dólares. El 6 de noviembre de 2025, mientras la comunidad de desarrolladores de IA revisaba distraídamente las notificaciones en Hugging Face, apareció un lanzamiento que podría haber parecido el enésimo modelo lingüístico chino. Kimi K2 Thinking, creado por la startup Moonshot AI, respaldada por Alibaba, prometía las maravillas de siempre: capacidades agénticas avanzadas, arquitectura Mixture-of-Experts, un billón de parámetros en total.*

*Pero cuando los primeros benchmarks comenzaron a circular, algo inesperado surgió de los números: 44,9% en el [Humanity's Last Exam](https://agi.safe.ai/), superando tanto a GPT-5 como a Claude Sonnet 4.5. No por poco, no por un error estadístico, sino con márgenes que obligaron incluso a los más escépticos a recalcular.*

*Para quienes no manejan a diario el alfabeto de los acrónimos de la IA, el Humanity's Last Exam es lo que ocurre cuando los expertos deciden detener la marcha triunfal de los modelos lingüísticos: [tres mil preguntas obtenidas por crowdsourcing de más de mil especialistas](https://scale.com/leaderboard/humanitys_last_exam), diseñadas para ser demasiado difíciles incluso para los sistemas más avanzados. Matemáticas avanzadas, biología molecular, filosofía analítica, física cuántica. El tipo de examen en el que GPT-4o balbucea con un 9% e incluso los modelos de razonamiento más recientes tienen dificultades para superar el 30%. Kimi K2 Thinking superó ese umbral con una naturalidad que recuerda a las películas de atracos, cuando el golpe imposible se convierte en rutina: sin espectáculo, solo precisión metódica.*

*Pero esta no es la historia de un único modelo excepcional. Es la crónica de un momento en el que lo imposible se convierte en la nueva normalidad, y las reglas económicas y geopolíticas de la IA son reescritas por quienes, en teoría, debían quedarse atrás.*

## Dentro de la Máquina

Para entender lo que hace diferente a K2 Thinking, hay que adentrarse en la arquitectura, donde las decisiones de ingeniería se convierten en declaraciones de intenciones. El modelo está construido sobre una arquitectura [Mixture-of-Experts con un billón de parámetros en total](https://arxiv.org/abs/2507.20534), pero solo activa 32.000 millones por cada token procesado. Es una estrategia que recuerda a las centrales eléctricas modulares: toda esa potencia existe, pero solo se recurre a ella cuando es necesaria, lo que reduce drásticamente los costes operativos sin sacrificar las capacidades.

La verdadera innovación, sin embargo, está en la cuantización INT4 nativa. Mientras que la mayoría de los modelos se entrenan con mayor precisión y luego se comprimen, K2 Thinking fue diseñado desde el principio para operar en INT4, reduciendo a la mitad los requisitos de memoria y duplicando la velocidad de inferencia sin las típicas pérdidas de precisión que afectan a la compresión post-hoc. Es el tipo de elección que prioriza la eficiencia operativa sobre la métrica de vanidad de los parámetros totales, una filosofía que se volverá central cuando hablemos de costes.

La arquitectura MoE de K2 distribuye la carga entre 384 expertos especializados, frente a los 256 de DeepSeek V3, lo que permite una mayor granularidad en la selección de competencias. Cada solicitud activa un subconjunto dinámico de estos expertos, y el sistema elige de forma autónoma qué neuronas poner en juego en función del tipo de problema. En la práctica, cuando K2 tiene que escribir código Python, activa un conjunto de expertos diferente a cuando tiene que resolver ecuaciones diferenciales o traducir sánscrito.

Pero el elemento que distingue a K2 Thinking de sus predecesores es el "test-time scaling", una técnica que permite al modelo "pensar más tiempo" en problemas complejos. No es un simple ensayo y error: el sistema puede asignar más ciclos computacionales a las preguntas difíciles, explorando cadenas de razonamiento alternativas antes de converger en una respuesta. Es lo que los investigadores llaman "modo de pensamiento", y es la razón por la que K2 puede abordar problemas de varios pasos que normalmente requerirían supervisión humana.

En el frente de la agencia, K2 demuestra capacidades que hasta hace unos meses eran prerrogativa de sistemas cerrados y costosos: puede ejecutar [entre 200 y 300 llamadas secuenciales a herramientas](https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model) sin intervención humana, navegando por API externas, procesando datos estructurados y orquestando flujos de trabajo complejos. La ventana de contexto de 256k tokens permite mantener la coherencia en conversaciones extensas o documentos técnicos extensos, mientras que el sistema de memoria caché reduce la latencia en las interacciones repetidas.
![grafico1.jpg](grafico1.jpg)
[Imagen extraída del artículo oficial en arxiv.org](https://arxiv.org/pdf/2507.20534)

## Los Números Hablan

Los benchmarks son el campo de batalla donde las promesas se miden con la realidad. En el [Humanity's Last Exam](https://scale.com/leaderboard/humanitys_last_exam), K2 Thinking alcanza un 44,9%, superando a GPT-5 (42,1%) y a Claude Sonnet 4.5 (41,7%). Pero la verdadera diferencia surge cuando se observan las tareas de agencia: en [BrowseComp](https://arxiv.org/abs/2507.20534), que mide la capacidad de navegar por la web y las API de forma autónoma, K2 obtiene un 34,2% frente al 28,5% de GPT-5. En SWE-Bench Verified, el benchmark de ingeniería de software que requiere resolver errores reales en bases de código de código abierto, K2 alcanza un 65,8%, superando prácticamente a todos los modelos no pensantes disponibles.

No todo brilla por igual. En GPQA Diamond, el conjunto de datos de preguntas científicas de nivel de posgrado, K2 se queda en un 75,1%, un resultado excelente pero no récord. Y cuando GPT-5 se ejecuta en "modo pesado" con razonamiento extendido, todavía logra superar a K2 en algunas tareas específicas de matemáticas puras. Pero lo que importa, en la narrativa más amplia, es que estas diferencias son marginales y desaparecen por completo cuando se considera la relación coste-rendimiento.

Porque aquí surge el dato que ha hecho temblar a Silicon Valley: K2 Thinking cuesta 0,33 dólares por millón de tokens de entrada y 1,33 dólares de salida. El GPT-5 estándar se sitúa en 1,25/10 dólares, mientras que el GPT-5 en modo de razonamiento puede llegar a los 50 dólares por millón de tokens de salida. No estamos hablando de diferencias del 20-30%, sino de un orden de magnitud. Para una empresa que procesa decenas de millones de tokens al día, las matemáticas se vuelven brutalmente sencillas.

Y hay un detalle técnico que vale la pena destacar: todos estos benchmarks de K2 se han ejecutado en INT4, sin trucos de precisión inflada para ganar puntos porcentuales. Algunos laboratorios publican cifras impresionantes en FP16 y luego, cuando el modelo se despliega realmente en producción cuantizado, el rendimiento se desploma. K2 ha sido probado en las mismas condiciones en las que se utilizaría en producción, una transparencia que debería ser estándar pero que rara vez lo es.

En [LiveCodeBench v6](https://arxiv.org/abs/2507.20534), que prueba la capacidad de escribir código para problemas nuevos nunca vistos durante el entrenamiento, K2 alcanza un 53,7%. En AIME 2025, el examen de matemáticas avanzadas para estudiantes estadounidenses, obtiene un 49,5%. En OJBench, un benchmark chino de programación competitiva, llega al 27,1%. Cifras que individualmente pueden parecer tecnicismos, pero que en conjunto dibujan el perfil de un sistema que ha superado el umbral de la utilidad práctica en una gama muy amplia de aplicaciones reales.
![grafico2.jpg](grafico2.jpg)
[Imagen extraída del artículo oficial en arxiv.org](https://arxiv.org/pdf/2507.20534)

## La Voz Crítica

Nathan Lambert no es del tipo que se deja impresionar fácilmente. Investigador de IA en el Allen Institute for AI y autor de la [newsletter Interconnects](https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means), Lambert ha dedicado años a analizar la brecha entre el bombo y la realidad en el sector. Cuando escribió su análisis sobre K2 Thinking, planteó una pregunta que corta como un bisturí: "¿Qué significa cuando un momento DeepSeek se convierte en rutina?"

Cuando DeepSeek V3 se lanzó a finales de 2024 con un coste de entrenamiento de 5,6 millones de dólares, la industria se estremeció colectivamente. Era la anomalía que confirmaba la regla: sí, es posible construir modelos competitivos con presupuestos ridículos, pero sigue siendo una excepción. Ahora, diez meses después, tenemos a Moonshot con K2, a Qwen que no para de lanzar versiones y a una docena de otros laboratorios chinos que publican modelos de código abierto cada dos semanas. Los servidores de Kimi ya están saturados, señal de que no estamos hablando de demos tecnológicas, sino de sistemas que los desarrolladores están desplegando realmente en producción.

Lambert identifica cinco dinámicas críticas, y la primera es la más sencilla pero devastadora: los laboratorios chinos lanzan más rápido. Mucho más rápido. Mientras que a Anthropic le puede llevar meses llevar un modelo del laboratorio a la producción, y OpenAI se sitúa en algún punto intermedio, los laboratorios chinos exprimen ese ciclo en semanas. Cuando el ritmo del progreso es alto, ser más rápido te hace parecer mejor. Lambert estima la brecha de rendimiento bruto entre los modelos cerrados y los abiertos en unos cuatro o seis meses, pero luego plantea la pregunta retórica: si estos modelos cerrados no están disponibles públicamente, ¿realmente cuentan?

El segundo punto toca algo más sutil: los laboratorios chinos están dominando en los benchmarks clave, pero existen "comportamientos de cola larga" para los que no tienen bucles de retroalimentación. Lambert señala que Qwen, en el último año, ha pasado de ser conocido por el "benchmaxing" (optimizar obsesivamente los benchmarks) a producir modelos genuinamente fantásticos que, casualmente, también tienen puntuaciones increíbles. DeepSeek y Kimi tienen lo que Lambert llama "buen gusto", una cualidad difícil de cuantificar pero inmediata de percibir cuando se usan los modelos. Pero siguen existiendo comportamientos de usuario comunes, especialmente los occidentales, sobre los que las empresas estadounidenses tienen años de datos internos y los laboratorios chinos no. Estos intangibles cuentan para la retención de usuarios, aunque no aparezcan en el Humanity's Last Exam.

Es aquí donde Lambert reconoce un detalle técnico a menudo pasado por alto: K2 Thinking fue entrenado de forma nativa en INT4 durante el post-entrenamiento, probablemente para hacer más eficiente el escalado del aprendizaje por refuerzo en secuencias largas. Y todos los benchmarks reportados están en INT4, no en precisión inflada. Es la forma honesta de hacer comparaciones, señala Lambert, porque así es como se servirá realmente el modelo.

El tercer punto es geopolítico e inexorable: a principios de 2025, la mayoría de la gente que seguía la IA no conocía ningún laboratorio chino. Ahora, hacia finales de año, DeepSeek, Qwen y Kimi se están convirtiendo en nombres comunes. Todos tienen temporadas de mejores lanzamientos y diferentes puntos fuertes. Y la lista seguirá creciendo: Lambert cita a Z.ai, Meituan y Ant Ling como posibles incorporaciones para 2026. Algunos de estos laboratorios iniciaron sus esfuerzos en modelos fundacionales después de DeepSeek, y en seis meses han alcanzado el nivel de la frontera abierta. La pregunta ahora es si pueden ofrecer algo en un nicho de la frontera que tenga una demanda real por parte de los usuarios.

El cuarto aspecto se refiere a las capacidades agénticas intercaladas: K2 Thinking puede ejecutar cientos de llamadas secuenciales a herramientas, una característica que se ha convertido en estándar en modelos cerrados como o3 y Grok 4. Técnicamente no es revolucionario, surge de forma natural durante el entrenamiento de RL, especialmente cuando el modelo tiene que buscar información para responder correctamente. Pero es la primera vez que esta capacidad aparece en un modelo abierto con esta robustez, y los proveedores que alojan pesos abiertos tendrán que trabajar duro para soportarla con precisión. Lambert espera que exista suficiente demanda de los usuarios para que la industria madure en el servicio de modelos abiertos que utilizan herramientas.

El quinto punto es el más preocupante para los laboratorios estadounidenses: la presión es real. Hay presión sobre los precios y expectativas que deben gestionar. La diferenciación y la narrativa sobre por qué sus servicios cerrados son mejores deben evolucionar rápidamente, alejándose de los benchmarks que ahora también domina el código abierto. Lambert ya lo había anticipado en su publicación de verano "Algunas reflexiones sobre lo que viene después", sugiriendo que los futuros lanzamientos se parecerán cada vez más al de Claude 4, donde las ganancias en los benchmarks son marginales pero las del mundo real son sustanciales. Esta transición requerirá mucho más matiz para entender si el ritmo del progreso continúa, especialmente cuando los críticos de la IA aprovechen el estancamiento de las evaluaciones para sostener que la IA ya no funciona.

La pregunta final de Lambert es engañosamente sencilla: ¿son suficientes los canales de distribución existentes, los productos y la capacidad de servicio para mantener estable el valor de todas las principales empresas de IA de Estados Unidos? Lambert cree que están a salvo, pero los modelos y las empresas chinas están acaparando porciones más grandes del creciente pastel de la IA. No será una mayoría en términos de ingresos, pero puede ser una mayoría en "mindshare", especialmente en los mercados internacionales.

Lo que Lambert no dice explícitamente, pero que se desprende de sus palabras, es que estamos asistiendo no a una competencia, sino a una bifurcación. Dos ecosistemas paralelos que se refuerzan mutuamente por dentro, pero que cada vez se comunican menos entre sí. Y cuando la pregunta pasa de "¿quién va por delante?" a "¿quién importa para qué mercado?", las respuestas se vuelven inquietantemente geopolíticas.

## Geopolítica de los Algoritmos

Para entender el contexto más amplio de K2 Thinking, hay que mirar más allá de Moonshot. China tiene seis grandes laboratorios de IA que los medios especializados han empezado a llamar informalmente los "Tigres de la IA": DeepSeek, Moonshot, Alibaba (con Qwen), Baidu (con Ernie), ByteDance (con VolcEngine) y Tencent (con Hunyuan). Cada uno lanza modelos importantes cada dos o tres meses, creando una cadencia que mantiene a la industria mundial en constante tensión.

Los controles de exportación estadounidenses sobre chips avanzados, diseñados para frenar el desarrollo de la IA en China, han tenido un efecto paradójico. DeepSeek V3 fue entrenado con el [Nvidia H800](https://www.axios.com/2025/01/17/deepseek-china-ai-model), una versión menos potente del H100 que Estados Unidos prohibió para China en 2022. La prohibición posterior también afectó a los H800 en 2023, pero para entonces el camino ya estaba trazado: los laboratorios chinos aprendieron a extraer un rendimiento de vanguardia de un hardware subóptimo mediante optimizaciones de software agresivas.

El coste del entrenamiento es el dato que sigue dominando la narrativa. K2 Thinking requirió [menos de 5 millones de dólares](https://www.cnbc.com/2025/11/06/alibaba-backed-moonshot-releases-new-ai-model-kimi-k2-thinking.html), según las estimaciones oficiales. DeepSeek V3 había costado 5,6 millones. En comparación, GPT-4 había requerido más de 100 millones de dólares en 2023, y los rumores sobre GPT-5 hablan de presupuestos del orden de miles de millones. Emad Mostaque, ex director ejecutivo de Stability AI, tuiteó que con los chips Nvidia Blackwell de nueva generación bastarían 3 millones de dólares para entrenar un modelo competitivo con los modelos de vanguardia actuales.

Estas cifras tienen implicaciones directas en el mercado. Empresas como Airbnb ya han declarado públicamente que utilizan Qwen para algunas aplicaciones internas, primando la relación coste-rendimiento sobre el reconocimiento de la marca. Y mientras OpenAI y Anthropic defienden sus precios argumentando que los costes operativos siguen siendo altos, la realidad es que el mercado está descubriendo que "suficientemente bueno y diez veces más barato" supera a "perfecto pero prohibitivo" en la mayoría de los casos de uso reales.

La licencia MIT modificada bajo la que se publica K2 Thinking merece una mención. Es técnicamente de código abierto, permite el uso comercial y las modificaciones, pero incluye cláusulas que limitan el uso de los nombres "Moonshot" y "Kimi" en productos derivados. Es un compromiso entre la apertura genuina y la protección de la marca, una estrategia que los laboratorios chinos están perfeccionando para maximizar la adopción sin renunciar al control narrativo.

¿Quién gana y quién pierde en este escenario? Ganan los desarrolladores, que obtienen acceso a tecnologías que hasta ayer costaban decenas de miles de dólares al mes en llamadas a la API. Ganan las startups, que pueden competir con los titulares que basaban su ventaja en el acceso privilegiado a modelos propietarios. Pierden relevancia los laboratorios de código abierto occidentales, aplastados entre la velocidad china y la calidad (presunta) de los modelos cerrados estadounidenses. Y los propios gigantes estadounidenses se encuentran en una posición delicada: continuar con la estrategia cerrada corre el riesgo de hacerlos irrelevantes a largo plazo, pero abrirse por completo significaría canibalizar los flujos de ingresos que financian la I+D.

El verdadero perdedor, quizás, es la idea misma de un ecosistema de IA global unificado. Estamos asistiendo a la cristalización de esferas de influencia tecnológica paralelas, cada una con sus propios estándares, conjuntos de datos, sesgos y valores. Y cuando Lambert pregunta si esto es democratización o fragmentación, la respuesta honesta es: probablemente ambas, simultáneamente.

## Futuro Próximo

K2 Thinking no es una demo tecnológica lanzada para hacer ruido y luego ser olvidada. Los servidores de Moonshot están actualmente saturados, con tiempos de espera que en los picos superan los diez minutos para obtener una respuesta. Es el tipo de problema que las startups sueñan con tener: demasiada demanda, poca capacidad. Pero señala algo más profundo: los desarrolladores están desplegando realmente estos modelos en producción, no solo probándolos por curiosidad.

El impacto más inmediato está en la dinámica cliente-proveedor en la IA. Durante años, la relación de poder estaba desequilibrada: si querías capacidades de vanguardia, tenías que aceptar los términos de OpenAI o Anthropic, incluidos los precios, los límites de velocidad y las políticas de datos. Con K2 y sus similares, el cálculo cambia. Una empresa puede descargar los pesos, desplegar en las propias instalaciones o en la nube de su elección, y tener un control completo sobre la latencia, la privacidad y los costes operativos. No es perfecto para todos los casos de uso, pero para una parte significativa del mercado es más que suficiente.

Las preguntas abiertas siguen siendo numerosas. La multimodalidad nativa, por ejemplo: K2 Thinking sigue siendo principalmente de texto, mientras que GPT-4 y Claude pueden procesar imágenes, audio y vídeo de forma integrada. Las trazas de razonamiento, esas cadenas de pensamiento explícitas que muestran modelos como o1 y R1, son menos transparentes en K2, lo que dificulta la depuración cuando el modelo se equivoca. Y la cuestión de la sostenibilidad a largo plazo: ¿puede Moonshot, con una fracción de los recursos de OpenAI, mantener este ritmo de innovación?

Pero quizás la pregunta más interesante es la que Lambert deja implícitamente abierta: ¿qué ocurre cuando lo imposible se convierte en rutina? Cuando se lanzó K2 Thinking, muchos reaccionaron con entusiasmo. El próximo modelo chino que bata los benchmarks tendrá menos cobertura mediática. El siguiente, aún menos. No porque sean menos impresionantes técnicamente, sino porque la curva de las expectativas se habrá desplazado.

Estamos en ese punto de la película de atracos en el que los protagonistas han perfeccionado el golpe hasta el punto de que parece casi aburrido. Entrar en la bóveda, sortear los sistemas, salir limpios. Sin drama, solo ejecución. Es el momento más peligroso, aquel en el que el exceso de confianza lleva a los errores. Y en el contexto de la IA, los errores no significan fallar un benchmark, sino distribuir sistemas que tomarán decisiones críticas sin que hayamos comprendido completamente cómo o por qué.

K2 Thinking es un logro técnico notable. Pero su verdadera importancia podría ser la de marcar el momento en el que dejamos de sorprendernos y empezamos a asumir que este nivel de capacidad es la nueva línea de base. Y cuando lo excepcional se vuelve ordinario, es ahí donde empiezan los verdaderos problemas interesantes.
