---
tags: ["Generative AI", "Applications", "Business"]
date: 2025-11-12
author: "Dario Ferrero"
---

# Kimi K2 Thinking : La Chine prend la tête
![kimi-k2-thinking.jpg](kimi-k2-thinking.jpg)

*Moonshot AI réécrit les règles de l'intelligence artificielle avec Kimi K2 Thinking : un modèle open source d'un trillion de paramètres qui défie GPT-5 et Claude, pour un coût inférieur à 5 millions de dollars. Le 6 novembre 2025, alors que la communauté des développeurs d'IA parcourait distraitement les notifications sur Hugging Face, une publication est apparue qui aurait pu sembler être un énième modèle de langage chinois. Kimi K2 Thinking, créé par la start-up Moonshot AI soutenue par Alibaba, promettait les merveilles habituelles : des capacités d'agent avancées, une architecture Mixture-of-Experts, un trillion de paramètres au total.*

*Mais lorsque les premiers benchmarks ont commencé à circuler, quelque chose d'inattendu a émergé des chiffres : 44,9 % sur l'[Humanity's Last Exam](https://agi.safe.ai/), battant à la fois GPT-5 et Claude Sonnet 4.5. Pas de peu, pas par erreur statistique, mais avec des marges qui ont forcé même les plus sceptiques à recalculer.*

*Pour ceux qui ne maîtrisent pas quotidiennement l'alphabet des acronymes de l'IA, Humanity's Last Exam est ce qui se produit lorsque les experts décident d'arrêter la marche triomphale des modèles de langage : [trois mille questions recueillies par crowdsourcing auprès de plus d'un millier de spécialistes](https://scale.com/leaderboard/humanitys_last_exam), conçues pour être trop difficiles même pour les systèmes les plus avancés. Mathématiques avancées, biologie moléculaire, philosophie analytique, physique quantique. Le genre d'examen où GPT-4o balbutie à 9 % et où même les modèles de raisonnement les plus récents peinent à dépasser 30 %. Kimi K2 Thinking a franchi ce seuil avec un naturel qui rappelle les films de braquage lorsque le coup impossible devient une routine : pas de spectacle, juste une précision méthodique.*

*Mais ce n'est pas l'histoire d'un seul modèle exceptionnel. C'est la chronique d'un moment où l'impossible devient la nouvelle norme, et où les règles économiques et géopolitiques de l'IA sont réécrites par ceux qui, théoriquement, devaient rester à la traîne.*

## À l'intérieur de la Machine

Pour comprendre ce qui rend K2 Thinking différent, il faut se plonger dans l'architecture, où les choix d'ingénierie deviennent des déclarations d'intention. Le modèle est construit sur une architecture [Mixture-of-Experts avec un trillion de paramètres au total](https://arxiv.org/abs/2507.20534), mais il n'en active que 32 milliards pour chaque jeton traité. C'est une stratégie qui rappelle les centrales électriques modulaires : toute cette puissance existe, mais elle n'est sollicitée que lorsque c'est nécessaire, ce qui réduit considérablement les coûts d'exploitation sans sacrifier les capacités.

La véritable innovation, cependant, réside dans la quantification INT4 native. Alors que la plupart des modèles sont entraînés avec une plus grande précision puis compressés, K2 Thinking a été conçu dès le départ pour fonctionner en INT4, ce qui réduit de moitié les besoins en mémoire et double la vitesse d'inférence sans les pertes de précision typiques qui affectent la compression post-hoc. C'est le genre de choix qui privilégie l'efficacité opérationnelle à la métrique de vanité du nombre total de paramètres, une philosophie qui deviendra centrale lorsque nous parlerons des coûts.

L'architecture MoE de K2 répartit la charge sur 384 experts spécialisés, contre 256 pour DeepSeek V3, ce qui permet une plus grande granularité dans la sélection des compétences. Chaque requête active un sous-ensemble dynamique de ces experts, et le système choisit de manière autonome les neurones à solliciter en fonction du type de problème. En pratique, lorsque K2 doit écrire du code Python, il active un ensemble d'experts différent de celui qu'il utilise pour résoudre des équations différentielles ou traduire du sanskrit.

Mais l'élément qui distingue K2 Thinking de ses prédécesseurs est la mise à l'échelle au moment du test, une technique qui permet au modèle de "réfléchir plus longtemps" à des problèmes complexes. Il ne s'agit pas d'un simple essai-erreur : le système peut allouer plus de cycles de calcul aux questions difficiles, en explorant des chaînes de raisonnement alternatives avant de converger vers une réponse. C'est ce que les chercheurs appellent le "mode de pensée", et c'est la raison pour laquelle K2 peut s'attaquer à des problèmes en plusieurs étapes qui nécessiteraient normalement une supervision humaine.

Sur le front de l'agentivité, K2 démontre des capacités qui, il y a quelques mois encore, étaient l'apanage de systèmes fermés et coûteux : il peut exécuter [200 à 300 appels séquentiels à des outils](https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model) sans intervention humaine, en naviguant dans des API externes, en traitant des données structurées et en orchestrant des flux de travail complexes. La fenêtre de contexte de 256 000 jetons permet de maintenir la cohérence sur des conversations étendues ou des documents techniques volumineux, tandis que le système de mémoire cache réduit la latence dans les interactions répétées.
![grafico1.jpg](grafico1.jpg)
[Image tirée de l'article officiel sur arxiv.org](https://arxiv.org/pdf/2507.20534)

## Les Chiffres Parlent

Les benchmarks sont le champ de bataille où les promesses sont mesurées à l'aune de la réalité. Sur [Humanity's Last Exam](https://scale.com/leaderboard/humanitys_last_exam), K2 Thinking atteint 44,9 %, dépassant GPT-5 (42,1 %) et Claude Sonnet 4.5 (41,7 %). Mais le véritable facteur de différenciation apparaît lorsque l'on examine les tâches d'agent : sur [BrowseComp](https://arxiv.org/abs/2507.20534), qui mesure la capacité à naviguer sur le web et les API de manière autonome, K2 obtient 34,2 % contre 28,5 % pour GPT-5. Sur SWE-Bench Verified, le benchmark d'ingénierie logicielle qui exige de résoudre des bogues réels dans des bases de code open source, K2 atteint 65,8 %, dépassant pratiquement tous les modèles non pensants disponibles.

Tout ne brille pas de la même manière. Sur GPQA Diamond, l'ensemble de données de questions scientifiques de niveau supérieur, K2 s'arrête à 75,1 %, un résultat excellent mais pas record. Et lorsque GPT-5 est exécuté en "mode lourd" avec un raisonnement étendu, il parvient encore à dépasser K2 sur certaines tâches spécifiques de mathématiques pures. Mais ce qui compte, dans le récit plus large, c'est que ces différences sont marginales, et elles disparaissent complètement lorsque l'on considère le rapport coût-performance.

Car c'est là qu'émerge la donnée qui a fait trembler la Silicon Valley : K2 Thinking coûte 0,33 $ par million de jetons d'entrée et 1,33 $ de sortie. Le GPT-5 standard s'élève à 1,25 $/10 $, tandis que le GPT-5 en mode raisonnement peut atteindre 50 $ par million de jetons de sortie. Nous ne parlons pas de différences de 20 à 30 %, mais d'un ordre de grandeur. Pour une entreprise qui traite des dizaines de millions de jetons par jour, le calcul devient brutalement simple.

Et il y a un détail technique qui mérite d'être souligné : tous ces benchmarks de K2 ont été exécutés en INT4, sans astuces de précision gonflée pour gagner des points de pourcentage. Certains laboratoires publient des chiffres impressionnants en FP16, puis, lorsque le modèle est effectivement déployé en production quantifié, les performances s'effondrent. K2 a été testé dans les mêmes conditions que celles dans lesquelles il serait utilisé en production, une transparence qui devrait être la norme mais qui l'est rarement.

Sur [LiveCodeBench v6](https://arxiv.org/abs/2507.20534), qui teste la capacité à écrire du code pour de nouveaux problèmes jamais vus pendant l'entraînement, K2 atteint 53,7 %. Sur AIME 2025, l'examen de mathématiques avancées pour les étudiants américains, il obtient 49,5 %. Sur OJBench, un benchmark chinois de programmation compétitive, il atteint 27,1 %. Des chiffres qui, individuellement, peuvent sembler être des détails techniques, mais qui, regroupés, dessinent le profil d'un système qui a franchi le seuil de l'utilité pratique sur un très large éventail d'applications réelles.
![grafico2.jpg](grafico2.jpg)
[Image tirée de l'article officiel sur arxiv.org](https://arxiv.org/pdf/2507.20534)

## La Voix Critique

Nathan Lambert n'est pas du genre à se laisser impressionner facilement. Chercheur en IA à l'Allen Institute for AI et auteur de la [newsletter Interconnects](https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means), Lambert a passé des années à analyser l'écart entre le battage médiatique et la réalité dans le secteur. Lorsqu'il a écrit son analyse de K2 Thinking, il a posé une question qui tranche comme un scalpel : "Qu'est-ce que cela signifie quand un moment DeepSeek devient une routine ?"

Lorsque DeepSeek V3 a été lancé fin 2024 avec un coût de formation de 5,6 millions de dollars, l'industrie a eu un sursaut collectif. C'était l'anomalie qui confirmait la règle : oui, il est possible de construire des modèles compétitifs avec des budgets ridicules, mais cela reste une exception. Aujourd'hui, dix mois plus tard, nous avons Moonshot avec K2, Qwen qui enchaîne les sorties, et une douzaine d'autres laboratoires chinois qui publient des modèles open source toutes les deux semaines. Les serveurs de Kimi sont déjà saturés, signe que nous ne parlons pas de démos technologiques mais de systèmes que les développeurs déploient réellement en production.

Lambert identifie cinq dynamiques critiques, et la première est la plus simple mais la plus dévastatrice : les laboratoires chinois publient plus vite. Beaucoup plus vite. Alors qu'Anthropic peut mettre des mois à faire passer un modèle du laboratoire à la production, et qu'OpenAI se situe quelque part au milieu, les laboratoires chinois réduisent ce cycle à quelques semaines. Lorsque le rythme du progrès est élevé, être plus rapide vous fait paraître meilleur. Lambert estime l'écart de performance brute entre les modèles fermés et ouverts à environ quatre à six mois, mais il pose ensuite la question rhétorique : si ces modèles fermés ne sont pas publiquement disponibles, comptent-ils vraiment ?

Le deuxième point touche quelque chose de plus nuancé : les laboratoires chinois dominent sur les benchmarks clés, mais il existe des "comportements de longue traîne" pour lesquels ils n'ont pas de boucles de rétroaction. Lambert note que Qwen, au cours de la dernière année, est passé du statut de connu pour le "benchmaxing" (optimisation obsessionnelle des benchmarks) à la production de modèles véritablement fantastiques qui, par coïncidence, ont également des scores insensés. DeepSeek et Kimi ont ce que Lambert appelle le "bon goût", une qualité difficile à quantifier mais immédiate à percevoir lorsque vous utilisez les modèles. Mais il reste des comportements d'utilisateurs courants, en particulier occidentaux, sur lesquels les entreprises américaines ont des années de données internes et les laboratoires chinois non. Ces immatériels comptent pour la fidélisation des utilisateurs, même s'ils n'apparaissent pas sur Humanity's Last Exam.

C'est là que Lambert reconnaît un détail technique souvent négligé : K2 Thinking a été entraîné nativement en INT4 pendant la post-formation, probablement pour rendre la mise à l'échelle de l'apprentissage par renforcement plus efficace sur les séquences longues. Et tous les benchmarks rapportés sont en INT4, pas en précision gonflée. C'est la manière honnête de faire des comparaisons, note Lambert, car c'est ainsi que le modèle sera réellement servi.

Le troisième point est géopolitique et inexorable : au début de 2025, la plupart des personnes qui suivaient l'IA ne connaissaient aucun laboratoire chinois. Aujourd'hui, vers la fin de l'année, DeepSeek, Qwen et Kimi deviennent des noms courants. Ils ont tous des saisons de meilleures sorties et des points forts différents. Et la liste continuera de s'allonger : Lambert cite Z.ai, Meituan, Ant Ling comme de possibles ajouts pour 2026. Certains de ces laboratoires ont commencé leurs efforts sur les modèles de fondation après DeepSeek, et en six mois, ils ont atteint le niveau de la frontière ouverte. La question est maintenant de savoir s'ils peuvent offrir quelque chose dans une niche de la frontière qui ait une réelle demande de la part des utilisateurs.

Le quatrième aspect concerne les capacités d'agent entrelacées : K2 Thinking peut exécuter des centaines d'appels séquentiels à des outils, une caractéristique qui est devenue la norme dans les modèles fermés comme o3 et Grok 4. Techniquement, ce n'est pas révolutionnaire, cela apparaît naturellement pendant l'entraînement RL, en particulier lorsque le modèle doit rechercher des informations pour répondre correctement. Mais c'est la première fois que cette capacité apparaît dans un modèle ouvert avec cette robustesse, et les fournisseurs qui hébergent des poids ouverts devront travailler dur pour la prendre en charge avec précision. Lambert espère qu'il existe une demande suffisante de la part des utilisateurs pour faire mûrir l'industrie dans le service de modèles ouverts utilisant des outils.

Le cinquième point est le plus préoccupant pour les laboratoires américains : la pression est réelle. Il y a une pression sur les prix et des attentes qu'ils doivent gérer. La différenciation et le discours sur les raisons pour lesquelles leurs services fermés sont meilleurs doivent évoluer rapidement, en s'éloignant des benchmarks que même l'open source domine désormais. Lambert avait anticipé cela dans son article de l'été "Quelques réflexions sur ce qui va suivre", suggérant que les futures sorties ressembleront de plus en plus à celle de Claude 4, où les gains sur les benchmarks sont marginaux mais ceux dans le monde réel sont substantiels. Cette transition nécessitera beaucoup plus de nuances pour comprendre si le rythme du progrès se poursuit, en particulier lorsque les critiques de l'IA exploiteront le plateau des évaluations pour soutenir que l'IA ne fonctionne plus.

La question finale de Lambert est d'une simplicité trompeuse : les canaux de distribution existants, les produits et la capacité de service sont-ils suffisants pour maintenir la valeur de toutes les grandes entreprises d'IA américaines stable ? Lambert pense qu'elles sont en sécurité, mais les modèles et les entreprises chinois prennent des parts plus importantes du gâteau de l'IA en pleine croissance. Ce ne sera pas une majorité en termes de revenus, mais cela peut être une majorité en termes de "mindshare", en particulier sur les marchés internationaux.

Ce que Lambert ne dit pas explicitement, mais qui émerge entre les lignes, c'est que nous assistons non pas à une compétition mais à une bifurcation. Deux écosystèmes parallèles qui se renforcent mutuellement à l'intérieur, mais qui communiquent de moins en moins entre eux. Et lorsque la question passe de "qui est en avance" à "qui compte pour quel marché", les réponses deviennent inquiétantes et géopolitiques.

## Géopolitique des Algorithmes

Pour comprendre le contexte plus large de K2 Thinking, il faut regarder au-delà de Moonshot. La Chine compte six grands laboratoires d'IA que les médias spécialisés ont commencé à appeler officieusement les "Tigres de l'IA" : DeepSeek, Moonshot, Alibaba (avec Qwen), Baidu (avec Ernie), ByteDance (avec VolcEngine) et Tencent (avec Hunyuan). Chacun publie des modèles majeurs tous les deux ou trois mois, créant une cadence qui maintient l'industrie mondiale sous une tension constante.

Les contrôles américains sur les exportations de puces avancées, conçus pour ralentir le développement de l'IA en Chine, ont eu un effet paradoxal. DeepSeek V3 a été entraîné sur le [Nvidia H800](https://www.axios.com/2025/01/17/deepseek-china-ai-model), une version moins puissante du H100 que les États-Unis ont interdite à la Chine en 2022. L'interdiction ultérieure a également frappé les H800 en 2023, mais à ce moment-là, la voie était tracée : les laboratoires chinois ont appris à extraire des performances de pointe à partir d'un matériel sous-optimal grâce à des optimisations logicielles agressives.

Le coût de la formation est la donnée qui continue de dominer le récit. K2 Thinking a nécessité [moins de 5 millions de dollars](https://www.cnbc.com/2025/11/06/alibaba-backed-moonshot-releases-new-ai-model-kimi-k2-thinking.html), selon les estimations officielles. DeepSeek V3 avait coûté 5,6 millions de dollars. À titre de comparaison, GPT-4 avait nécessité plus de 100 millions de dollars en 2023, et les rumeurs sur GPT-5 parlent de budgets de l'ordre de plusieurs milliards. Emad Mostaque, ancien PDG de Stability AI, a tweeté qu'avec les puces Nvidia Blackwell de nouvelle génération, il ne faudrait que 3 millions de dollars pour entraîner un modèle compétitif avec les modèles de pointe actuels.

Ces chiffres ont des implications directes sur le marché. Des entreprises comme Airbnb ont déjà déclaré publiquement qu'elles utilisaient Qwen pour certaines applications internes, privilégiant le rapport coût-performance à la reconnaissance de la marque. Et tandis qu'OpenAI et Anthropic défendent leurs prix en soutenant que les coûts d'exploitation restent élevés, la réalité est que le marché découvre que "assez bon et dix fois moins cher" l'emporte sur "parfait mais prohibitif" dans la plupart des cas d'utilisation réels.

La licence MIT modifiée sous laquelle K2 Thinking est publié mérite une note. Elle est techniquement open source, permet une utilisation commerciale et des modifications, mais inclut des clauses qui limitent l'utilisation des noms "Moonshot" et "Kimi" dans les produits dérivés. C'est un compromis entre une ouverture authentique et la protection de la marque, une stratégie que les laboratoires chinois perfectionnent pour maximiser l'adoption sans renoncer au contrôle narratif.

Qui gagne et qui perd dans ce scénario ? Les développeurs gagnent, en accédant à des technologies qui, jusqu'à hier, coûtaient des dizaines de milliers de dollars par mois en appels d'API. Les start-ups gagnent, en pouvant concurrencer les acteurs établis qui fondaient leur avantage sur un accès privilégié à des modèles propriétaires. Les laboratoires open source occidentaux perdent de leur pertinence, écrasés entre la vitesse chinoise et la qualité (présumée) des modèles fermés américains. Et les géants américains eux-mêmes se retrouvent dans une position délicate : continuer avec la stratégie fermée risque de les rendre insignifiants à long terme, mais ouvrir complètement signifierait cannibaliser les flux de revenus qui financent la R&D.

Le vrai perdant, peut-être, est l'idée même d'un écosystème d'IA mondial unifié. Nous assistons à la cristallisation de sphères d'influence technologique parallèles, chacune avec ses propres normes, ensembles de données, biais et valeurs. Et lorsque Lambert demande s'il s'agit de démocratisation ou de fragmentation, la réponse honnête est : probablement les deux, simultanément.

## Futur Proche

K2 Thinking n'est pas une démo technologique lancée pour faire du bruit puis oubliée. Les serveurs de Moonshot sont actuellement saturés, avec des temps d'attente qui, aux heures de pointe, dépassent les dix minutes pour obtenir une réponse. C'est le genre de problème que les start-ups rêvent d'avoir : trop de demande, pas assez de capacité. Mais cela signale quelque chose de plus profond : les développeurs déploient réellement ces modèles en production, et ne se contentent pas de les tester par curiosité.

L'impact le plus immédiat se situe sur la dynamique client-fournisseur dans l'IA. Pendant des années, le rapport de force était déséquilibré : si vous vouliez des capacités de pointe, vous deviez accepter les conditions d'OpenAI ou d'Anthropic, y compris les prix, les limites de débit, les politiques de données. Avec K2 et ses semblables, le calcul change. Une entreprise peut télécharger les poids, les déployer sur site ou sur le cloud de son choix, et avoir un contrôle total sur la latence, la confidentialité et les coûts d'exploitation. Ce n'est pas parfait pour tous les cas d'utilisation, mais pour une part importante du marché, c'est plus que suffisant.

Les questions ouvertes restent nombreuses. La multimodalité native, par exemple : K2 Thinking est encore principalement basé sur le texte, tandis que GPT-4 et Claude peuvent traiter des images, du son, de la vidéo de manière intégrée. Les traces de raisonnement, ces chaînes de pensée explicites que des modèles comme o1 et R1 montrent, sont moins transparentes dans K2, ce qui rend le débogage plus difficile lorsque le modèle se trompe. Et la question de la durabilité à long terme : Moonshot, avec une fraction des ressources d'OpenAI, peut-il maintenir ce rythme d'innovation ?

Mais peut-être que la question la plus intéressante est celle que Lambert laisse implicitement ouverte : que se passe-t-il lorsque l'impossible devient une routine ? Lorsque K2 Thinking a été lancé, beaucoup ont réagi avec enthousiasme. Le prochain modèle chinois qui battra les benchmarks aura moins de couverture médiatique. Le suivant encore moins. Non pas parce qu'ils sont moins impressionnants techniquement, mais parce que la courbe des attentes se sera déplacée.

Nous en sommes à ce point du film de braquage où les protagonistes ont perfectionné le coup au point qu'il en semble presque ennuyeux. Entrer dans le coffre-fort, contourner les systèmes, sortir indemnes. Pas de drame, juste de l'exécution. C'est le moment le plus dangereux, celui où l'excès de confiance mène aux erreurs. Et dans le contexte de l'IA, les erreurs ne signifient pas échouer à un benchmark, mais distribuer des systèmes qui prendront des décisions critiques sans que nous ayons complètement compris comment ou pourquoi.

K2 Thinking est une réalisation technique remarquable. Mais sa véritable importance pourrait être de marquer le moment où nous avons cessé d'être étonnés et où nous avons commencé à supposer que ce niveau de capacité est la nouvelle base de référence. Et lorsque l'exceptionnel devient ordinaire, c'est là que les vrais problèmes intéressants commencent.
