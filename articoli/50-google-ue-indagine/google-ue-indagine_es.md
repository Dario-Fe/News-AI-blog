---
tags: ["Copyright", "Ethics & Society", "Business"]
date: 2025-11-19
author: "Dario Ferrero"
---

# La UE investiga a Google: ¿Es la IA la culpable del colapso de los editores?
![google-ue-indagine.jpg](google-ue-indagine.jpg)


*La UE abre una investigación formal sobre Google por el colapso del tráfico de los editores. Pero detrás de la disputa sobre el spam se esconde una partida más grande: quién controla realmente el flujo de información en línea y quién se beneficia de él.*

## La chispa que enciende el fuego

El 13 de noviembre de 2025, la Comisión Europea [inició un procedimiento formal](https://ec.europa.eu/commission/presscorner/detail/it/ip_25_2675) contra Google en virtud de la Ley de Mercados Digitales. La acusación es precisa: las modificaciones de las políticas de clasificación de la búsqueda, introducidas bajo la etiqueta de lucha contra el spam, habrían causado un colapso vertical del tráfico hacia los sitios de los editores europeos, penalizando en particular a aquellos que alojan contenidos comerciales de terceros.

Teresa Ribera, vicepresidenta ejecutiva de la Comisión, no se anda con rodeos: "Nos preocupa que las políticas de Google no permitan que los editores de noticias sean tratados de manera justa, razonable y no discriminatoria en los resultados de búsqueda". La investigación se centra en dos artículos específicos de la DMA, el 6(5) y el 6(12), que obligan a los llamados "guardianes de acceso" a garantizar la transparencia y la igualdad de trato a los usuarios comerciales de sus servicios.

La respuesta de Google llega pocas horas después, con una [publicación en el blog de la empresa](https://blog.google/inside-google/company-announcements/defending-search-users-from-parasite-seo-spam/) que da un vuelco total a la narrativa. Dan Taylor, vicepresidente de Google Search, enmarca la cuestión como una batalla para proteger a los usuarios de prácticas manipuladoras: el "SEO parásito", donde los sitios con autoridad venden espacios en sus propias URL para alojar contenidos de terceros que aprovechan su reputación para escalar en los resultados de búsqueda.

El momento del anuncio europeo no es casual. En octubre de 2025, Google ya había recibido una multa de 2.950 millones de euros por infracciones en el sector de la tecnología publicitaria, también en virtud de la DMA. Esta nueva investigación, que podría dar lugar a sanciones de hasta el 10% de la facturación global anual de la empresa, se inscribe en un contexto de creciente tensión entre las grandes tecnológicas y los reguladores europeos.
![ue.jpg](ue.jpg)
[Imagen extraída del sitio web de la Unión Europea](https://ec.europa.eu/commission/presscorner/detail/it/ip_25_2675)

## Anatomía de una degradación

Para entender lo que realmente está sucediendo, hay que retroceder unos meses. En marzo de 2024, Google introduce la política de "abuso de la reputación del sitio", destinada a combatir lo que la empresa define como una contaminación sistemática de los resultados de búsqueda. El mecanismo es tan simple como devastador: los medios de comunicación y los sitios con autoridad vendían subdirectorios o subdominios a operadores comerciales, que publicaban en ellos contenidos optimizados para SEO de productos financieros, casinos en línea, reseñas patrocinadas.

El caso simbólico es el de Forbes, que alojaba en sus subdominios contenidos de afiliación para tarjetas de crédito y cuentas corrientes que no tenían ninguna conexión editorial con el medio. Lo mismo ocurría con el Wall Street Journal, la CNN y decenas de otros medios que habían transformado porciones de sus propias URL en verdaderos enclaves comerciales. Google define esta práctica como "parasitaria" porque aprovecha la autoridad de un dominio construida a lo largo del tiempo con fines puramente comerciales, creando una distorsión de la competencia con respecto a los sitios especializados que, en cambio, operan de forma autónoma.

Sin embargo, la política inicial dejaba una escapatoria: solo podía aplicarse manualmente, caso por caso. En noviembre de 2024 llega la actualización que cierra cualquier resquicio, haciendo automática la detección y la degradación de estos contenidos. Los efectos son inmediatos y drásticos. [Según los datos reportados por diversas fuentes](https://www.siliconrepublic.com/business/eu-google-news-media-search-results-dma), algunos editores europeos registran caídas de tráfico de hasta el 34% en pocas semanas.

El problema es que el algoritmo no siempre distingue entre la explotación parasitaria y las asociaciones legítimas. Un medio que publica contenidos patrocinados claramente etiquetados, o que aloja secciones de afiliación coherentes con su línea editorial, puede acabar en el mismo saco que el spam puro. Es como usar un mazo donde se necesitaría un bisturí.
![google.jpg](google.jpg)
[Imagen extraída del blog de Google](https://blog.google/inside-google/company-announcements/defending-search-users-from-parasite-seo-spam/)

## El verdadero campo de batalla

Detrás de esta disputa técnica se esconde una partida mucho más amplia sobre el futuro del ecosistema informativo digital. La Ley de Mercados Digitales, que entró en vigor en 2023, designa a Google como guardián de acceso precisamente por su papel dominante en la distribución de la información en línea. La empresa de Mountain View controla más del 90% del mercado europeo de la búsqueda, una posición que le confiere un poder sin precedentes para decidir qué contenidos llegan a los usuarios y cuáles no.

Pero hay otra dimensión de la cuestión que rara vez emerge en el debate público: el artículo 15 de la Directiva Europea sobre Derechos de Autor, comúnmente conocido como "derechos vecinos". Esta norma, aprobada tras años de batallas legislativas, reconoce a los editores el derecho a ser compensados cuando sus contenidos son utilizados por las plataformas digitales. Google siempre ha visto esta directiva como una amenaza existencial para su modelo de negocio.

Las crónicas recientes documentan bien este conflicto. En 2018, cuando la directiva aún se estaba discutiendo, Google había [realizado pruebas](https://medium.com/whats-new-in-publishing/45-traffic-decline-to-news-publishers-due-to-eus-article-11-google-reveals-344d8427cf0c) en varios países europeos para demostrar el impacto de una posible eliminación de los fragmentos de las noticias. Los resultados mostraban caídas de tráfico del 45% para los editores, un mensaje intimidatorio que decía: sin nosotros, estáis muertos. En España, donde en 2014 se había aprobado una ley similar, Google simplemente había cerrado Google News, causando daños económicos significativos, sobre todo a los pequeños editores.

Francia tomó un camino diferente. Tras largas negociaciones y amenazas de sanciones, Google aceptó pagar compensaciones a los editores franceses, aunque los importes y los términos precisos de los acuerdos siguen siendo confidenciales. Angela Mills Wade, directora ejecutiva del Consejo Europeo de Editores, había acusado en su momento a Google](https://www.cjr.org/the_media_today/google-news-france.php) de "abusar de su posición dominante y ponerse por encima de la ley".

Hoy el guion se repite con nuevas variantes. Google sostiene que lucha contra el spam, los editores denuncian una degradación arbitraria, Bruselas investiga. Pero el verdadero tema subyacente es siempre el mismo: quién controla el grifo del tráfico en línea y quién se beneficia económicamente de él.

## La revolución silenciosa

Para comprender plenamente la estrategia de Google, hay que mirar más allá de esta controversia específica y analizar un fenómeno más amplio: la transformación de la búsqueda de una herramienta de navegación a un destino final. Es aquí donde entra en juego el elemento más disruptivo de todo el asunto.

[Un estudio publicado por SparkToro](https://sparktoro.com/blog/2024-zero-click-search-study-for-every-1000-us-google-searches-only-374-clicks-go-to-the-open-web-in-the-eu-its-360/) en 2024 reveló datos sorprendentes: el 59,7% de las búsquedas europeas en Google terminan sin ningún clic hacia sitios externos. Esto significa que de cada mil búsquedas, solo 374 generan tráfico hacia la web abierta. El resto se disuelve dentro del ecosistema de Google: búsquedas que terminan sin acción, consultas que cambian sin salir nunca de la plataforma, usuarios que encuentran la respuesta directamente en la página de resultados.

El principal mecanismo detrás de esta transformación son las "AI Overviews", los resúmenes generados automáticamente que aparecen en la parte superior de los resultados. Cuando un usuario ve una respuesta completa ya preparada por un algoritmo de inteligencia artificial, la probabilidad de que haga clic en un enlace se reduce drásticamente. [Investigaciones del Pew Research Center](https://www.pewresearch.org/short-reads/2025/07/22/google-users-are-less-likely-to-click-on-links-when-an-ai-summary-appears-in-the-results/) han demostrado que la presencia de estos resúmenes reduce en un 50% la propensión a hacer clic, y solo el 1% de los usuarios hace clic en los enlaces citados dentro de las propias "AI Overviews".

Como documenté en el análisis de la revolución [de la IA de Google](https://aitalk.it/it/google-ai-revolution.html), esta transformación no es accidental, sino planificada. El 6 de septiembre de 2025, cuando google.com/ai fue redirigido a la búsqueda estándar, la inteligencia artificial se convirtió en el motor predeterminado para miles de millones de consultas diarias. Ya no es un experimento, sino la nueva realidad de Internet.

Esta evolución plantea preguntas fundamentales. Si Google entrena sus modelos de inteligencia artificial con los contenidos producidos por los editores, para luego utilizar esos modelos para retener a los usuarios dentro de su propio ecosistema, ¿quién se beneficia económicamente de esta transformación? ¿El creador original del contenido o la plataforma que lo reelabora y distribuye?

El debate sobre cómo remunerar a los productores de contenidos en la era de la IA acaba de empezar. Como profundicé en el artículo sobre [Really Simple Licensing](https://aitalk.it/it/rsl-really-simple-licensing.html), el protocolo propuesto por el co-creador de RSS, Dave Winer, busca crear estándares técnicos que permitan a los editores especificar los términos y condiciones para el uso de sus contenidos en el entrenamiento de sistemas de inteligencia artificial. Plataformas como Reddit, Yahoo y Medium ya se han adherido, pero el camino hacia una adopción universal parece todavía largo e incierto.

## Los intereses ocultos

La disputa entre Google y los editores europeos presenta múltiples niveles de complejidad, donde las razones legítimas se entrelazan con los intereses económicos y las estrategias de posicionamiento. Analizar las motivaciones de cada parte requiere ir más allá de las declaraciones públicas y mirar los modelos de negocio subyacentes.

Google sostiene que protege a los usuarios del spam, y esta afirmación tiene su validez objetiva. El SEO parásito es un problema real: los sitios con autoridad que venden porciones de sus propias URL a operadores comerciales crean efectivamente distorsiones en los resultados de búsqueda. Un usuario que busca información financiera y se encuentra en un subdominio de Forbes con contenidos de afiliación poco transparentes tiene razón en sentirse engañado. El algoritmo de Google, en este caso, está intentando restablecer una coherencia entre la expectativa del usuario y el contenido realmente servido.

Sin embargo, esta narrativa protectora choca con un dato económico ineludible: Google se beneficia directamente de la reducción del tráfico hacia el exterior. Cada usuario que permanece más tiempo dentro del ecosistema de Google está potencialmente expuesto a más publicidad de Google, utiliza más servicios de Google, genera más datos para Google. Las búsquedas de "cero clics" no son un efecto secundario no deseado, sino una característica del sistema. Cuando la empresa declara que está "luchando contra el spam", también está construyendo un jardín amurallado cada vez más autosuficiente.

Por otro lado, los editores denuncian un trato discriminatorio, y también aquí el argumento tiene fundamentos concretos. La distinción entre el contenido comercial legítimo y el spam parasitario es a menudo difusa. ¿Una publicación que publica guías de compra bien cuidadas, con enlaces de afiliación transparentes, está haciendo algo diferente de lo que hace Wirecutter del New York Times? La diferencia radica en la calidad y la honestidad editorial, no en la presencia o ausencia de fines comerciales.

Pero la posición de los editores también esconde ambigüedades no despreciables. Muchos medios han construido durante años modelos de negocio opacos, donde la línea entre el periodismo y la publicidad se ha ido desdibujando progresivamente. El "native advertising", cuando está bien hecho, puede ser informativo y útil. Cuando está mal hecho, se vuelve indistinguible del spam que Google dice combatir. Los editores que hoy protestan contra la degradación son, en muchos casos, los mismos que durante años han aceptado alojar contenidos comerciales poco transparentes, tratando de maximizar los ingresos a corto plazo a expensas de la credibilidad a largo plazo.

La Comisión Europea, por último, se mueve en un delicado equilibrio entre la protección de la competencia y la tutela del ecosistema informativo. La DMA nace con el objetivo de impedir que los guardianes de acceso digitales utilicen su posición dominante para distorsionar los mercados. Google, con su control casi monopolístico de la búsqueda, encaja perfectamente en esta categoría. Pero la pregunta compleja es: ¿cuándo se convierte una modificación algorítmica en un abuso de posición dominante? Si Google mejora realmente la experiencia del usuario luchando contra el spam, ¿puede la UE imponerle que no lo haga para proteger los ingresos de los editores?

## ¿Jaque o tablas?

Los caminos que se abren ante los protagonistas de esta historia son múltiples, cada uno con consecuencias profundas para el futuro de la web. El resultado más inmediato podría ser un acuerdo bajo cuerda, donde Google acepte modificaciones marginales de su política a cambio del archivo de la investigación. Esta solución, ya vista en el pasado en otras controversias antimonopolio, dejaría sin resolver las cuestiones de fondo.

Un escenario más drástico prevé sanciones severas y remedios estructurales. La Comisión podría obligar a Google a hacer más transparentes los criterios de clasificación, a crear mecanismos de apelación para los editores penalizados, o incluso a separar el negocio de la búsqueda del de la publicidad. Se han aplicado medidas similares en otros casos de abuso de posición dominante, pero su eficacia práctica sigue siendo objeto de debate.

La hipótesis más extrema, pero no del todo inverosímil, es que Google decida retirar algunas funcionalidades en Europa, como ha amenazado en varias ocasiones en el pasado. El cierre de Google News en España en 2014 demostró que la empresa está dispuesta a jugar duro cuando considera que las regulaciones locales amenazan su modelo de negocio. Una medida similar hoy tendría consecuencias aún más dramáticas, dada la dependencia casi total del ecosistema editorial europeo del tráfico de Google.

El contexto geopolítico añade más complejidad. Las declaraciones públicas de la administración Trump, que ha criticado en varias ocasiones las sanciones europeas contra las empresas tecnológicas estadounidenses, podrían convertir una disputa comercial en un incidente diplomático. Google, al igual que otras grandes tecnológicas estadounidenses, podría invocar la protección política de su propio gobierno, convirtiendo la investigación de la UE en un caso de tensión transatlántica.

Pero quizás la consecuencia más profunda de este asunto no afecte a Google ni a los editores, sino al futuro de la información en línea. Si los usuarios se acostumbran a obtener respuestas sintéticas de la inteligencia artificial sin visitar nunca las fuentes originales, ¿qué incentivo queda para producir contenidos de calidad? Si los editores no pueden monetizar el tráfico orgánico porque Google lo retiene en su propio ecosistema, ¿cómo financiarán el periodismo de investigación?

Estas preguntas no tienen respuestas sencillas. El equilibrio entre la innovación tecnológica y la sostenibilidad del ecosistema informativo es frágil, y cualquier intervención regulatoria corre el riesgo de producir efectos inesperados. Lo que es seguro es que el modelo construido en los últimos veinte años, en el que Google funcionaba como un gran distribuidor universal de tráfico hacia la web abierta, se está disolviendo rápidamente. En su lugar, surge un sistema en el que el acceso a la información está cada vez más mediado por inteligencias artificiales que sintetizan, reelaboran y presentan contenidos sin llevar necesariamente a los usuarios a la fuente.

El reto para los reguladores europeos será encontrar un punto de equilibrio que proteja la competencia sin ahogar la innovación, que tutele a los editores sin cristalizar modelos de negocio obsoletos, que garantice a los usuarios el acceso a información de calidad sin imponer artificialmente formas de navegar por la web que ya no se corresponden con los comportamientos reales.

Mientras tanto, mientras Bruselas y Mountain View se enfrentan en lo que podría revelarse como un largo pulso legal, el ecosistema digital sigue transformándose. Los editores más avispados ya están diversificando las fuentes de tráfico, invirtiendo en boletines informativos directos, comunidades propias y modelos de suscripción. Otros, menos adaptables o simplemente más pequeños, corren el riesgo de ser arrollados por una tormenta perfecta: menos tráfico de Google, más competencia de los contenidos sintéticos generados por la IA y la creciente dificultad de monetizar una atención cada vez más fragmentada.

La verdadera pregunta, al final, no es quién ganará esta batalla legal específica. Es si lograremos construir un ecosistema digital en el que quienes producen información de calidad puedan ser remunerados adecuadamente, en el que las plataformas tecnológicas respondan de cómo ejercen su poder de intermediación y en el que los usuarios mantengan el acceso a una pluralidad de voces y perspectivas. El "juego" entre Bruselas y Mountain View es solo el último capítulo de una transformación que redefinirá profundamente cómo producimos, distribuimos y consumimos información en el siglo XXI.
