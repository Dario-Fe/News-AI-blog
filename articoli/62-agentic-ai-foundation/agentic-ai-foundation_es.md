---
tags: ["Business", "Ethics & Society", "Generative AI"]
date: 2025-12-17
author: "Dario Ferrero"
---

# El Cártel de los Agentes: Cuando el Código Abierto se Convierte en un Monopolio Preventivo
![agentic-ai-foundation.jpg](agentic-ai-foundation.jpg)

*El nueve de diciembre de 2025, la Fundación Linux anunció la creación de la [Agentic AI Foundation](https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/), una iniciativa que reúne a OpenAI, Anthropic y Block bajo la égida de lo que debería ser una gobernanza neutral. Los tres gigantes han donado sus proyectos más estratégicos: el Protocolo de Contexto de Modelo de Anthropic, el marco Goose de Block y AGENTS.md de OpenAI. Acompañan la iniciativa patrocinadores de platino como AWS, Google, Microsoft, Bloomberg y Cloudflare. Una coalición tan amplia que parece casi sospechosa.*

El comunicado oficial habla de "transparencia", "colaboración" e "interés público". Todos términos tranquilizadores que ocultan una pregunta incómoda: ¿por qué ahora? Y, sobre todo, ¿por qué esta prisa por definir estándares para una tecnología que los reguladores todavía están tratando de comprender?

## La Genealogía del Agente Autónomo

Para entender lo que está en juego, es necesario dar un paso atrás. Los agentes de IA no son una novedad teórica: ya en 2023, proyectos experimentales como Auto-GPT demostraban que los modelos de lenguaje podían ser orquestados para ejecutar tareas complejas de forma autónoma. Pero entre un experimento en GitHub y un producto empresarial hay un abismo hecho de fiabilidad, seguridad y, sobre todo, interoperabilidad.

[El Protocolo de Contexto de Modelo](https://www.anthropic.com/news/model-context-protocol), lanzado por Anthropic en noviembre de 2024, representa el primer intento serio de estandarizar cómo los agentes de IA se comunican con sistemas externos. Como explicó David Soria Parra, cocreador de MCP, a [TechCrunch](https://techcrunch.com/2025/12/09/openai-anthropic-and-block-join-new-linux-foundation-effort-to-standardize-the-ai-agent-era/): "El objetivo principal es tener suficiente adopción en el mundo para que se convierta en el estándar de facto". La adopción ha sido rápida: según datos de [GitHub](https://github.blog/open-source/maintainers/mcp-joins-the-linux-foundation-what-this-means-for-developers-building-the-next-era-of-ai-tools-and-agents/), en pocos meses se crearon miles de servidores MCP, con SDK disponibles para todos los principales lenguajes de programación y [más de 97 millones de descargas mensuales](https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation) combinadas para las bibliotecas de Python y TypeScript.

[Goose de Block](https://block.github.io/goose/), lanzado a principios de 2025, adopta una filosofía local-first que hace un guiño a los paranoicos de la privacidad. Como marco de agente que combina modelos de lenguaje con herramientas extensibles e integraciones basadas en MCP, Goose permite a los desarrolladores mantener el control sobre qué se envía y a dónde. Un enfoque que Manik Surtani, responsable de Código Abierto de Block, resumió así en el [lanzamiento de AAIF](https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation): "La tecnología que definirá la próxima década puede permanecer cerrada y propietaria en beneficio de unos pocos, o ser impulsada por estándares abiertos para todos".

[AGENTS.md de OpenAI](https://agents.md/), lanzado en agosto de 2025, es quizás el proyecto más simple pero también el más insidioso. Se trata de un archivo Markdown que los agentes pueden leer para entender cómo operar en un repositorio: convenciones de código, pasos de compilación, requisitos de prueba. [Según OpenAI](https://openai.com/index/agentic-ai-foundation/), más de 60.000 proyectos de código abierto ya lo han adoptado, incluidas herramientas como Cursor, Devin, GitHub Copilot y VS Code. Un número impresionante para un estándar nacido hace apenas cuatro meses.

## Quien Escribe el Protocolo, Escribe la Ley

Y es aquí donde la narrativa oficial comienza a resquebrajarse. Porque esta convergencia coordinada hacia estándares comunes ocurre en un momento muy específico: cuando los reguladores aún no han definido legalmente qué son los agentes de IA autónomos.

La [Ley de IA de la UE](https://artificialintelligenceact.eu/), que entró en vigor en agosto de 2024, fue diseñada antes de que los agentes se generalizaran. Como señala un [informe de The Future Society](https://thefuturesociety.org/aiagentsintheeu/) de junio de 2025, "aunque la Ley de IA no fue diseñada originalmente pensando en los agentes de IA, encontramos que el marco regulatorio más completo del mundo para gobernar la IA se aplica de hecho a los agentes. Pero persisten las lagunas". El problema central es que la Ley clasifica los sistemas de IA basándose en el riesgo estático, mientras que los agentes operan de forma dinámica, adaptándose y tomando decisiones autónomas que pueden variar el nivel de riesgo según el contexto.

Un [artículo en el European Law Blog](https://www.europeanlawblog.eu/pub/dq249o3c/release/1) describe lo que denomina "Soberanía de Herramientas Agénticas": la imposibilidad para los estados y proveedores de mantener un control legal sobre cómo los sistemas de IA invocan y utilizan herramientas transfronterizas de forma autónoma. Imagínese un sistema de reclutamiento en París que en cinco segundos invoca una API psicométrica de EE. UU., un servicio de verificación del Reino Unido, una plataforma de habilidades de Singapur y una herramienta salarial suiza. Tres meses después, cuatro reguladores emiten sanciones. ¿Quién es responsable? El implementador no tenía visibilidad sobre los flujos de datos, los registros de auditoría eran insuficientes, el agente no tenía controles de enrutamiento geográfico.

En septiembre de 2025, el eurodiputado Sergey Lagodinsky pidió formalmente a la Comisión que aclarara "cómo se regularán los agentes de IA". En el momento de escribir este artículo, no se ha emitido ninguna respuesta pública. Este vacío normativo es el campo de juego perfecto para quienes quieren escribir las reglas antes de que lleguen los árbitros.
![annuncio.jpg](annuncio.jpg)
[Imagen del sitio web de la Agentic AI Foundation](https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/)

## Anatomía de una Alianza Estratégica

Los tres proyectos fundacionales de AAIF no se eligen al azar: representan las capas críticas de la infraestructura de agentes. MCP define cómo los agentes hablan con el mundo exterior. AGENTS.md estandariza cómo los agentes comprenden los contextos de trabajo. Goose demuestra cómo estas piezas se ensamblan en un marco funcional. Juntos, cubren toda la pila tecnológica.

La donación a la Fundación Linux suena noble, pero plantea interrogantes sobre la gobernanza real. La Fundación Linux tiene una historia controvertida con la influencia corporativa. Como informó [The New Stack](https://thenewstack.io/linux-foundation-critics/) ya en 2021, la fundación eliminó de sus estatutos la posibilidad de que miembros de la comunidad fueran elegidos para la junta, dejando el control exclusivamente a los patrocinadores corporativos. Matthew Garrett, colaborador del kernel de Linux, [denunció](https://techrights.org/o/2016/01/21/linux-foundation-coup/) este cambio como un abandono de la representación comunitaria.

Jim Zemlin, director ejecutivo de la Fundación Linux, [declaró](https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation) que "un indicador temprano de éxito, más allá de la adopción de estos estándares, sería el desarrollo y la implementación de estándares compartidos utilizados por agentes de proveedores en todo el mundo". Pero, ¿quién decide qué estándares se deben implementar? ¿Los miembros de platino que pagan cientos de miles de dólares al año, o la comunidad que desarrolla las herramientas?

Nick Cooper de OpenAI afirmó en [TechCrunch](https://techcrunch.com/2025/12/09/openai-anthropic-and-block-join-new-linux-foundation-effort-to-standardize-the-ai-agent-era/) que "no quiero que sea algo estancado. No quiero que estos protocolos formen parte de esta fundación y se queden ahí durante dos años. Deberían evolucionar y aceptar continuamente más aportes". Palabras bonitas, pero la historia del software de código abierto enseña que quien controla a los mantenedores y financia el desarrollo determina la dirección del proyecto.

## Lo que está en juego

Las implicaciones económicas son enormes. Los analistas predicen que el mercado de los agentes de IA autónomos alcanzará decenas de miles de millones de dólares en los próximos años, con aplicaciones que van desde la gestión de correos electrónicos hasta la navegación web compleja. Quien controla los estándares controla los peajes: ¿qué empresa querrá invertir en un sistema de agente propietario cuando el ecosistema se consolide en torno a MCP, AGENTS.md y similares?

Microsoft y GitHub [anunciaron](https://www.tekedia.com/microsoft-and-github-join-forces-with-anthropic-to-expand-ai-ecosystem-via-model-context-protocol/) en mayo de 2025 que se unían al comité directivo de MCP, trayendo consigo el acceso al sistema de archivos de Windows, funcionalidades de ventanas y el Subsistema de Windows para Linux a través de servidores MCP. GitHub está desarrollando un servicio de registro para MCP. Cuando los gigantes tecnológicos alinean sus infraestructuras en torno a un protocolo, este se convierte de facto en el estándar, independientemente de cuán "abierto" sea sobre el papel.

Como señala un [análisis crítico en Implicator](https://www.implicator.ai/the-agentic-ai-foundation-is-a-trade-bloc-disguised-as-open-governance/), AAIF se parece más a un bloque comercial disfrazado de gobernanza abierta. Las membresías de pago crean una jerarquía donde quien paga más tiene más voz. Los miembros de platino incluyen exactamente a las empresas que más tienen que ganar con la consolidación del mercado de agentes bajo estándares que ellas mismas han ayudado a crear.

## La Inversión del Proceso de Estandarización

Hay un detalle que se escapa en la narrativa oficial, pero que cualquiera que haya vivido los años noventa reconoce de inmediato: el proceso está invertido. Cuando nació Internet, los estándares iban primero. Las Solicitudes de Comentarios (RFC) eran documentos rigurosos, discutidos públicamente, que definían protocolos como TCP/IP, HTTP, SMTP antes de que existiera un mercado. Aguas abajo, las empresas implementaban esos estándares. Era un proceso de abajo hacia arriba donde ingenieros y académicos definían la arquitectura y el mercado seguía.

Con AAIF asistimos a lo contrario: primero las empresas construyen los protocolos propietarios (MCP nace dentro de Anthropic, AGENTS.md dentro de OpenAI, Goose dentro de Block), luego ven que tienen tracción y, finalmente, se unen en una fundación "abierta" para cristalizar su ventaja de ser los primeros en moverse. No están creando estándares neutrales desde cero, están legitimando protocolos ya implementados en millones de sistemas. Es una estandarización post-facto, donde la adopción precede a la gobernanza.

Pero hay un segundo aspecto aún más inquietante: la geografía. Todos los fundadores de AAIF son estadounidenses. La Fundación Linux tiene su sede en San Francisco. Los patrocinadores de platino son todos occidentales, con predominio de Estados Unidos. Sin embargo, China está invirtiendo masivamente en IA agéntica: según un [informe de McKinsey de 2025](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai), las empresas chinas representan el 15% de las inversiones globales en IA y están desarrollando sus propios marcos para agentes autónomos. Alibaba, Baidu, Tencent tienen todos proyectos internos sobre agentes. ¿Por qué ninguno de ellos está en AAIF?

Una posible lectura es que AAIF no es realmente una iniciativa global, sino un bloque occidental que intenta establecer estándares antes de que los actores chinos puedan proponer alternativas. Es la misma dinámica que se vio con el 5G, donde Estados Unidos y Europa presionaron para excluir a Huawei de las redes críticas. La diferencia es que aquí no hablamos de infraestructura física, sino de protocolos de software, mucho más difíciles de controlar una vez que son de código abierto. Si mañana Alibaba lanzara un protocolo de agente incompatible con MCP pero técnicamente superior, y el ecosistema chino lo adoptara masivamente, AAIF correría el riesgo de volverse irrelevante fuera de Occidente.

Es una manifestación más de la balcanización tecnológica: un mundo, dos Internet, dos conjuntos de estándares de IA. Y como siempre sucede en estos escenarios, quien paga el precio es la interoperabilidad global que estos mismos estándares declaran querer preservar.

## El Vacío Normativo como Oportunidad

Y aquí llegamos al punto crucial: ¿es posible que detrás de la retórica de la interoperabilidad abierta, AAIF represente un ataque preventivo a los estándares antes de que los reguladores puedan establecer las reglas? Esta es mi hipótesis, pero consideren los tiempos. La Ley de IA de la UE se está implementando con lagunas evidentes sobre los agentes. EE. UU. todavía no tiene una regulación federal integral sobre IA. En este vacío normativo, los gigantes tecnológicos están de facto escribiendo el reglamento antes de que lleguen los árbitros.

Un [informe del Centro de Estudios de Política Europea](https://babl.ai/new-report-urges-eu-to-clarify-governance-of-ai-agents-under-ai-act/) advierte que los agentes de IA podrían "escapar por completo a la regulación o conducir a una aplicación fragmentada en toda la UE". Las [implicaciones para la privacidad son profundas](https://www.mhc.ie/latest/insights/rise-of-the-helpful-machines): el RGPD no menciona explícitamente a los agentes, pero su capacidad para recopilar y procesar de forma autónoma enormes cantidades de datos personales plantea interrogantes sobre quién es el controlador de los datos cuando un sistema actúa de forma autónoma.

Los riesgos de seguridad son igualmente preocupantes. Los agentes introducen nuevas superficies de ataque: inyección de prompts a través de datos externos, fuga de información personal, manipulación de modelos, envenenamiento de datos a través de bucles de retroalimentación comprometidos. [HiddenLayer](https://hiddenlayer.com/innovation-hub/governing-agentic-ai/), una empresa de seguridad de IA, señala que estos sistemas "ponen a prueba los límites de la regulación existente" y que "el cumplimiento no es una casilla que marcar, es una ventaja competitiva en la era de la IA autónoma".

Pero si los estándares técnicos ya han sido definidos por los proveedores a través de AAIF, los reguladores tendrán pocas opciones: adaptarse a los estándares existentes o arriesgarse a sofocar la innovación al exigir cambios incompatibles con el ecosistema ya consolidado. Es la misma dinámica que hizo que el RGPD fuera tan difícil de aplicar a las plataformas sociales: cuando las arquitecturas técnicas ya están desplegadas, cambiarlas se vuelve prohibitivo.

## Hacia un Futuro Centrado en Agentes

No todo es oscuro. Los estándares abiertos han acelerado históricamente la innovación al permitir que los jugadores más pequeños compitan sin tener que reinventar la infraestructura. MCP podría reducir efectivamente la fragmentación del ecosistema, AGENTS.md podría hacer que el comportamiento de los agentes sea más predecible, Goose podría demostrar que lo local-first es posible. La Fundación Linux, a pesar de las críticas, tiene una larga historia de administración de proyectos críticos como Kubernetes y Node.js.

Pero se necesita un ojo crítico. Como observó Neal Stephenson en "Snow Crash", cuando los protocolos privados gobiernan espacios compartidos, quien controla los protocolos controla de facto esos espacios. AAIF podría ser genuinamente una iniciativa para el bien común, o podría ser el equivalente tecnológico de repartirse un territorio antes de que llegue la ley.

Las preguntas que hay que hacerse son simples: ¿quién tiene poder de decisión real en AAIF? ¿Cómo se resuelven los conflictos entre corporaciones miembro con intereses competitivos? ¿Qué mecanismos existen para garantizar que los estándares sirvan a los usuarios finales y no solo a los intereses comerciales de los fundadores? Y, sobre todo: ¿se involucrará a los reguladores en el proceso de definición de estándares, o se encontrarán teniendo que ratificar decisiones ya tomadas?

Jim Zemlin de la Fundación Linux [sostiene](https://techcrunch.com/2025/12/09/openai-anthropic-and-block-join-new-linux-foundation-effort-to-standardize-the-ai-agent-era/) que "el dominio surge del mérito y no del control del proveedor", citando a Kubernetes como ejemplo. Pero Kubernetes surgió cuando el campo estaba abierto. AAIF está intentando definir estándares cuando los fundadores ya son los principales actores del mercado.

El tiempo dirá si AAIF se convertirá en la infraestructura neutral que promete ser, o si resultará ser un cártel bien empaquetado donde el código abierto se convierte en una herramienta de monopolio preventivo. Por ahora, mientras las empresas de tecnología escriben los protocolos y los reguladores todavía estudian el problema, una cosa es segura: quien define el lenguaje, define luego la ley. Y en este momento, el lenguaje lo están definiendo OpenAI, Anthropic y Block, con el imprimátur de la Fundación Linux y la financiación de los gigantes tecnológicos. Pregúntense: ¿es realmente en interés del público, o es una alianza estratégica disfrazada de benevolencia?
