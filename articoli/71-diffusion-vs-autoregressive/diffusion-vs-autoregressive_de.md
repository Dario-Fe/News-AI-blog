---
tags: ["Research", "Training", "Generative AI"]
date: 2026-01-07
author: "Dario Ferrero"
---

# Diffusion vs. Autoregression: Ein Blick unter die Haube von LLMs
![diffusion-vs-autoregressive.jpg](diffusion-vs-autoregressive.jpg)

*Es gibt ein Experiment, das die verborgenen Grenzen der fortschrittlichsten Sprachmodelle aufdeckt: Bitten Sie GPT-4, ein klassisches chinesisches Gedicht zu vervollständigen. Wenn Sie die erste Zeile angeben, erhalten Sie die zweite mit beeindruckender Genauigkeit. Kehren Sie jedoch die Anfrage um, indem Sie mit der zweiten Zeile beginnen, um die erste zu erhalten, und die Genauigkeit fällt von über achtzig Prozent auf vierunddreißig. Dieses Phänomen, von Forschern als ["Umkehrfluch"](https://arxiv.org/abs/2309.12288) bezeichnet, ist kein Fehler, sondern eine direkte Folge des autoregressiven Paradigmas, das das gesamte Ökosystem der zeitgenössischen LLMs beherrscht.*

Die Autoregression, die Technik, die das nächste Token auf der Grundlage der vorhergehenden vorhersagt und dabei streng von links nach rechts vorgeht, hat seit dem ursprünglichen GPT bis zu den neuesten Modellen unangefochten dominiert. Es ist ein Ansatz, der in seiner kausalen Linearität verfeinert, aber von Natur aus asymmetrisch ist. Wie ein Leser, der gezwungen ist, nur vorwärts und niemals zurück zu lesen, konstruieren diese Modelle Bedeutung in nur eine Richtung.

Jetzt jedoch taucht eine Familie alternativer Techniken aus den Falten der akademischen Forschung auf und schlägt ein radikal anderes Paradigma vor. Sie werden als Diffusionsmodelle für natürliche Sprache bezeichnet, und anstatt Text als kausale Kette zu erzeugen, verfeinern sie ihn schrittweise von Rauschen zu Kohärenz, Token für Token, aber parallel, ohne gerichtete Einschränkungen. Dies ist der Ansatz, der die Bilderzeugung mit Stable Diffusion und DALL-E revolutioniert hat und nun auf den diskreten Bereich der Wörter angewendet wird.

## Vom Rauschen zur Kohärenz

Um die auf Text angewendete Diffusion zu verstehen, müssen wir die lineare Intuition der Autoregression aufgeben. Stellen Sie sich einen vollständig verdeckten Satz vor, bei dem jedes Wort durch ein spezielles Maskierungstoken ersetzt wurde. Das Modell muss die gesamte Äußerung nicht von links nach rechts rekonstruieren, sondern indem es alle maskierten Token gleichzeitig vorhersagt und dann die weniger sicheren Vorhersagen iterativ verfeinert.

Der Prozess gliedert sich in zwei komplementäre Phasen. Während der Vorwärtsphase fügt das System der Textsequenz schrittweise Rauschen hinzu, indem es Token mit zunehmender Wahrscheinlichkeit maskiert, bis der ursprüngliche Satz in reines Rauschen umgewandelt ist. Die Rückwärtsphase kehrt diesen Prozess um: Ausgehend von einer vollständig maskierten Sequenz sagt das Modell iterativ die fehlenden Token voraus und beseitigt nach und nach die Unsicherheit, bis es zu einem kohärenten Text konvergiert.

[LLaDA](https://arxiv.org/html/2502.09992v1), das ehrgeizigste Experiment in dieser Richtung, das im Januar 2025 vorgestellt wurde, skalierte diese Architektur auf bis zu acht Milliarden Parameter und wurde mit 2,3 Billionen Token trainiert. Es ist nicht der erste Versuch, die Diffusion in den sprachlichen Bereich zu bringen, aber es ist der erste, der eine wirklich wettbewerbsfähige Leistung mit autoregressiven Modellen derselben Größenordnung erzielt. Die Forscher folgten dem Standardprotokoll des Pre-Trainings und des überwachten Fine-Tunings und zeigten, dass die für LLMs typischen emergenten Fähigkeiten (In-Context-Learning, Instruction-Following, Reasoning) nicht ausschließlich der Autoregression vorbehalten sind, sondern allgemeinere Eigenschaften der groß angelegten generativen Modellierung darstellen.

Die zugrunde liegende mathematische Formulierung unterscheidet sich grundlegend. Während die Autoregression die gemeinsame Wahrscheinlichkeit in ein Produkt streng geordneter bedingter Wahrscheinlichkeiten zerlegt, konstruieren Diffusionsmodelle die Verteilung durch einen reversiblen stochastischen Prozess. Das [SEDD-Modell](https://arxiv.org/abs/2310.16834) (Score Entropy Discrete Diffusion), Gewinner des Best Paper Award auf der ICML 2024, formalisierte diesen Ansatz durch die Einführung der "Score-Entropie", einer Verlustfunktion, die das Score-Matching elegant auf den diskreten Bereich erweitert. SEDD übertraf frühere Diffusionsparadigmen, indem es die Perplexität um fünfundzwanzig bis fünfundsiebzig Prozent reduzierte und sogar GPT-2 auf vergleichbaren Datensätzen übertraf.

## Wenn Parallelität die Sequenzialität schlägt

Die theoretischen Vorteile der Diffusion führen zu messbaren praktischen Vorteilen, auch wenn das Bild nuancierter ist, als es akademische Schlagzeilen vermuten lassen. LLaDA zeigt eine beeindruckende Skalierbarkeit bis zu 10²³ FLOPs und erzielt Ergebnisse, die mit autoregressiven Baselines vergleichbar sind, die auf denselben Daten trainiert wurden. Auf Standard-Benchmarks wie MMLU und GSM8K konkurriert das Acht-Milliarden-Parameter-Modell direkt mit LLaMA3 derselben Größe und übertrifft LLaMA2 7B fast vollständig, obwohl es auf einem Bruchteil der Daten trainiert wurde (2,3 Billionen gegenüber fünfzehn Billionen Token).

Der deutlichste Unterschied zeigt sich bei Aufgaben, die bidirektionales Denken erfordern. Bei der umgekehrten Gedichtvervollständigungsaufgabe behält LLaDA eine Genauigkeit von zweiundvierzig Prozent in beide Richtungen bei, während GPT-4o von dreiundachtzig auf vierunddreißig Prozent abstürzt. Das ist keine Magie, sondern architektonische Konsistenz: Ohne intrinsische Richtungsneigungen behandelt das Modell alle Token einheitlich, was zu einer natürlich robusteren Leistung bei symmetrischen Aufgaben führt.

Die Fähigkeit zum kontrollierten Infilling ist ein weiterer entscheidender Vorteil. Autoregressive Modelle können gezwungen werden, Lücken zu füllen, benötigen aber spezifische Architekturen oder dedizierte Trainingstricks. Für die Diffusion ist das Infilling nativ: Man muss nur den Zielbereich maskieren und das Modell ihn unter Berücksichtigung des umgebenden Kontexts rekonstruieren lassen. SEDD zeigt eine vergleichbare Qualität wie das autoregressive Nucleus-Sampling und ermöglicht gleichzeitig Generierungsstrategien, die für streng von links nach rechts gerichtete Ansätze unmöglich sind.

Es gibt jedoch einen rechnerischen Nachteil. Die Diffusionsgenerierung erfordert mehrere Entrauschungsschritte, jeder mit einem Vorwärtsdurchlauf durch das gesamte Netzwerk. LLaDA verwendet typischerweise sechzehn bis zweiunddreißig Schritte, was zu einer deutlich höheren Latenz im Vergleich zur Token-für-Token-Autoregression auf Consumer-Hardware führt. SEDD hat die Möglichkeit eines Kompromisses zwischen Rechenaufwand und Qualität gezeigt und erreicht eine vergleichbare Qualität mit zweiunddreißigmal weniger Netzwerk-Auswertungen, aber es bleibt ein Bereich, in dem eine hardwarebewusste Optimierung für den realen Einsatz entscheidend wird.

Das Training selbst stellt spezifische Herausforderungen dar. Die mehrstufige Optimierung der diskreten Diffusion ist von Natur aus komplexer als der autoregressive Verlust und erfordert numerische Stabilität und eine genaue Abstimmung der Rauschpläne. Frühe Modelle wie [Diffusion-LM](https://arxiv.org/abs/2205.14217) aus dem Jahr 2022 hatten gerade wegen dieser technischen Hürden Schwierigkeiten, über bescheidene Größen hinaus zu skalieren. LLaDA und SEDD haben viele dieser Probleme durch solidere theoretische Formulierungen und sorgfältiges Engineering gelöst, aber die Lernkurve für diejenigen, die von Grund auf implementieren, bleibt steil.
![esempio1.jpg](esempio1.jpg)
[Bild von arxiv.org](https://arxiv.org/html/2309.12288v4)

## Die Ironie der Kreuzkonvergenz

Die jüngste Geschichte der multimodalen Erzeugung weist eine fast Dickens'sche Ironie auf. Während Sprachmodelle zaghaft die Diffusion erforschen, macht die Bilderzeugung den umgekehrten Weg zur Autoregression. [VAR](https://arxiv.org/abs/2404.02905) (Visual Autoregressive Modeling), vorgestellt im Jahr 2024, gewann den Best Paper Award auf der NeurIPS, indem es gerade Diffusionsmodelle wie Stable Diffusion schlug. Der Ansatz greift die Autoregression wieder auf, jedoch auf einer Hierarchie progressiver Auflösungen, und kombiniert die Vorteile der sequentiellen Vorhersage mit der visuellen Qualität, die die Diffusion berühmt gemacht hatte.

Projekte wie [LlamaGen](https://arxiv.org/abs/2406.06525) treiben dieses Revival weiter voran und zeigen, dass die Autoregression bei entsprechender Architektur eine hochmoderne Qualität in der visuellen Erzeugung erreichen kann. Es ist eine Mahnung, dass kein einziges Paradigma das Monopol auf Wirksamkeit besitzt und dass die besten Techniken aus einem kontinuierlichen Dialog zwischen scheinbar widersprüchlichen Ansätzen entstehen.

Diese Kreuzkonvergenz deutet darauf hin, dass die Zukunft möglicherweise nicht einem einzigen Paradigma gehört, sondern hybriden Architekturen, die die Stärken beider kombinieren. Einige Forscher untersuchen Modelle, die Autoregression zur Erfassung von Langstreckenabhängigkeiten und Diffusion zur lokalen Verfeinerung verwenden oder die je nach generativem Kontext adaptiv zwischen den beiden Modi wechseln.

Der Bereich der Multimodalität könnte das ultimative Testfeld sein. Ein Modell, das gleichzeitig Bilder und beschreibenden Text erzeugt, könnte von der Diffusion für den kontinuierlichen visuellen Bereich und der Autoregression für die syntaktische Struktur der Sprache profitieren oder umgekehrt. [DIFFA](https://arxiv.org/html/2507.18452v3), ein Diffusionsexperiment für Audio, hat gezeigt, dass sich diese Prinzipien auch effektiv auf den akustischen Bereich übertragen lassen, was Perspektiven für wirklich multimodale Systeme eröffnet, die auf diffusiven Grundlagen aufbauen.

## Offene Fragen und zukünftige Trajektorien

Die industrielle Akzeptanz bleibt die große Frage. LLaDA und SEDD sind brillante akademische Proof-of-Concepts, aber noch kein großes Technologieunternehmen hat ein sprachliches Diffusionsmodell in der Produktion eingesetzt. Die Gründe sind pragmatisch: Die Inferenzinfrastruktur ist für Autoregression optimiert, mit dedizierter Hardware (TPUs, Inferentia), spezialisierten CUDA-Kernen für kausale Aufmerksamkeit und über Jahre hinweg im realen Einsatz erprobten Serving-Frameworks.

Diesen Stack für die Diffusion neu zu schreiben, erfordert eine massive Investition ohne Garantie auf einen höheren ROI. Die Latenz bleibt für Echtzeitanwendungen wie Konversations-Chatbots problematisch, bei denen jede Millisekunde Verzögerung das Benutzererlebnis beeinträchtigt. Solange Diffusionsmodelle keinen klaren Vorteil in Bezug auf Genauigkeit oder Kosten nachweisen, der eine vollständige Portierung rechtfertigt, werden sie auf die Forschung beschränkt bleiben.

Die Frage der extremen Skalierbarkeit bleibt offen. LLaDA mit acht Milliarden Parametern ist respektabel, aber weit entfernt von den Hundert- bis Fünfhundert-Milliarden-Giganten, die den Markt beherrschen. Skalierungsgesetze wurden für die Autoregression intensiv untersucht, bleiben aber für die sprachliche Diffusion weitgehend unerforscht. Wird eine lineare Skalierung möglich sein oder werden bei größeren Maßstäben unvorhergesehene Engpässe auftreten?

Algorithmische Verzerrungen stellen einen dringenden Forschungsbereich dar. Die Autoregression erbt Richtungsneigungen aus dem Links-nach-Rechts-Pre-Training, die sich auf dokumentierte und (teilweise) abschwächbare Weise manifestieren. Die Diffusion führt unterschiedliche Verzerrungsmuster ein, die mit dem Entrauschungsprozess und den Rauschplänen zusammenhängen. Wie sich diese Verzerrungen nachgelagert in Anwendungen ausbreiten und welche Alignment-Techniken am besten funktionieren, sind weitgehend unerforschte Fragen.

Die Integration mit Reinforcement Learning nach dem Training ist noch im Anfangsstadium. LLaDA hat nur ein überwachtes Fine-Tuning erhalten, ohne die RLHF- oder DPO-Ausrichtung, die Modelle wie GPT-4 und Claude von statistischen Prädiktoren in nützliche Assistenten verwandelt hat. Die Ausweitung dieser Protokolle auf die Diffusion erfordert ein Umdenken bei der Gestaltung von Belohnungen und der Optimierung von Richtlinien in nicht-autoregressiven Kontexten, ein nicht-triviales theoretisches Problem.

Die Wettbewerbslandschaft zersplittert sich. Neben den Industriegiganten, die auf etablierten Architekturen iterieren, erforschen akademische Labore und Startups radikale Alternativen. Die Diffusion ist nur eine dieser Richtungen: Es entstehen auch Ansätze, die auf Flow Matching basieren, hybride symbolisch-neuronale Modelle und völlig neue Architekturen wie Mamba, die die Aufmerksamkeit durch effiziente rekurrente Mechanismen ersetzen.

In diesem pluralistischen Ökosystem positioniert sich die sprachliche Diffusion als eine Wette mit hohem Risiko und hohem Ertrag. Wenn es ihr gelänge, entscheidende Vorteile in bestimmten Bereichen (kontrollierte Bearbeitung, auf Einschränkungen basierende Erzeugung, komplexe kompositionelle Aufgaben) nachzuweisen, könnte sie bedeutende Nischen erobern, ohne die Autoregression zwangsläufig von ihrem allgemeinen Thron zu stoßen. Sollte sie sich hingegen als rechnerische Sackgasse erweisen, bliebe sie ein faszinierendes, aber abgeschlossenes Kapitel in der Geschichte der generativen künstlichen Intelligenz.

Die Antwort wird nicht aus den Papieren kommen, sondern aus den eingesetzten Systemen, aus realen Benchmarks, aus der tatsächlichen industriellen Akzeptanz. In der Zwischenzeit lohnt es sich, die Augen offen zu halten. Wie jede Geschichte der technologischen Disruption lehrt, scheinen dominante Paradigmen unbesiegbar, bis sie es nicht mehr sind. Und dieser Moment kommt immer dann, wenn jemand beweist, dass die Alternative nicht nur theoretisch elegant, sondern praktisch überlegen ist, wo es wirklich darauf ankommt.
