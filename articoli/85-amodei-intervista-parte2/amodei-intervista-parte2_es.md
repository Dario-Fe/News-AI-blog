---
tags: ["Ethics & Society", "Security", "Business"]
date: 2026-02-09
author: "Dario Ferrero"
---

# Dario Amodei y la adolescencia tecnológica de la humanidad - Parte 2
![amodei-intervista-parte2.jpg](amodei-intervista-parte2.jpg)

*Retomamos y terminamos, con esta segunda entrega, la larga conversación simulada con Dario Amodei, CEO de Anthropic, reconstruida a partir de las reflexiones publicadas en su último ensayo "The Adolescence of Technology". Un recurso narrativo para hacer más inmediato el mensaje urgente que Amodei quiere lanzar: la humanidad está entrando en un paso crítico que podría definirse en los próximos dos años.*

---

**¿Quién te preocupa más, en orden de gravedad?**

El Partido Comunista Chino. China es la segunda después de Estados Unidos en capacidades de IA y es el país con mayor probabilidad de superar a Estados Unidos en dichas capacidades. Su gobierno es actualmente autocrático y opera un estado de vigilancia de alta tecnología. Ya ha desplegado vigilancia basada en IA, incluida la represión de los uigures, y se cree que emplea propaganda algorítmica a través de TikTok, además de sus muchos otros esfuerzos de propaganda internacional. Claramente tienen el camino más directo hacia la pesadilla totalitaria habilitada por la IA que he descrito. Incluso podría ser el resultado por defecto dentro de China, así como dentro de otros estados autocráticos a los que el PCCh exporta tecnología de vigilancia. He escrito a menudo sobre la amenaza de que el PCCh tome la delantera en la IA y sobre el imperativo existencial de evitar que lo hagan. Por eso. Para ser claros, es el propio pueblo chino el que tiene más probabilidades de sufrir la represión habilitada por la IA del PCCh, y no tienen voz en las acciones de su gobierno. Admiro y respeto profundamente al pueblo chino y apoyo a los muchos valientes disidentes dentro de China y su lucha por la libertad.

Luego están las democracias competitivas en la IA. Como he escrito, las democracias tienen un interés legítimo en ciertas herramientas militares y geopolíticas potenciadas por la IA, porque los gobiernos democráticos ofrecen la mejor oportunidad de contrarrestar el uso de estas herramientas por parte de las autocracias. En general, estoy a favor de armar a las democracias con las herramientas necesarias para derrotar a las autocracias en la era de la IA, simplemente no creo que haya otra manera. Pero no podemos ignorar el potencial de abuso de estas tecnologías por parte de los propios gobiernos democráticos. Las democracias normalmente tienen salvaguardias que impiden que su aparato militar y de inteligencia se vuelva hacia el interior contra su propia población, pero debido a que las herramientas de IA requieren tan pocas personas para operar, existe el potencial de que puedan eludir estas salvaguardias y las normas que las sustentan.

Luego los países no democráticos con grandes centros de datos y, finalmente, las propias empresas de IA. Es un poco vergonzoso decirlo como CEO de una empresa de IA, pero creo que el siguiente nivel de riesgo son en realidad las propias empresas de IA. Las empresas de IA controlan grandes centros de datos, entrenan modelos de frontera, tienen la mayor experiencia sobre cómo usar esos modelos y, en algunos casos, tienen contacto diario y la posibilidad de influir en decenas o cientos de millones de usuarios. Lo principal que les falta es la legitimidad e infraestructura de un estado. Creo que la gobernanza de las empresas de IA merece mucho escrutinio.

**¿Cómo nos defendemos de estos riesgos multiformes?**

No deberíamos vender chips, herramientas para fabricar chips o centros de datos al PCCh en absoluto. Los chips y las herramientas para fabricar chips son el mayor cuello de botella para una IA potente, y bloquearlos es una medida simple pero extremadamente efectiva, tal vez la acción más importante que podemos tomar. No tiene sentido vender al PCCh las herramientas con las que construir un estado totalitario de IA y posiblemente conquistarnos militarmente. China está varios años por detrás de Estados Unidos en su capacidad para producir chips de frontera en cantidad, y el período crítico para construir el país de genios en el centro de datos es muy probablemente dentro de esos próximos años.

En segundo lugar, tiene sentido usar la IA para potenciar a las democracias para que resistan a las autocracias. Esta es la razón por la que Anthropic considera importante proporcionar IA a las comunidades de inteligencia y defensa en Estados Unidos y sus aliados democráticos. Defender democracias bajo ataque, como Ucrania y Taiwán, parece una prioridad particularmente alta, al igual que potenciar a las democracias para que usen sus servicios de inteligencia para desestabilizar y degradar a las autocracias desde dentro.

En tercer lugar, debemos trazar una línea dura contra los abusos de la IA dentro de las democracias. La formulación que he desarrollado es que deberíamos usar la IA para la defensa nacional en todos los sentidos, excepto en aquellos que nos harían más parecidos a nuestros adversarios autocráticos. Usar la IA para la vigilancia masiva doméstica y la propaganda masiva me parecen fronteras infranqueables y completamente ilegítimas. Las armas completamente autónomas y la IA para la toma de decisiones estratégicas son líneas más difíciles de trazar, ya que tienen usos legítimos en la defensa de la democracia, al tiempo que son propensas al abuso. Aquí creo que lo que se justifica es una precaución y un control extremos combinados con salvaguardias para prevenir el abuso.

En cuarto lugar, después de haber trazado una línea dura contra los abusos de la IA en las democracias, deberíamos usar ese precedente para crear un tabú internacional contra los peores abusos de la IA potente. El mundo debe comprender el potencial oscuro de la IA potente en manos de los autócratas y reconocer que ciertos usos de la IA equivalen a un intento de robar permanentemente su libertad e imponer un estado totalitario del que no pueden escapar. Incluso argumentaría que, en algunos casos, la vigilancia a gran escala con IA potente, la propaganda masiva con IA potente y ciertos tipos de usos ofensivos de armas completamente autónomas deberían considerarse crímenes contra la humanidad.

**Cuarto riesgo: la destrucción económica. Es el tema central de La pianola (Player Piano) de Vonnegut: cuando las máquinas lo hacen todo, ¿qué les queda a los humanos?**

Exactamente esa resonancia. En 2025 advertí públicamente que la IA podría desplazar a la mitad de todos los trabajos administrativos (white collar) de nivel de entrada en los próximos uno a cinco años, incluso mientras acelera drásticamente el crecimiento económico y el progreso científico. Esto inició un debate público. Muchos CEO, tecnólogos y economistas estuvieron de acuerdo, pero otros asumieron que estaba cayendo presa de una falacia de la "cantidad fija de trabajo" (lump of labor) y que no entendía cómo funcionan los mercados laborales, y algunos no vieron el rango de tiempo de uno a cinco años y pensaron que estaba afirmando que la IA está desplazando trabajos ahora mismo, algo que acepto que probablemente no esté sucediendo. Vale la pena examinar en detalle por qué me preocupa el desplazamiento laboral.

El ritmo del progreso en la IA es mucho más rápido que las revoluciones tecnológicas anteriores. En los últimos dos años, los modelos de IA han pasado de apenas poder completar una sola línea de código a escribir todo o casi todo el código para algunas personas, incluidos ingenieros en Anthropic. Incluso programadores legendarios se describen cada vez más a sí mismos como "atrasados". Pronto los modelos podrían realizar toda la tarea de un ingeniero de software de extremo a extremo. Es difícil para las personas adaptarse a este ritmo de cambio, tanto a los cambios en cómo funciona un trabajo determinado como a la necesidad de pasar a nuevos trabajos. En todo caso, el ritmo puede seguir acelerándose a medida que los modelos de codificación de IA aceleren cada vez más la tarea del desarrollo de la IA. Para ser claros, la velocidad en sí misma no significa que los mercados laborales y el empleo no se recuperen eventualmente; solo significa que la transición a corto plazo será inusualmente dolorosa.

La amplitud cognitiva es el segundo factor: la IA será capaz de una gama muy amplia de habilidades cognitivas humanas, tal vez todas ellas. Esto es muy diferente de las tecnologías anteriores como la agricultura mecanizada, el transporte o incluso las computadoras. Esto dificultará que las personas pasen fácilmente de trabajos que son reemplazados a trabajos similares para los que serían aptas. Las habilidades intelectuales generales requeridas para trabajos de nivel de entrada en, digamos, finanzas, consultoría y derecho son bastante similares, incluso si el conocimiento específico es bastante diferente. Una tecnología que interrumpa solo uno de los tres permitiría a los empleados pasar a los dos sustitutos cercanos, o a aquellos menos preparados cambiar de especialidad. Pero interrumpir los tres simultáneamente, junto con muchos otros trabajos similares, podría ser más difícil de adaptar para las personas. Además, no es solo que la mayoría de los trabajos existentes se verán interrumpidos. Esto ya ha sucedido antes: la agricultura era un porcentaje enorme del empleo. Pero los agricultores podían pasar al trabajo relativamente similar de operar maquinaria de fábrica, aunque ese trabajo no hubiera sido común antes. Por el contrario, la IA satisface cada vez más el perfil cognitivo general de los humanos, lo que significa que también será buena en los nuevos trabajos que ordinariamente se crearían en respuesta a los antiguos que se automatizan. Otra forma de decirlo es que la IA no es un sustituto para trabajos humanos específicos, sino más bien un sustituto general del trabajo para los humanos.

Tercer factor: la selección basada en las capacidades cognitivas. A través de una amplia gama de tareas, la IA parece avanzar desde la parte inferior de la escala de habilidades hacia la superior. Por ejemplo, en la codificación nuestros modelos han pasado del nivel de "programador mediocre" a "programador fuerte" a "programador muy fuerte". Ahora estamos empezando a ver la misma progresión en el trabajo administrativo en general. Por lo tanto, corremos el riesgo de una situación en la que, en lugar de afectar a personas con habilidades específicas o en profesiones específicas que pueden adaptarse mediante el reentrenamiento, la IA está afectando a personas con ciertas propiedades cognitivas intrínsecas, a saber, menor capacidad intelectual, que es más difícil de cambiar. No está claro a dónde irán estas personas o qué harán, y me preocupa que puedan formar una "clase baja" desempleada o con salarios muy bajos. Para ser claros, cosas algo similares a esto han sucedido antes, por ejemplo, algunos economistas creen que las computadoras e Internet representan un "cambio tecnológico que favorece a los trabajadores cualificados". Pero este sesgo de habilidades (skill biasing) no fue tan extremo como lo que espero ver con la IA, y se cree que contribuyó a un aumento de la desigualdad salarial, por lo que no es exactamente un precedente alentador.

Cuarto: la capacidad de llenar los vacíos. La forma en que los trabajos humanos a menudo se adaptan ante las nuevas tecnologías es que hay muchos aspectos del trabajo, y la nueva tecnología, aunque parece reemplazar directamente a los humanos, a menudo tiene lagunas. Si alguien inventa una máquina para fabricar piezas, los humanos aún podrían tener que cargar materia prima en la máquina. Incluso si esto requiere solo el uno por ciento del esfuerzo de fabricar las piezas manualmente, los trabajadores humanos simplemente pueden fabricar cien veces más piezas. Pero la IA, además de ser una tecnología que avanza rápidamente, también es una tecnología que se adapta rápidamente. Durante cada lanzamiento de modelo, las empresas de IA miden cuidadosamente en qué es bueno el modelo y en qué no, y los clientes también proporcionan dicha información después del lanzamiento. Las debilidades pueden abordarse recopilando tareas que encarnen la brecha actual y entrenando en ellas para el próximo modelo. Al principio de la IA generativa, los usuarios notaron que los sistemas de IA tenían ciertas debilidades, como los modelos de imágenes de IA que generaban manos con el número incorrecto de dedos, y muchos asumieron que estas debilidades eran intrínsecas a la tecnología. Si lo hubieran sido, habrían limitado la interrupción de los trabajos. Pero prácticamente cada una de estas debilidades se aborda rápidamente, a menudo en pocos meses.

**¿Cuáles son las defensas posibles contra esta interrupción sin precedentes?**

Tengo varias sugerencias, algunas de las cuales Anthropic ya está llevando a cabo. Lo primero es simplemente obtener datos precisos sobre lo que está sucediendo con el desplazamiento laboral en tiempo real. Cuando un cambio económico ocurre muy rápidamente, es difícil obtener datos confiables sobre lo que está sucediendo y, sin datos confiables, es difícil diseñar políticas efectivas. Por ejemplo, los datos gubernamentales carecen actualmente de datos granulares y de alta frecuencia sobre la adopción de la IA en empresas e industrias. Durante el último año, Anthropic ha operado y publicado un Índice Económico que muestra el uso de nuestros modelos casi en tiempo real, desglosado por industria, tarea, ubicación e incluso cosas como si una tarea se está automatizando o se está llevando a cabo en colaboración. También tenemos un Consejo Asesor Económico para ayudarnos a interpretar estos datos y ver qué se avecina.

En segundo lugar, las empresas de IA tienen una opción en cómo trabajan con las empresas. La propia ineficiencia de las empresas tradicionales significa que su despliegue de la IA puede estar fuertemente condicionado por las elecciones iniciales, y hay espacio para elegir un camino mejor. Las empresas a menudo tienen que elegir entre "ahorro de costes", hacer lo mismo con menos personas, e "innovación", hacer más con el mismo número de personas. El mercado producirá inevitablemente ambos al final, y cualquier empresa de IA competitiva tendrá que servir un poco de ambos, pero podría haber espacio para orientar a las empresas hacia la innovación cuando sea posible, y podría ganarnos algo de tiempo. Anthropic está pensando activamente en esto.

En tercer lugar, las empresas deberían pensar en cómo cuidar a sus empleados. A corto plazo, ser creativos sobre formas de reasignar empleados dentro de las empresas podría ser una forma prometedora de evitar la necesidad de despidos. A largo plazo, en un mundo con una enorme riqueza total, en el que muchas empresas aumentan enormemente su valor debido a una mayor productividad y concentración de capital, podría ser factible pagar a los empleados humanos incluso mucho tiempo después de que ya no proporcionen valor económico en el sentido tradicional. Anthropic está considerando actualmente una gama de posibles caminos para nuestros empleados que compartiremos en el futuro cercano.

En cuarto lugar, las personas ricas tienen la obligación de ayudar a resolver este problema. Me entristece que muchas personas ricas, especialmente en la industria tecnológica, hayan adoptado recientemente una actitud cínica y nihilista de que la filantropía es inevitablemente fraudulenta o inútil. Tanto la filantropía privada como la Fundación Gates como los programas públicos como PEPFAR han salvado decenas de millones de vidas en el mundo en desarrollo y han ayudado a crear oportunidades económicas en el mundo desarrollado. Todos los cofundadores de Anthropic se han comprometido a donar el ochenta por ciento de nuestra riqueza, y el personal de Anthropic se ha comprometido individualmente a donar acciones de la empresa por valor de miles de millones a los precios actuales, donaciones que la empresa se ha comprometido a igualar.

En quinto lugar, si bien todas las acciones privadas anteriores pueden ser útiles, en última instancia, un problema macroeconómico de esta magnitud requerirá la intervención del gobierno. La respuesta política natural a un pastel económico enorme junto con una alta desigualdad, debido a la falta de trabajos o trabajos mal pagados para muchos, es la tributación progresiva. El impuesto podría ser general o podría estar dirigido a las empresas de IA en particular. Obviamente, el diseño de los impuestos es complicado y hay muchas formas en que puede salir mal. No apoyo políticas fiscales mal diseñadas. Creo que los niveles extremos de desigualdad predichos en este ensayo justifican una política fiscal más robusta sobre bases morales, pero también puedo hacer un llamamiento pragmático a los multimillonarios del mundo de que es en su interés apoyar una buena versión de ella: si no apoyan una buena versión, inevitablemente obtendrán una mala versión diseñada por una multitud.

**Pero no hablas solo de desempleo. También está el problema de la concentración económica del poder, que es independiente pero está relacionado.**

Sí, es un riesgo distinto. Independiente del problema del desplazamiento laboral o la desigualdad económica en sí, está el problema de la concentración económica del poder. Otro tipo de pérdida de poder (disempowerment) puede ocurrir si hay una concentración de riqueza tan enorme que un pequeño grupo de personas controla efectivamente la política del gobierno con su influencia, y los ciudadanos comunes no tienen influencia porque carecen de influencia económica. La democracia se sustenta en última instancia en la idea de que la población en su conjunto es necesaria para el funcionamiento de la economía. Si esa influencia económica desaparece, entonces el contrato social implícito de la democracia podría dejar de funcionar.

Para ser claros, no estoy en contra de que la gente gane mucho dinero. Muchos han escrito sobre este tema que incentiva el crecimiento económico en condiciones normales, y estoy de acuerdo. Estoy de acuerdo con las preocupaciones sobre impedir la innovación matando a la gallina de los huevos de oro que la genera. Pero en un escenario donde el crecimiento del PIB es del diez al veinte por ciento anual y la IA se está apoderando rápidamente de la economía, y sin embargo, individuos aislados poseen fracciones apreciables del PIB, la innovación no es lo que debe preocupar. Lo que debe preocupar es un nivel de concentración de riqueza que romperá la sociedad.

El ejemplo más famoso de concentración extrema de riqueza en la historia de Estados Unidos es la Gilded Age (Edad Dorada), y el industrial más rico de la Gilded Age fue John D. Rockefeller. La riqueza de Rockefeller ascendía a aproximadamente el dos por ciento del PIB de EE. UU. en ese momento. Una fracción similar hoy llevaría a una fortuna de seiscientos mil millones de dólares, y la persona más rica del mundo hoy, Elon Musk, ya supera esa cifra situándose en unos setecientos mil millones. Por lo tanto, ya estamos en niveles históricamente sin precedentes de concentración de riqueza, incluso antes de la mayor parte del impacto económico de la IA. No creo que sea demasiado descabellado, si conseguimos un "país de genios", imaginar empresas de IA, empresas de semiconductores y tal vez empresas de aplicaciones posteriores que generen unos tres billones en ingresos al año, valoradas en unos treinta billones, lo que llevaría a fortunas personales del orden de los billones. En ese mundo, los debates que tenemos hoy sobre la política fiscal simplemente no se aplicarán, ya que estaremos en una situación fundamentalmente diferente.

Relacionado con esto, el acoplamiento de esta concentración económica de riqueza con el sistema político ya me preocupa. Los centros de datos de IA ya representan una fracción sustancial del crecimiento económico de Estados Unidos y, por lo tanto, están vinculando fuertemente los intereses financieros de las grandes empresas tecnológicas, que se centran cada vez más en la IA o la infraestructura de IA, y los intereses políticos del gobierno de una manera que puede producir incentivos perversos. Ya vemos esto a través de la renuencia de las empresas tecnológicas a criticar al gobierno de EE. UU. y el apoyo del gobierno a políticas extremadamente antirregulatorias sobre la IA.

**¿Qué se puede hacer contra esto?**

En primer lugar, y más obviamente, las empresas deberían simplemente elegir no formar parte de ello. Anthropic siempre se ha esforzado por ser un actor político y no político, y por mantener nuestras opiniones auténticas sea cual sea la administración. Hemos hablado a favor de una regulación sensata de la IA y de controles de exportación que sean de interés público, incluso cuando estos están en desacuerdo con la política del gobierno. Muchas personas me han dicho que deberíamos dejar de hacer esto, que podría llevar a un trato desfavorable, pero en el año en que lo hemos hecho, la valoración de Anthropic ha aumentado más de seis veces, un salto casi sin precedentes para nuestra escala comercial.

En segundo lugar, la industria de la IA necesita una relación más saludable con el gobierno, basada en un compromiso político sustancial en lugar de una alineación política. Nuestra elección de comprometernos con la sustancia de las políticas en lugar de con la política a veces se interpreta como un error táctico o una incapacidad para "leer la sala" en lugar de una decisión de principios, y ese encuadre me preocupa. En una democracia saludable, las empresas deberían ser capaces de apoyar buenas políticas para sí mismas.

En tercer lugar, las intervenciones macroeconómicas que describí anteriormente en esta sección, así como un renacimiento de la filantropía privada, pueden ayudar a equilibrar la balanza económica, abordando juntos tanto el problema del desplazamiento laboral como el de la concentración del poder económico. Deberíamos mirar la historia de nuestro país aquí: incluso en la Gilded Age, industriales como Rockefeller y Carnegie sentían una fuerte obligación hacia la sociedad en general, un sentimiento de que la sociedad había contribuido enormemente a su éxito y que necesitaban devolver algo. Ese espíritu parece estar cada vez más ausente hoy en día, y creo que es una gran parte de la salida de este dilema económico. Aquellos que están a la vanguardia del auge económico de la IA deberían estar dispuestos a ceder tanto su riqueza como su poder.

**El quinto y último riesgo se refiere a los efectos indirectos. Las incógnitas desconocidas. ¿Qué te preocupa aquí?**

Esta es una categoría que lo abarca todo para las llamadas 'incógnitas desconocidas' (unknown unknowns): esas incógnitas totalmente impredecibles, particularmente cosas que podrían salir mal como resultado indirecto de los avances positivos en la IA y la consiguiente aceleración de la ciencia y la tecnología en general. Supongamos que enfrentamos todos los riesgos descritos hasta ahora y comenzamos a cosechar los beneficios de la IA. Probablemente obtendremos un "siglo de progreso científico y económico comprimido en una década", y esto será enormemente positivo para el mundo, pero luego tendremos que enfrentarnos a los problemas que surjan de este rápido ritmo de progreso, y esos problemas podrían llegar rápido.

Por la naturaleza de las incógnitas desconocidas, es imposible hacer una lista exhaustiva, pero enumero tres como ejemplos ilustrativos. Progresos rápidos en biología: si obtenemos un siglo de progreso médico en pocos años, es posible que aumentemos drásticamente la duración de la vida humana, y existe la posibilidad de obtener incluso capacidades radicales como la posibilidad de aumentar la inteligencia humana o modificar radicalmente la biología humana. Se trataría de grandes cambios en lo posible, que ocurrirían muy rápidamente. Podrían ser positivos si se hicieran de manera responsable, que es mi esperanza como se describe en Machines of Loving Grace, pero siempre existe el riesgo de que salgan mal, por ejemplo, si los esfuerzos para hacer que los humanos sean más inteligentes también los hacen más inestables o buscadores de poder.

La IA cambia la vida humana de manera poco saludable: un mundo con miles de millones de inteligencias mucho más inteligentes que los humanos en todo será un mundo muy extraño en el que vivir. Incluso si la IA no se propone activamente atacar a los humanos, y no es utilizada explícitamente para la opresión o el control por parte de los estados, hay muchas cosas que podrían salir mal fuera de eso, a través de incentivos comerciales normales y transacciones nominalmente consensuadas. Vemos los primeros indicios de esto en las preocupaciones sobre la psicosis por IA, sobre la IA que lleva a las personas al suicidio y preocupaciones sobre las relaciones románticas con la IA. Como ejemplo, ¿podrían las IA potentes inventar alguna nueva religión y convertir a millones de personas a ella? ¿Podría la mayoría de la gente terminar "adicta" de alguna manera a las interacciones con la IA?

Propósito humano: esto está relacionado con el punto anterior, pero no se refiere tanto a las interacciones humanas específicas con los sistemas de IA como a cómo cambia la vida humana en general en un mundo con una IA potente. ¿Serán los humanos capaces de encontrar propósito y significado en tal mundo? Creo que esto es una cuestión de actitud: como dije en Machines of Loving Grace, creo que el propósito humano no depende de ser el mejor del mundo en algo, y los humanos pueden encontrar propósito incluso durante períodos de tiempo muy largos a través de historias y proyectos que aman. Simplemente tenemos que romper el vínculo entre la generación de valor económico y la autoestima y el significado. Pero esta es una transición que la sociedad debe hacer, y siempre existe el riesgo de que no la gestionemos bien.

Mi esperanza, con todos estos problemas potenciales, es que en un mundo con una IA potente en la que confiemos y que no nos mate, que no sea la herramienta de un gobierno opresor y que realmente trabaje para nosotros, podamos usar la propia IA para anticipar y prevenir estos problemas. Pero esto no está garantizado: como todos los demás riesgos, es algo que debemos gestionar con precaución.

**Al final de tu ensayo, a pesar de este mapeo tan detallado de los riesgos y las tensiones entre ellos, escribes que crees en la capacidad de la humanidad para prevalecer. ¿En qué se basa este optimismo? ¿No es ingenuo?**

Las tensiones son auténticas y debemos reconocerlas. Tomarse tiempo para construir sistemas de IA que no amenacen de forma autónoma a la humanidad está en tensión genuina con la necesidad de que las naciones democráticas se mantengan por delante de las autocracias y no sean subyugadas por ellas. Pero a su vez, las mismas herramientas potenciadas por la IA necesarias para combatir las autocracias pueden, si se llevan demasiado lejos, volverse hacia el interior para crear tiranía en nuestros propios países. El terrorismo potenciado por la IA podría matar a millones mediante el uso indebido de la biología, pero una reacción exagerada a este riesgo podría llevarnos por el camino de un estado de vigilancia autocrático. Los efectos sobre el empleo y la concentración económica de la IA, además de ser problemas graves en sí mismos, podrían obligarnos a enfrentar los otros problemas en un ambiente de ira pública y tal vez incluso de disturbios civiles, en lugar de poder apelar a los mejores recursos de nuestra naturaleza. Sobre todo, el simple número de riesgos, incluidos los desconocidos, y la necesidad de abordarlos todos juntos, crea un desafío intimidante que la humanidad debe atravesar.

**Y detener o ralentizar el desarrollo no es una opción.**

Exactamente. Los últimos años deberían dejar claro que la idea de detener o incluso ralentizar sustancialmente la tecnología es fundamentalmente insostenible. La fórmula para construir sistemas de IA potentes es increíblemente simple, tanto que casi puede decirse que emerge espontáneamente de la combinación adecuada de datos y cálculo bruto. Su creación fue probablemente inevitable en el instante en que la humanidad inventó el transistor, o tal vez incluso antes, cuando aprendimos por primera vez a controlar el fuego. Si una empresa no la construye, otras lo harán casi con la misma rapidez. Si todas las empresas de los países democráticos detuvieran o ralentizaran el desarrollo, por acuerdo mutuo o decreto regulatorio, los países autoritarios simplemente continuarían. Dado el increíble valor económico y militar de la tecnología, junto con la falta de cualquier mecanismo de ejecución significativo, no veo cómo podríamos convencerlos de que se detuvieran.

**Pero propones un camino específico. ¿Cuál?**

Veo un camino hacia una moderación ligera en el desarrollo de la IA compatible con una visión realista de la geopolítica. Ese camino implica ralentizar la marcha de las autocracias hacia una IA potente durante unos pocos años negándoles los recursos necesarios para construirla, a saber, chips y equipos para la fabricación de semiconductores. Esto, a su vez, da a los países democráticos un margen (buffer) que pueden "gastar" para construir la IA potente con más cuidado, con más atención a sus riesgos, procediendo aún lo suficientemente rápido como para vencer cómodamente a las autocracias. La carrera entre las empresas de IA dentro de las democracias puede entonces gestionarse bajo el paraguas de un marco legal común, a través de una mezcla de estándares industriales y regulación.

Anthropic ha defendido con mucha fuerza este camino, presionando por controles a la exportación de chips y una regulación juiciosa de la IA, pero incluso estas propuestas aparentemente de sentido común han sido rechazadas en gran medida por los responsables políticos en Estados Unidos, que es el país donde es más importante tenerlas. Hay tanto dinero por ganar con la IA, literalmente billones de dólares al año, que incluso las medidas más simples están encontrando dificultades para superar la economía política intrínseca en la IA. Esta es la trampa: la IA es tan potente, un premio tan brillante, que es muy difícil para la civilización humana imponerle cualquier restricción.

**Y así vuelves a Sagan, a la prueba que toda civilización debe enfrentar.**

Puedo imaginar, como hizo Sagan en Contact, que esta misma historia se repite en miles de mundos. Una especie adquiere la sintiencia, aprende a usar herramientas, comienza el ascenso exponencial de la tecnología, se enfrenta a las crisis de la industrialización y de las armas nucleares y, si sobrevive a ellas, se enfrenta al desafío más duro y final cuando aprende a dar forma a la arena para convertirla en máquinas que piensan. Que sobrevivamos a esa prueba y sigamos adelante para construir la bella sociedad descrita en Machines of Loving Grace, o sucumbamos a la esclavitud y la destrucción, dependerá de nuestro carácter y de nuestra determinación como especie, de nuestro espíritu y de nuestra alma.

A pesar de los muchos obstáculos, creo que la humanidad tiene en su interior la fuerza para superar esta prueba. Me alientan los miles de investigadores que han dedicado sus carreras a ayudarnos a comprender y guiar los modelos de IA, a moldear el carácter y la constitución de estos modelos. Creo que ahora hay una buena probabilidad de que esos esfuerzos den sus frutos a su debido tiempo. Me alienta que al menos algunas empresas hayan declarado que pagarán costes comerciales significativos para bloquear que sus modelos contribuyan a la amenaza del bioterrorismo. Me alienta que algunas personas valientes hayan resistido los vientos políticos imperantes y hayan aprobado una legislación que pone las primeras semillas iniciales de salvaguardias sensatas en los sistemas de IA. Me alienta que el público comprenda que la IA conlleva riesgos y quiera que esos riesgos se aborden. Me alienta el espíritu indomable de libertad en el mundo y la determinación de resistir la tiranía dondequiera que ocurra.

**Pero hace falta un despertar colectivo.**

Debemos intensificar nuestros esfuerzos si queremos tener éxito. El primer paso es que los más cercanos a la tecnología simplemente digan la verdad sobre la situación en la que se encuentra la humanidad, algo que siempre he intentado hacer. Estoy haciendo esto de manera más explícita y con mayor urgencia con este ensayo. El siguiente paso será convencer a los pensadores, a los responsables políticos, a las empresas y a los ciudadanos del mundo de la inminencia y la importancia prioritaria de este tema, de que vale la pena dedicar pensamiento y capital político a esto en comparación con las miles de otras cuestiones que dominan las noticias cada día. Luego habrá un tiempo para el coraje, para que suficientes personas vayan a contracorriente y se mantengan firmes en sus principios, incluso frente a las amenazas a sus intereses económicos y a su seguridad personal.

Los años que tenemos por delante serán increíblemente difíciles, exigirán más de lo que creemos que podemos dar. Pero en mi tiempo como investigador, líder y ciudadano, he visto suficiente coraje y nobleza para creer que podemos ganar, que cuando se la pone en las circunstancias más oscuras, la humanidad tiene una forma de reunir, aparentemente en el último minuto, la fuerza y la sabiduría necesarias para prevalecer. No tenemos tiempo que perder.
