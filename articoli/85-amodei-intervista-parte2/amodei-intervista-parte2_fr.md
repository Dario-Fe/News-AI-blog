---
tags: ["Ethics & Society", "Security", "Business"]
date: 2026-02-09
author: "Dario Ferrero"
---

# Dario Amodei et l'adolescence technologique de l'humanité - Partie 2
![amodei-intervista-parte2.jpg](amodei-intervista-parte2.jpg)

*Nous reprenons et terminons, avec ce deuxième volet, la longue conversation simulée avec Dario Amodei, PDG d'Anthropic, reconstruite à rebours à partir des réflexions publiées dans son dernier essai "The Adolescence of Technology". Un procédé narratif pour rendre plus immédiat le message urgent qu'Amodei veut lancer : l'humanité entre dans un passage critique qui pourrait se définir dans les deux prochaines années.*

---

**Qui vous inquiète le plus, par ordre de gravité ?**

Le Parti communiste chinois. La Chine n'est devancée que par les États-Unis en termes de capacités d'IA et c'est le pays qui a la plus grande probabilité de dépasser les États-Unis dans ces capacités. Leur gouvernement est actuellement autocratique et gère un État de surveillance high-tech. Il a déjà déployé une surveillance basée sur l'IA, notamment dans la répression des Ouïghours, et on pense qu'il emploie une propagande algorithmique via TikTok en plus de ses nombreux autres efforts de propagande internationale. Ils ont clairement le chemin le plus direct vers le cauchemar totalitaire rendu possible par l'IA que j'ai décrit. Cela pourrait même être le résultat par défaut en Chine, ainsi que dans d'autres États autocratiques auxquels le PCC exporte sa technologie de surveillance. J'ai souvent écrit sur la menace que représente le PCC s'il prend l'avantage dans l'IA et sur l'impératif existentiel de l'en empêcher. Voici pourquoi. Pour être clair, c'est le peuple chinois lui-même qui est le plus susceptible de souffrir de la répression rendue possible par l'IA du PCC, et il n'a pas son mot à dire sur les actions de son gouvernement. J'admire et respecte profondément le peuple chinois et je soutiens les nombreux dissidents courageux en Chine et leur lutte pour la liberté.

Ensuite, il y a les démocraties compétitives dans l'IA. Comme je l'ai écrit, les démocraties ont un intérêt légitime dans certains outils militaires et géopolitiques renforcés par l'IA, car les gouvernements démocratiques offrent la meilleure chance de contrer l'utilisation de ces outils par les autocraties. Je suis généralement favorable à l'armement des démocraties avec les outils nécessaires pour vaincre les autocraties à l'ère de l'IA ; je ne pense tout simplement pas qu'il y ait d'autre moyen. Mais nous ne pouvons pas ignorer le potentiel d'abus de ces technologies par les gouvernements démocratiques eux-mêmes. Les démocraties disposent normalement de garde-fous qui empêchent leur appareil militaire et de renseignement d'être tourné vers l'intérieur contre leur propre population, mais comme les outils d'IA nécessitent si peu de personnes pour fonctionner, il est possible qu'ils contournent ces garde-fous et les normes qui les soutiennent.

Viennent ensuite les pays non démocratiques disposant de grands centres de données, et enfin les entreprises d'IA elles-mêmes. C'est un peu gênant de dire cela en tant que PDG d'une entreprise d'IA, mais je pense que le niveau de risque suivant est en fait celui des entreprises d'IA elles-mêmes. Les entreprises d'IA contrôlent de grands centres de données, entraînent des modèles de pointe, possèdent la plus grande expertise sur la manière d'utiliser ces modèles et, dans certains cas, ont un contact quotidien avec des dizaines ou des centaines de millions d'utilisateurs et la possibilité de les influencer. La chose principale qui leur manque est la légitimité et l'infrastructure d'un État. Je pense que la gouvernance des entreprises d'IA mérite un examen approfondi.

**Comment se défendre contre ces risques multiformes ?**

Nous ne devrions absolument pas vendre de puces, d'outils de fabrication de puces ou de centres de données au PCC. Les puces et les outils de fabrication de puces constituent le principal goulot d'étranglement pour une IA puissante, et les bloquer est une mesure simple mais extrêmement efficace, peut-être l'action la plus importante que nous puissions entreprendre. Il n'y a aucun sens à vendre au PCC les outils lui permettant de construire un État totalitaire d'IA et potentiellement de nous conquérir militairement. La Chine a plusieurs années de retard sur les États-Unis dans sa capacité à produire des puces de pointe en quantité, et la période critique pour construire le pays des génies dans le centre de données se situe très probablement dans ces prochaines années.

Deuxièmement, il est logique d'utiliser l'IA pour donner aux démocraties les moyens de résister aux autocraties. C'est pourquoi Anthropic considère qu'il est important de fournir une IA aux communautés du renseignement et de la défense aux États-Unis et chez ses alliés démocratiques. Défendre les démocraties attaquées, comme l'Ukraine et Taïwan, semble être une priorité particulièrement élevée, tout comme donner aux démocraties les moyens d'utiliser leurs services de renseignement pour déstabiliser et dégrader les autocraties de l'intérieur.

Troisièmement, nous devons tracer une ligne dure contre les abus de l'IA au sein des démocraties. La formulation que j'ai élaborée est que nous devrions utiliser l'IA pour la défense nationale de toutes les manières, sauf celles qui nous rendraient plus semblables à nos adversaires autocratiques. L'utilisation de l'IA pour la surveillance de masse domestique et la propagande de masse me semble être des frontières infranchissables et complètement illégitimes. Les armes complètement autonomes et l'IA pour la prise de décision stratégique sont des lignes plus difficiles à tracer car elles ont des utilisations légitimes dans la défense de la démocratie, tout en étant sujettes à des abus. Ici, je pense que ce qui s'impose est une prudence et un contrôle extrêmes, combinés à des garde-fous pour prévenir les abus.

Quatrièmement, après avoir tracé une ligne dure contre les abus de l'IA dans les démocraties, nous devrions utiliser ce précédent pour créer un tabou international contre les pires abus d'une IA puissante. Le monde doit comprendre le sombre potentiel d'une IA puissante entre les mains d'autocrates, et reconnaître que certaines utilisations de l'IA équivalent à une tentative de voler définitivement leur liberté et d'imposer un État totalitaire auquel ils ne peuvent échapper. Je soutiendrais même que, dans certains cas, la surveillance à grande échelle avec une IA puissante, la propagande de masse avec une IA puissante et certains types d'utilisations offensives d'armes totalement autonomes devraient être considérées comme des crimes contre l'humanité.

**Quatrième risque : la destruction économique. C'est le thème central du Piano mécanique (Player Piano) de Vonnegut : quand les machines font tout, que reste-t-il aux humains ?**

Exactement cette résonance. En 2025, j'ai averti publiquement que l'IA pourrait déplacer la moitié de tous les emplois de bureau (white collar) de début de carrière dans les un à cinq ans à venir, tout en accélérant considérablement la croissance économique et le progrès scientifique. Cela a lancé un débat public. De nombreux PDG, technologues et économistes étaient d'accord, mais d'autres ont supposé que je succombais à l'illusion de la « quantité fixe de travail » (lump of labor) et que je ne comprenais pas le fonctionnement des marchés du travail. Certains n'ont pas vu l'horizon de un à cinq ans et ont pensé que je prétendais que l'IA déplaçait des emplois dès maintenant, ce qui n'est probablement pas le cas, j'en conviens. Il vaut la peine d'examiner en détail pourquoi je m'inquiète du déplacement des emplois.

Le rythme du progrès de l'IA est bien plus rapide que celui des révolutions technologiques précédentes. Au cours des deux dernières années, les modèles d'IA sont passés d'une capacité à peine suffisante pour compléter une seule ligne de code à l'écriture de la totalité ou de la quasi-totalité du code pour certaines personnes, y compris des ingénieurs chez Anthropic. Même des programmeurs légendaires se décrivent de plus en plus comme « dépassés ». Bientôt, les modèles pourraient accomplir l'intégralité de la tâche d'un ingénieur logiciel de bout en bout. Il est difficile pour les gens de s'adapter à ce rythme de changement, tant aux modifications de la manière dont un emploi donné fonctionne qu'à la nécessité de passer à de nouveaux emplois. Au contraire, le rythme peut continuer à s'accélérer, à mesure que les modèles de codage d'IA accélèrent de plus en plus la tâche de développement de l'IA. Pour être clair, la vitesse en elle-même ne signifie pas que les marchés du travail et l'emploi ne se rétabliront pas un jour ; cela signifie seulement que la transition à court terme sera exceptionnellement douloureuse.

L'étendue cognitive est le deuxième facteur : l'IA sera capable d'une très large gamme de capacités cognitives humaines, peut-être de toutes. C'est très différent des technologies précédentes comme l'agriculture mécanisée, les transports ou même les ordinateurs. Cela rendra plus difficile pour les gens de passer facilement d'emplois remplacés à des emplois similaires pour lesquels ils seraient qualifiés. Les compétences intellectuelles générales requises pour les emplois de début de carrière dans la finance, le conseil et le droit, par exemple, sont assez similaires, même si les connaissances spécifiques sont assez différentes. Une technologie qui ne perturberait qu'un seul des trois permettrait aux employés de passer aux deux substituts proches, ou à ceux moins préparés de changer de spécialité. Mais perturber les trois simultanément, ainsi que de nombreux autres emplois similaires, pourrait être plus difficile à gérer pour les gens. De plus, ce n'est pas seulement que la plupart des emplois existants seront perturbés. Cela s'est déjà produit auparavant : l'agriculture représentait un pourcentage énorme de l'emploi. Mais les agriculteurs pouvaient passer à l'emploi relativement similaire de conducteur de machines d'usine, même si cet emploi n'était pas courant auparavant. À l'inverse, l'IA répond de plus en plus au profil cognitif général des humains, ce qui signifie qu'elle sera également douée pour les nouveaux emplois qui seraient ordinairement créés en réponse à l'automatisation des anciens. Une autre façon de le dire est que l'IA n'est pas un substitut à des emplois humains spécifiques, mais plutôt un substitut général au travail des humains.

Troisième facteur : la sélection basée sur les capacités cognitives. Sur une vaste gamme de tâches, l'IA semble progresser du bas vers le haut de l'échelle des compétences. Par exemple, en codage, nos modèles sont passés du niveau de « programmeur médiocre » à « programmeur fort », puis « programmeur très fort ». Nous commençons maintenant à voir la même progression dans le travail de bureau en général. Nous risquons donc de nous retrouver dans une situation où, au lieu de toucher des personnes ayant des compétences spécifiques ou dans des professions spécifiques qui peuvent s'adapter en se formant à nouveau, l'IA touche des personnes possédant certaines propriétés cognitives intrinsèques, à savoir une capacité intellectuelle moindre, qu'il est plus difficile de changer. Il n'est pas clair où ces personnes iront ou ce qu'elles feront, et je crains qu'elles ne forment une « sous-classe » sans emploi ou aux salaires très bas. Pour être clair, des choses assez similaires se sont déjà produites ; par exemple, les ordinateurs et Internet sont considérés par certains économistes comme représentant un « changement technologique favorisant les travailleurs qualifiés ». Mais ce biais de compétences (skill biasing) n'était pas aussi extrême que ce que je m'attends à voir avec l'IA, et on pense qu'il a contribué à une augmentation de l'inégalité salariale, ce qui n'est donc pas exactement un précédent rassurant.

Quatrième facteur : la capacité à combler les lacunes. La manière dont les emplois humains s'adaptent souvent face aux nouvelles technologies est qu'il existe de nombreux aspects de l'emploi, et que la nouvelle technologie, même si elle semble remplacer directement les humains, présente souvent des lacunes. Si quelqu'un invente une machine pour fabriquer des pièces, les humains pourraient encore devoir charger les matières premières dans la machine. Même si cela ne nécessite qu'un pour cent de l'effort nécessaire pour fabriquer les pièces manuellement, les travailleurs humains peuvent simplement fabriquer cent fois plus de pièces. Mais l'IA, en plus d'être une technologie qui progresse rapidement, est aussi une technologie qui s'adapte rapidement. Lors de chaque sortie de modèle, les entreprises d'IA mesurent soigneusement ce pour quoi le modèle est bon et ce pour quoi il ne l'est pas, et les clients fournissent également ces informations après le lancement. Les faiblesses peuvent être corrigées en collectant des tâches qui incarnent la lacune actuelle et en s'entraînant sur celles-ci pour le modèle suivant. Au début de l'IA générative, les utilisateurs ont remarqué que les systèmes d'IA présentaient certaines faiblesses, comme les modèles d'images d'IA générant des mains avec un nombre incorrect de doigts, et beaucoup ont supposé que ces faiblesses étaient intrinsèques à la technologie. Si elles l'avaient été, cela aurait limité la perturbation des emplois. Mais pratiquement chacune de ces faiblesses est corrigée rapidement, souvent en quelques mois.

**Quelles sont les défenses possibles contre cette perturbation sans précédent ?**

J'ai plusieurs suggestions, dont certaines sont déjà mises en œuvre par Anthropic. La première chose est simplement d'obtenir des données précises sur ce qui se passe concernant le déplacement des emplois en temps réel. Lorsqu'un changement économique se produit très rapidement, il est difficile d'obtenir des données fiables sur ce qui se passe, et sans données fiables, il est difficile de concevoir des politiques efficaces. Par exemple, les données gouvernementales manquent actuellement de données granulaires et à haute fréquence sur l'adoption de l'IA dans les entreprises et les secteurs. Depuis un an, Anthropic gère et publie un Indice Économique qui montre l'utilisation de nos modèles presque en temps réel, décomposée par secteur, tâche, lieu, et même par des éléments tels que si une tâche est automatisée ou menée en collaboration. Nous avons également un Conseil Consultatif Économique pour nous aider à interpréter ces données et à voir ce qui se profile.

Deuxièmement, les entreprises d'IA ont le choix dans leur manière de travailler avec les entreprises. L'inefficacité même des entreprises traditionnelles signifie que leur déploiement de l'IA peut être fortement conditionné par les choix initiaux, et qu'il est possible de choisir une meilleure voie. Les entreprises ont souvent le choix entre les « économies de coûts », faire la même chose avec moins de personnes, et l'« innovation », faire plus avec le même nombre de personnes. Le marché finira inévitablement par produire les deux, et toute entreprise d'IA compétitive devra proposer les deux, mais il pourrait y avoir de la place pour orienter les entreprises vers l'innovation quand cela est possible, ce qui pourrait nous faire gagner du temps. Anthropic y réfléchit activement.

Troisièmement, les entreprises devraient réfléchir à la manière de prendre soin de leurs employés. À court terme, être créatif sur les moyens de réaffecter les employés au sein des entreprises pourrait être une voie prometteuse pour éviter les licenciements. À long terme, dans un monde de richesse totale énorme, où de nombreuses entreprises voient leur valeur augmenter considérablement grâce à une productivité accrue et à la concentration du capital, il pourrait être faisable de payer des employés humains même longtemps après qu'ils ne fournissent plus de valeur économique au sens traditionnel. Anthropic envisage actuellement une gamme de voies possibles pour nos employés que nous partagerons dans un avenir proche.

Quatrièmement, les individus riches ont l'obligation d'aider à résoudre ce problème. Il m'est triste de voir que de nombreux individus fortunés, en particulier dans le secteur technologique, ont récemment adopté une attitude cynique et nihiliste selon laquelle la philanthropie est inévitablement frauduleuse ou inutile. La philanthropie privée comme la Fondation Gates et les programmes publics comme le PEPFAR ont sauvé des dizaines de millions de vies dans le monde en développement et ont aidé à créer des opportunités économiques dans le monde développé. Tous les cofondateurs d'Anthropic se sont engagés à faire don de quatre-vingts pour cent de leur richesse, et le personnel d'Anthropic s'est engagé individuellement à faire don d'actions de l'entreprise d'une valeur de plusieurs milliards aux prix actuels, dons que l'entreprise s'est engagée à égaler.

Cinquièmement, bien que toutes les actions privées ci-dessus puissent être utiles, un problème macroéconomique de cette ampleur nécessitera en fin de compte une intervention gouvernementale. La réponse politique naturelle à un gâteau économique énorme couplé à une forte inégalité, due à un manque d'emplois ou à des emplois mal payés pour beaucoup, est une fiscalité progressive. La taxe pourrait être générale ou cibler les entreprises d'IA en particulier. Évidemment, la conception des taxes est compliquée et peut mal tourner de bien des manières. Je ne soutiens pas les politiques fiscales mal conçues. Je pense que les niveaux extrêmes d'inégalité prédits dans cet essai justifient une politique fiscale plus robuste sur des bases morales, mais je peux aussi lancer un appel pragmatique aux milliardaires du monde entier en leur disant qu'il est dans leur intérêt de soutenir une bonne version de celle-ci : s'ils ne soutiennent pas une bonne version, ils obtiendront inévitablement une mauvaise version conçue par la foule.

**Mais vous ne parlez pas seulement de chômage. Il y a aussi le problème de la concentration économique du pouvoir, qui est distinct mais lié.**

Oui, c'est un risque distinct. Indépendamment du problème du déplacement des emplois ou de l'inégalité économique en soi, il y a le problème de la concentration économique du pouvoir. Un autre type de perte de pouvoir (disempowerment) peut survenir s'il existe une concentration de richesse si énorme qu'un petit groupe de personnes contrôle effectivement la politique gouvernementale par son influence, et que les citoyens ordinaires n'ont aucune influence parce qu'ils manquent de levier économique. La démocratie est en fin de compte soutenue par l'idée que la population dans son ensemble est nécessaire au fonctionnement de l'économie. Si ce levier économique disparaît, alors le contrat social implicite de la démocratie pourrait cesser de fonctionner.

Pour être clair, je ne suis pas contre le fait de gagner beaucoup d'argent. Beaucoup ont écrit sur ce sujet en disant que cela encourage la croissance économique dans des conditions normales, et je suis d'accord. Je suis d'accord avec les inquiétudes concernant le frein à l'innovation en tuant la poule aux œufs d'or qui la génère. Mais dans un scénario où la croissance du PIB est de dix à vingt pour cent par an et où l'IA prend rapidement le contrôle de l'économie, alors que des individus détiennent des fractions appréciables du PIB, l'innovation n'est pas ce dont il faut se soucier. Ce dont il faut se soucier, c'est d'un niveau de concentration de richesse qui brisera la société.

L'exemple le plus célèbre de concentration extrême de richesse dans l'histoire des États-Unis est l'Âge doré (Gilded Age), et l'industriel le plus riche de l'Âge doré était John D. Rockefeller. La richesse de Rockefeller s'élevait à environ deux pour cent du PIB américain de l'époque. Une fraction similaire aujourd'hui conduirait à une fortune de six cents milliards de dollars, et la personne la plus riche du monde aujourd'hui, Elon Musk, dépasse déjà ce chiffre en s'établissant à environ sept cents milliards. Nous en sommes donc déjà à des niveaux de concentration de richesse historiquement sans précédent, avant même la majeure partie de l'impact économique de l'IA. Je ne pense pas qu'il soit trop farfelu, si nous obtenons un « pays des génies », d'imaginer des entreprises d'IA, des entreprises de semi-conducteurs et peut-être des entreprises d'applications en aval générant environ trois mille milliards de revenus par an, valorisées à environ trente mille milliards, ce qui mènerait à des fortunes personnelles de l'ordre de plusieurs milliers de milliards. Dans ce monde, les débats que nous avons aujourd'hui sur la politique fiscale ne s'appliqueront tout simplement pas car nous serons dans une situation fondamentalement différente.

Lié à cela, le couplage de cette concentration économique de richesse avec le système politique m'inquiète déjà. Les centres de données d'IA représentent déjà une fraction substantielle de la croissance économique des États-Unis et lient donc fortement les intérêts financiers des grandes entreprises technologiques, qui se concentrent de plus en plus sur l'IA ou l'infrastructure d'IA, et les intérêts politiques du gouvernement d'une manière qui peut produire des incitations perverses. Nous le voyons déjà à travers la réticence des entreprises technologiques à critiquer le gouvernement américain, et le soutien du gouvernement à des politiques extrêmement anti-réglementaires sur l'IA.

**Que peut-on faire contre cela ?**

Premièrement, et c'est le plus évident, les entreprises devraient simplement choisir de ne pas en faire partie. Anthropic s'est toujours efforcé d'être un acteur politique et non politique, et de garder ses points de vue authentiques, quelle que soit l'administration. Nous nous sommes prononcés en faveur d'une réglementation sensée de l'IA et de contrôles à l'exportation qui sont dans l'intérêt public, même lorsqu'ils sont en contradiction avec la politique gouvernementale. Beaucoup de gens m'ont dit que nous devrions arrêter de faire cela, que cela pourrait mener à un traitement défavorable, mais au cours de l'année où nous l'avons fait, la valorisation d'Anthropic a été multipliée par plus de six, un bond presque sans précédent pour notre échelle commerciale.

Deuxièmement, l'industrie de l'IA a besoin d'une relation plus saine avec le gouvernement, basée sur un engagement politique substantiel plutôt que sur un alignement politique. Notre choix de nous engager sur le fond des politiques plutôt que sur la politique elle-même est parfois interprété comme une erreur tactique ou un échec à « lire la salle » plutôt que comme une décision de principe, et ce cadrage m'inquiète. Dans une démocratie saine, les entreprises devraient être capables de soutenir de bonnes politiques pour elles-mêmes.

Troisièmement, les interventions macroéconomiques que j'ai décrites plus haut dans cette section, ainsi qu'une renaissance de la philanthropie privée, peuvent aider à équilibrer les balances économiques, en abordant ensemble le problème du déplacement des emplois et celui de la concentration du pouvoir économique. Nous devrions regarder l'histoire de notre pays ici : même à l'Âge doré, des industriels comme Rockefeller et Carnegie ressentaient une forte obligation envers la société en général, le sentiment que la société avait énormément contribué à leur succès et qu'ils devaient rendre la pareille. Cet esprit semble de plus en plus manquer aujourd'hui, et je pense que c'est une grande partie de la solution à ce dilemme économique. Ceux qui sont à l'avant-garde du boom économique de l'IA devraient être prêts à céder à la fois leur richesse et leur pouvoir.

**Le cinquième et dernier risque concerne les effets indirects. Les inconnues inconnues. Qu'est-ce qui vous inquiète ici ?**

C'est une catégorie fourre-tout pour ce qu'on appelle les 'unknown unknowns' : ces inconnues totalement imprévisibles, en particulier les choses qui pourraient mal tourner comme résultat indirect des progrès positifs de l'IA et de l'accélération de la science et de la technologie en général qui en résulte. Supposons que nous affrontions tous les risques décrits jusqu'à présent et commencions à récolter les bénéfices de l'IA. Nous obtiendrons probablement un « siècle de progrès scientifique et économique compressé en une décennie », et ce sera extrêmement positif pour le monde, mais nous devrons ensuite faire face aux problèmes découlant de ce rythme rapide de progrès, et ces problèmes pourraient arriver vite.

Par la nature des inconnues inconnues, il est impossible d'en dresser une liste exhaustive, mais j'en cite trois à titre d'exemples illustratifs. Progrès rapides en biologie : si nous obtenons un siècle de progrès médical en quelques années, il est possible que nous augmentions considérablement la durée de vie humaine, et il y a la possibilité d'acquérir des capacités radicales comme la possibilité d'augmenter l'intelligence humaine ou de modifier radicalement la biologie humaine. Il s'agirait de changements majeurs dans le champ des possibles, se produisant très rapidement. Ils pourraient être positifs s'ils sont faits de manière responsable, ce qui est mon espoir comme décrit dans Machines of Loving Grace, mais il y a toujours un risque qu'ils tournent mal — par exemple, si les efforts pour rendre les humains plus intelligents les rendent aussi plus instables ou avides de pouvoir.

L'IA change la vie humaine de manière malsaine : un monde comptant des milliards d'intelligences bien plus intelligentes que les humains en tout sera un monde très étrange dans lequel vivre. Même si l'IA ne cherche pas activement à attaquer les humains, et n'est pas explicitement utilisée pour l'oppression ou le contrôle par les États, il y a beaucoup de choses qui pourraient mal tourner en dehors de cela, par le biais d'incitations commerciales normales et de transactions nominalement consensuelles. Nous voyons les premiers signes de cela dans les inquiétudes concernant la psychose de l'IA, l'IA menant les gens au suicide, et les inquiétudes concernant les relations amoureuses avec l'IA. Par exemple, des IA puissantes pourraient-elles inventer une nouvelle religion et y convertir des millions de personnes ? La plupart des gens pourraient-ils finir par être « accros » d'une certaine manière aux interactions avec l'IA ?

Sens humain : ce point est lié au précédent, mais ne concerne pas tant les interactions humaines spécifiques avec les systèmes d'IA que la manière dont la vie humaine change en général dans un monde disposant d'une IA puissante. Les humains seront-ils capables de trouver un sens et un but dans un tel monde ? Je pense que c'est une question d'attitude : comme je l'ai dit dans Machines of Loving Grace, je pense que le but humain ne dépend pas du fait d'être le meilleur au monde dans un domaine, et les humains peuvent trouver un sens même sur de très longues périodes de temps à travers les histoires et les projets qu'ils aiment. Nous devons simplement briser le lien entre la génération de valeur économique et l'estime de soi et le sens. Mais c'est une transition que la société doit faire, et il y a toujours le risque que nous ne la gérions pas bien.

Mon espoir, face à tous ces problèmes potentiels, est que dans un monde doté d'une IA puissante en laquelle nous avons confiance et qui ne nous tuera pas, qui n'est pas l'outil d'un gouvernement oppressif et qui travaille réellement pour nous, nous puissions utiliser l'IA elle-même pour anticiper et prévenir ces problèmes. Mais ce n'est pas garanti : comme tous les autres risques, c'est quelque chose que nous devons gérer avec prudence.

**À la fin de votre essai, malgré cette cartographie si détaillée des risques et des tensions entre eux, vous écrivez que vous croyez en la capacité de l'humanité à prévaloir. Sur quoi se base cet optimisme ? N'est-ce pas naïf ?**

Les tensions sont réelles et nous devons les reconnaître. Prendre le temps de construire des systèmes d'IA qui ne menacent pas l'humanité de manière autonome est en tension réelle avec la nécessité pour les nations démocratiques de rester en avance sur les autocraties et de ne pas être assujetties par elles. Mais à leur tour, les mêmes outils renforcés par l'IA nécessaires pour combattre les autocraties peuvent, s'ils sont poussés trop loin, être tournés vers l'intérieur pour créer de la tyrannie dans nos propres pays. Le terrorisme renforcé par l'IA pourrait tuer des millions de personnes par le mauvais usage de la biologie, mais une réaction excessive à ce risque pourrait nous mener sur la voie d'un État de surveillance autocratique. Les effets sur l'emploi et la concentration économique de l'IA, en plus d'être des problèmes graves en soi, pourraient nous forcer à affronter les autres problèmes dans un climat de colère publique et peut-être même d'agitation civile, au lieu de pouvoir faire appel aux meilleures ressources de notre nature. Surtout, le nombre de risques, y compris les inconnus, et la nécessité de les affronter tous ensemble, créent un défi intimidant que l'humanité doit relever.

**Et arrêter ou ralentir le développement n'est pas une option.**

Exactement. Les dernières années devraient montrer clairement que l'idée d'arrêter ou même de ralentir substantiellement la technologie est fondamentalement intenable. La formule pour construire des systèmes d'IA puissants est incroyablement simple, à tel point que l'on peut presque dire qu'elle émerge spontanément de la bonne combinaison de données et de calcul brut. Sa création était probablement inévitable à l'instant même où l'humanité a inventé le transistor, ou peut-être même plus tôt, lorsque nous avons appris pour la première fois à maîtriser le feu. Si une entreprise ne le construit pas, d'autres le feront presque aussi vite. Si toutes les entreprises des pays démocratiques arrêtaient ou ralentissaient le développement, par accord mutuel ou décret réglementaire, alors les pays autoritaires continueraient tout simplement. Étant donné l'incroyable valeur économique et militaire de la technologie, combinée à l'absence de tout mécanisme d'application significatif, je ne vois pas comment nous pourrions les convaincre d'arrêter.

**Mais vous proposez une voie spécifique. Laquelle ?**

Je vois une voie vers une modération légère du développement de l'IA, compatible avec une vision réaliste de la géopolitique. Cette voie implique de ralentir la marche des autocraties vers une IA puissante pendant quelques années en leur refusant les ressources nécessaires pour la construire, à savoir les puces et les équipements de fabrication de semi-conducteurs. Cela donne en retour aux pays démocratiques une marge de manœuvre (buffer) qu'ils peuvent « dépenser » pour construire une IA puissante avec plus de soin, en accordant plus d'attention à ses risques, tout en procédant assez rapidement pour battre confortablement les autocraties. La course entre les entreprises d'IA au sein des démocraties peut ensuite être gérée sous l'égide d'un cadre juridique commun, via un mélange de normes industrielles et de réglementation.

Anthropic a soutenu très fermement cette voie, poussant pour des contrôles à l'exportation de puces et une réglementation judicieuse de l'IA, mais même ces propositions apparemment de bon sens ont été largement rejetées par les décideurs politiques aux États-Unis, qui est le pays où il est le plus important de les avoir. Il y a tellement d'argent à gagner avec l'IA, littéralement des milliers de milliards de dollars par an, que même les mesures les plus simples ont du mal à surmonter l'économie politique intrinsèque de l'IA. C'est le piège : l'IA est si puissante, un prix si étincelant, qu'il est très difficile pour la civilisation humaine de lui imposer la moindre contrainte.

**Et donc vous revenez à Sagan, au test que toute civilisation doit passer.**

Je peux imaginer, comme Sagan l'a fait dans Contact, cette même histoire se répétant sur des milliers de mondes. Une espèce acquiert la conscience, apprend à utiliser des outils, commence l'ascension exponentielle de la technologie, affronte les crises de l'industrialisation et des armes nucléaires, et si elle survit à celles-ci, fait face au défi le plus dur et ultime lorsqu'elle apprend à façonner le sable pour en faire des machines qui pensent. Que nous survivions à ce test et allions de l'avant pour construire la belle société décrite dans Machines of Loving Grace, ou que nous succombions à l'esclavage et à la destruction, dépendra de notre caractère et de notre détermination en tant qu'espèce, de notre esprit et de notre âme.

Malgré les nombreux obstacles, je crois que l'humanité a en elle la force de réussir ce test. Je suis encouragé par les milliers de chercheurs qui ont consacré leur carrière à nous aider à comprendre et à guider les modèles d'IA, à façonner le caractère et la constitution de ces modèles. Je pense qu'il y a maintenant de bonnes chances que ces efforts portent leurs fruits en temps utile. Je suis encouragé par le fait qu'au moins certaines entreprises aient déclaré qu'elles paieraient des coûts commerciaux importants pour empêcher leurs modèles de contribuer à la menace du bioterrorisme. Je suis encouragé par le fait que des personnes courageuses aient résisté aux vents politiques dominants et aient adopté une législation qui pose les premiers jalons de garde-fous sensés sur les systèmes d'IA. Je suis encouragé par le fait que le public comprenne que l'IA comporte des risques et veuille que ces risques soient traités. Je suis encouragé par l'esprit indomptable de liberté dans le monde et par la détermination à résister à la tyrannie partout où elle se produit.

**Mais un réveil collectif est nécessaire.**

Nous devons intensifier nos efforts si nous voulons réussir. La première étape consiste pour ceux qui sont les plus proches de la technologie à dire simplement la vérité sur la situation dans laquelle se trouve l'humanité, ce que j'ai toujours essayé de faire. Je le fais plus explicitement et avec une plus grande urgence avec cet essai. L'étape suivante consistera à convaincre les penseurs, les décideurs politiques, les entreprises et les citoyens du monde de l'imminence et de l'importance prioritaire de cette question, qui mérite que l'on y consacre de la réflexion et du capital politique par rapport aux milliers d'autres sujets qui dominent l'actualité chaque jour. Ensuite viendra le temps du courage, pour qu'un nombre suffisant de personnes aillent à contre-courant et défendent leurs principes, même face à des menaces pour leurs intérêts économiques et leur sécurité personnelle.

Les années qui nous attendent seront incroyablement difficiles, elles demanderont plus que ce que nous pensons pouvoir donner. Mais au cours de mon parcours de chercheur, de dirigeant et de citoyen, j'ai vu assez de courage et de noblesse pour croire que nous pouvons gagner, que lorsqu'elle est placée dans les circonstances les plus sombres, l'humanité a un moyen de rassembler, apparemment à la dernière minute, la force et la sagesse nécessaires pour prévaloir. Nous n'avons pas de temps à perdre.
