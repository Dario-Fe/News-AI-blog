---
tags: ["Ethics & Society", "Generative AI", "Copyright"]
date: 2026-02-18
author: "Dario Ferrero"
---

# When AI Draws for You. Designer, Not Author?
![fumetto1.jpg](fumetto1.jpg)

*Marco was fifty, with calloused hands and an ear honed by decades of work. He knew when a machine was running well by its sound, he could hear imperceptible tolerances, and he corrected defects before they became problems. Then came AURA, the robot with artificial intelligence, and it recorded his ear too. They replaced him.*

This is the story of the comic I created in less than half an hour using only two free tools (for now): DeepSeek for the script and NotebookLM for the drawings. Two simple, almost trivial prompts. For the first, I asked for "a short comic book story about a worker replaced by an AI-driven robot, five pages, emotional tone, themes of connection and choice." For the second, I gave it the script, asking it to convert it into a visual comic format.
![prompt.jpg](prompt.jpg)

The result surprised me. Not for its technical perfection, which is lacking, but for its narrative coherence. Marco watching the robot freeze in front of defective materials. Marco intervening with his hands, the ones the machine doesn't have. The bittersweet ending: "Human & AURA Process Development Supervisor." Like in Spike Jonze's *Her*, where intimacy with AI doesn't eliminate the human but redefines it, forcing us to question what remains irreducibly ours.

Two prompts. Half an hour. A complete comic. The question is not whether AI can create, but what it means to create when the machine executes and the human supervises.
![fumetto2.jpg](fumetto2.jpg)
![fumetto3.jpg](fumetto3.jpg)

## The Dark Side of Productivity

The numbers say one thing clearly: [generative AI increases artistic productivity by 25%](https://academic.oup.com/pnasnexus/article/3/3/pgae052/7618478) and the perceived value of works by 50%. This is revealed by a study published in *PNAS Nexus* that analyzed over four million works of art created by more than 50,000 users. But there is a disturbing detail: while productivity grows, "average originality" declines. The works become more similar to each other.

It is the paradox documented by [researchers from MIT and other universities](https://www.science.org/doi/10.1126/sciadv.adn5290): access to AI-generated ideas makes individual stories more creative, better written, and more enjoyable, especially for less experienced authors. But collectively, these stories converge. They resemble each other. As if AI provided not only tools but also increasingly narrow narrative tracks.

[Luciano Floridi](https://scholarlypublishingcollective.org/uip/apq/article/61/4/301/391691/Introduction-to-the-Special-IssuesThe-Ethics-of), a philosopher of information at Yale, had predicted it: AI poses "unprecedented" challenges to our understanding of authenticity, originality, and creativity. It's no longer about what machines can do, Floridi argues, but about what humans must choose to do with machines. It is a radical change of perspective: from ability to responsibility.

[Evan Selinger](https://www.rit.edu/news/philosophy-ethics-and-pursuit-responsible-artificial-intelligence), a philosopher of technology at the Rochester Institute of Technology, insists that "the ethics of AI go beyond technical solutions" and require humanistic skills to address nuanced principles, value conflicts, and power dynamics. These skills are needed not only for current problems but, says Selinger, "for anticipatory governance."

Productivity increases, therefore, but at what cost? Artists who excel at "ideation" and "human filtering" reap the greatest benefits from AI. Those who know how to imagine and then select with critical judgment. The others risk becoming prompt operators, executors of others' algorithmic visions.
![fumetto4.jpg](fumetto4.jpg)
![fumetto5.jpg](fumetto5.jpg)

## Who Distinguishes Human from Machine

Put a work of art in front of someone and ask them: human or artificial? [The average accuracy is 61.67%](https://www.jmis.org/archive/view_article?pid=jmis-11-3-201), according to a study published in the *Journal of Multimedia Information System*. A little better than a coin toss. 38.33% of people completely fail to distinguish them.

Scott Alexander, a blogger and rationalist, gave 11,000 people a similar test with fifty mixed images. [The median result? 60%](https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing). Barely above chance. Participants reported that the task was more difficult than expected. Alexander deliberately excluded obvious "tells": illegible text, deformed hands, complex poses that AI still can't handle. He wanted to test pure stylistic discrimination. And there, most humans falter.

Some studies show [even lower accuracies](https://arxiv.org/html/2509.11371v1/): in the "viva voce" Lovelace-style test, participants did no better than random choice (46%). Only when they could compare works in pairs did accuracy rise to 75%. It's as if our eye, in isolation, no longer knows what to look for. We need direct references, comparisons, to activate that critical sense that otherwise remains dormant.

The strategies people use to recognize AI are revealing. Some look for logical details: impossible objects, wrong proportions, nonsensical text. Others rely on aesthetics: a certain use of light, excessive smoothness, that "perfection" that seems to say "too good to be true." Still others scrutinize human traits: irregular brushstrokes, intentional imperfections. But [the strategy with the lowest success rate](https://www.jmis.org/archive/view_article?pid=jmis-11-3-201) is precisely the one based on human characteristics and material properties. AI has learned to simulate imperfection too.

In my comic, the lines are too clean, the shadows too uniform. An experienced comic artist would see it immediately. But for a general reader? It works. And that's the point: AI doesn't have to fool the experts, it has to cross the credibility threshold of the average audience. And it has already done so.
![fumetto6.jpg](fumetto6.jpg)

## The Bill That Doesn't Add Up

The economic impact of generative AI on creativity is a ticking time bomb. [A report from CISAC](https://www.theguardian.com/music/2024/dec/04/artificial-intelligence-music-industry-impact-income-loss) (the International Confederation of Societies of Authors and Composers) predicts a 24% loss in music revenues for human creators by 2028, and 21% in the audiovisual sector. AI will generate 64 billion euros, but it will transfer value from the hands of artists to the hands of tech companies, often using unlicensed works for model training.

Musicians and artists see AI as a threat. [61% consider it a danger to their work](https://aihub.org/2025/01/14/understanding-artists-perspectives-on-generative-ai-art-and-transparency-ownership-and-fairness/), although 44% also recognize its benefits. Composers demand "traceability" and "transparency" in AI tools to maintain creative control. Comic artists fear the erosion of personal style, of that "artistic identity" that took years to build and seconds to clone.

Then there's Grimes. The Canadian singer Claire Boucher [publicly offered](https://finance.yahoo.com/news/grimes-offers-50-royalties-ai-104130503.html) to split royalties 50/50 with anyone who uses her voice for a successful AI song. "Feel free to use my voice without penalty," she tweeted in 2023. "I like the idea of being fused with a machine and I like the idea of making all art open source and killing copyright." A radically opposite approach to that of Universal Music Group, which had the AI track with the fake voices of Drake and The Weeknd removed from platforms.

Grimes created [Elf.Tech](https://www.rocksoffmag.com/grimes-artificial-angels/), a platform where anyone can generate her voice in exchange for a 50% royalty and a "GrimesAI" credit. Is it transparency or surrender? Is it avant-garde or capitulation? It depends on who's looking. But one thing is certain: while Grimes embraces the man-machine fusion, thousands of artists without her symbolic capital are fighting legal battles against Stability AI, Midjourney, and others, accused of [copyright infringement](https://www.hollywoodreporter.com/business/business-news/artists-score-major-win-copyright-case-against-ai-art-generators-1235973601/) for using billions of images in training without permission.

The legal boundary is as blurred as the aesthetic one. In the United States, [the Copyright Office denies protection to purely AI art](https://www.fiverr.com/resources/guides/graphic-design/ai-art-ethics) for lack of "human authorship." But what about hybrids? If I write a detailed prompt, select from hundreds of outputs, modify and refine, is that work mine? Is it "human" enough?
![fumetto7.jpg](fumetto7.jpg)

## Designer, Not Author

I go back to my comic. Marco, AURA, the hands that know and the machine that learns. Did I create it? No, I didn't draw it. Did I think of it? Yes and no. I provided parameters, the LLM filled in the details. I chose the narrative direction, the algorithm built dialogues and scenes. Collaboration, some say. Delegation, others say.

But wait: I used free, generic tools with minimal prompts. Two lines of instructions. What if I had used professional software dedicated to comics, if I had studied character design, constrained the AI to precise color palettes, built a detailed storyboard panel by panel, dedicated days instead of half an hour? If I had put the AI on tracks decided entirely by me, with technical competence and a clear authorial vision, could I say with more certainty that I thought of it? Without that "yes and no"? I think so.

And what if on the cover I wrote "Designed by" instead of "Written by"? If I specified that the writing, the drawings, and even part of the plot were produced with AI tools under my architectural supervision, ethical choice, artistic taste, and moral responsibility? It would be transparent. It would be honest. But would it be enough?

It echoes the question posed by Walter Benjamin in his 1935 essay on the work of art in the age of mechanical reproduction. Benjamin spoke of the "aura" of the original, that unique quality that derives from the artist's physical presence, from the object's history, from its unrepeatability. AI produces works without an aura: infinitely reproducible, without history, without sweat. Technically perfect but, as some critics write, [emotionally empty](https://theconversation.com/ai-has-passed-the-aesthetic-turing-test-and-its-changing-our-relationship-with-art-262997).

And yet there is something profoundly human in choosing. In imagining Marco, in deciding that the ending should not be catastrophic but melancholic and hopeful. I delegated the execution, but I kept the vision. Is that enough to call myself an author? Or am I just a curator of algorithmic outputs?

The answer perhaps lies in what Floridi calls a "new ethical balance between human and artificial autonomy." AI is neither a miracle nor a plague, he writes. It is a tool that requires continuous human choices: what to automate, what to preserve, what to consider irreducibly ours. And here the paradox of productivity re-emerges: we can produce faster, but we risk producing more uniformly. Efficiency versus diversity. Speed versus uniqueness.

[My previous article on AI and music](https://aitalk.it/it/AI-Musica-Copyright.html) explored similar tensions in the world of sound, where copyright clashes with massive training datasets. [The one on content creation](https://aitalk.it/it/AI-Creazione-Contenuti.html) questioned the sustainability of economic models based on increasingly automated creativity. The questions return, amplified: if everyone can create decent content by pressing a button, what happens to the value of creation? If originality becomes statistical, what remains of art?

Perhaps the answer lies in the hybrid model that is emerging: artists who use AI as an assistant, not a substitute. Who maintain control over ideation and final curation, delegating repetitive or exploratory tasks. Like Marco, who doesn't go back to his old bench but becomes a supervisor of processes that integrate human and machine. Not a surrender, but a redefinition of a role.

Declaring "Designed by" instead of "Created by" would be a step towards that transparency that Selinger and other philosophers of technology are calling for. Not hiding the AI, but not denying the human contribution either. Recognizing that there was thought, choice, ethical and legal responsibility on my part, even if the execution was delegated. Just as a film director does not shoot every single shot but signs the film, or an architect does not lay every brick but signs the building.

The difference, perhaps, is that the director coordinates humans and the architect supervises bricklayers. I coordinated algorithms. Is it the same thing? I don't know. But I know that Marco, at the end of the story, chooses. He chooses to adapt the defective piece with his hands, he chooses to live with AURA instead of fighting it. And that choice, however suggested by an LLM, I wanted. I thought it, curated it, approved it. Is it mine? Maybe not all of it. But a piece of it is, the piece that matters. The piece that decides what.
