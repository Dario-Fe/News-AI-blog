<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notizie IA</title>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            background-color: #f0f2f5;
            color: #1c1e21;
        }
        header {
            background-color: #ffffff;
            padding: 20px;
            text-align: center;
            border-bottom: 1px solid #dddfe2;
            position: relative;
        }
        #language-selector-container {
            position: absolute;
            top: 20px;
            right: 20px;
        }
        #language-selector {
            padding: 8px;
            border-radius: 6px;
            border: 1px solid #dddfe2;
            background-color: #f0f2f5;
            font-size: 1em;
        }

        @media (max-width: 768px) {
            #language-selector-container {
                position: static;
                margin-bottom: 15px;
            }
        }
        header h1 {
            margin: 0;
            font-size: 2.5em;
            color: #000;
        }
        header h2 {
            margin: 5px 0 0;
            font-size: 1.2em;
            font-weight: normal;
            color: #606770;
        }
        main {
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
        }
        #articles-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 20px;
        }
        .article-card {
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            overflow: hidden;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            text-decoration: none;
            color: inherit;
        }
        .article-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        .article-card img {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }
        .article-card-content {
            padding: 15px;
        }
        .article-card-content h3 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .article-card-content p {
            margin: 0;
            font-size: 0.9em;
            color: #606770;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }
        #article-view {
            background-color: #ffffff;
            padding: 20px 40px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #article-view img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
        }
        #article-view h1 {
            font-size: 2.2em;
        }
        #article-view p {
            line-height: 1.6;
        }
        .back-button {
            display: inline-block;
            margin-bottom: 20px;
            padding: 10px 15px;
            background-color: #1877f2;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: bold;
        }
        .footer-back-button {
            margin-top: 30px;
            text-align: center;
        }
        footer {
            text-align: center;
            padding: 20px;
            margin-top: 40px;
            background-color: #ffffff;
            border-top: 1px solid #dddfe2;
            color: #606770;
        }
        footer p {
            margin: 5px 0;
        }
        footer a {
            color: #1877f2;
            text-decoration: none;
        }
        footer a:hover {
            text-decoration: underline;
        }
        .subscribe-link {
            font-size: 0.8em;
            font-weight: bold;
            text-decoration: none;
            color: #1877f2;
            background-color: #e7f3ff;
            padding: 8px 12px;
            border-radius: 6px;
            transition: background-color 0.3s;
        }
        .subscribe-link:hover {
            background-color: #dcebff;
            text-decoration: none;
        }
        .pagination-controls {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
        }
        .pagination-controls a {
            background-color: #ffffff;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            color: #1c1e21;
            font-weight: bold;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: all 0.2s;
        }
        .pagination-controls a:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.15);
            text-decoration: none;
        }
    </style>
</head>
<body>
    <header>
        <div id="language-selector-container" style="display: flex; gap: 10px; font-size: 1.2em; align-items: center;">
            <a href="newsletter.html" class="subscribe-link">Suscr칤bete</a>
            <span class="separator" style="border-left: 1px solid #dddfe2; height: 20px;"></span>
            <a href="../it/index.html" title="Italiano">游쉻릖</a>
            <a href="../en/index.html" title="English">游섫릖</a>
            <a href="../es/index.html" title="Espa침ol">游쀯릖</a>
        </div>
        <a href="index.html"><img src="logo_vn_ia.png" alt="Notizie IA Logo" style="max-width: 100%; height: auto;"></a>
        <h2 id="subtitle">Noticias y an치lisis sobre Inteligencia Artificial</h2>
    </header>
    <main>

        <div id="article-view">
            <a href="index.html" class="back-button">Torna indietro</a>
            <h1>"Cuando el tama침o no importa": La revoluci칩n del modelo HRM</h1>
<p><em>por Dario Ferrero (VerbaniaNotizie.it)</em>
<img alt="hrm_le_dimensioni_non_contano.jpg" src="https://raw.githubusercontent.com/matteobaccan/CorsoAIBook/main/articoli/11 - AI La rivoluzione HRM /hrm_le_dimensioni_non_contano.jpg"/></p>
<p><em>La mayor revoluci칩n en inteligencia artificial de los 칰ltimos a침os no proviene de los laboratorios de OpenAI o Google, sino de una peque침a startup de Singapur llamada <a href="https://www.sapient.inc/">Sapient Intelligence</a>.</em></p>
<p>El protagonista de esta historia se llama <a href="https://github.com/sapientinc/HRM">Hierarchical Reasoning Model</a> (HRM), un agente de IA que est치 sacudiendo los cimientos de todo el sector con una promesa aparentemente imposible: razonar mejor que los gigantes de la IA utilizando una fracci칩n de sus recursos.</p>
<p>No se trata del habitual modelo de lenguaje ampliado hasta lo inveros칤mil, ni de otra variaci칩n sobre el tema de los transformadores. HRM est치 construido de forma diferente, inspirado directamente en el funcionamiento del cerebro humano, y los resultados que est치 obteniendo son, como m칤nimo, asombrosos. Este modelo de apenas 27 millones de par치metros, menos de una cuarta parte del primer GPT, est치 superando sistem치ticamente a modelos cuatro veces m치s grandes en tareas de razonamiento complejo. Por si fuera poco, se entrena con solo mil ejemplos por problema, mientras que sus adversarios requieren monta침as de datos y meses de procesamiento en los servidores m치s potentes del mundo.</p>
<p>Pero la verdadera magia de HRM no reside en su reducido tama침o ni en su eficiencia de entrenamiento. Su innovaci칩n radica en que no se limita a procesar informaci칩n como todos los dem치s: razona de verdad, emulando los procesos cognitivos humanos de formas que parec칤an ciencia ficci칩n hasta hace unos meses. Y los resultados hablan por s칤 solos: donde otros modelos fracasan por completo, HRM sobresale con una naturalidad que recuerda m치s a un cerebro pensante que a una m치quina calculadora.</p>
<h2>Cuando la cadena de pensamiento se rompe</h2>
<p>Para comprender la importancia de la revoluci칩n que trae consigo HRM, primero debemos entender c칩mo funcionan los modelos de inteligencia artificial actuales y por qu칠 sus limitaciones son cada vez m치s evidentes. ChatGPT, Claude, Gemini y todos sus hermanos mayores se basan en una t칠cnica llamada "Cadena de Pensamiento" o Chain of Thought, un enfoque que suena prometedor pero que esconde profundas fragilidades estructurales.</p>
<p>Imagina que tienes que resolver un problema matem치tico complejo escribiendo cada paso con un bol칤grafo indeleble, sin poder volver atr치s para comprobar o corregir lo que has escrito. As칤 es exactamente como funcionan los modelos actuales: se gu칤an a s칤 mismos paso a paso a trav칠s de un problema, casi "hablando consigo mismos" en voz alta, pero si cometen un solo peque침o error en esta cadena, toda la respuesta puede desmoronarse como un castillo de naipes.</p>
<p>Como explican los investigadores de Sapient Intelligence en su <a href="https://arxiv.org/abs/2506.21734">art칤culo cient칤fico</a>, "la cadena de pensamiento para el razonamiento es una muleta, no una soluci칩n satisfactoria. Se basa en descomposiciones fr치giles definidas por el hombre en las que un solo paso en falso o un desorden de los pasos puede hacer descarrilar por completo el proceso de razonamiento".</p>
<p>El problema es a칰n m치s profundo de lo que parece. Los modelos basados en transformadores, la arquitectura que domina la IA moderna, siempre realizan la misma cantidad de "pensamiento" independientemente de la dificultad de la pregunta. Es como si un detective tuviera que dedicar exactamente el mismo tiempo y los mismos recursos para resolver tanto un robo de bicicletas como un intrincado caso de asesinato. No pueden decir "Esto es dif칤cil, necesito m치s tiempo para pensar" y no pueden revisar su razonamiento una vez que han empezado a generar la respuesta.</p>
<p>Esta rigidez tiene enormes consecuencias pr치cticas. Los modelos actuales se ven obligados a traducir cada proceso de razonamiento en un lenguaje expl칤cito, produciendo respuestas largas, lentas y a menudo redundantes. Peor a칰n, esta dependencia del lenguaje los hace vulnerables a errores en cascada: si se equivocan en un paso intermedio, todo lo que sigue se ve comprometido, independientemente de lo correctas que puedan ser sus capacidades de razonamiento b치sicas.</p>
<h2>La arquitectura que imita al cerebro</h2>
<p>HRM abandona por completo este paradigma, adoptando un enfoque radicalmente diferente que sus creadores describen como "inspirado en el cerebro". No se trata de una met치fora superficial o de marketing: la arquitectura de HRM toma prestada directamente la estrategia de decisi칩n por capas del cerebro humano, aplic치ndola a la inteligencia artificial con resultados que est치n redefiniendo lo que es posible en el campo del aprendizaje autom치tico.</p>
<p>En el coraz칩n de HRM hay dos componentes que trabajan en t치ndem como un d칰o perfectamente coordinado. El primero es un planificador de alto nivel, que podr칤amos imaginar como el "cerebro estrat칠gico lento" que observa el panorama general, identifica el tipo de problema a resolver y traza un mapa general del enfoque a seguir. El segundo es un ejecutor de bajo nivel, el "procesador r치pido" que recibe las 칩rdenes del planificador y las ejecuta con precisi칩n y rapidez.</p>
<p>La analog칤a m치s acertada es la de un maestro de ajedrez que colabora con un asistente incre칤blemente eficiente. El maestro estudia el tablero, planifica la estrategia general y decide qu칠 movimiento hacer, mientras que el asistente ejecuta f칤sicamente el movimiento con precisi칩n milim칠trica. Pero aqu칤 la similitud se vuelve a칰n m치s interesante: los dos no se limitan a un 칰nico intercambio de informaci칩n, sino que mantienen un di치logo continuo durante toda la duraci칩n del problema.</p>
<p>Este es el coraz칩n de la innovaci칩n de HRM: el <a href="https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/">bucle de razonamiento jer치rquico</a>. El m칩dulo de alto nivel elabora un plan estrat칠gico y se lo pasa al m칩dulo de bajo nivel, que lo ejecuta y devuelve los resultados. En este punto, el m칩dulo de alto nivel analiza lo sucedido, actualiza su estrategia en funci칩n de los nuevos datos y proporciona al m칩dulo de bajo nivel un nuevo subproblema refinado en el que trabajar. Este "toma y daca" contin칰a en ciclos iterativos hasta que el modelo converge en la soluci칩n 칩ptima.</p>
<p>La belleza de este enfoque es que permite a HRM controlar y refinar internamente su propio razonamiento mientras a칰n est치 procesando el problema, una capacidad que la gran mayor칤a de los dem치s modelos simplemente no poseen. Es como si, mientras resuelves ese problema de matem치ticas con el bol칤grafo indeleble, alguien te permitiera de repente borrar, reescribir y repensar cada paso hasta que est칠s completamente seguro de la soluci칩n.</p>
<p>Pero hay m치s. La versi칩n m치s avanzada de HRM utiliza el aprendizaje por refuerzo para decidir de forma aut칩noma cu치ntas iteraciones son necesarias para cada tipo de tarea, lo que lo asemeja a칰n m치s al pensamiento flexible humano. Al igual que nosotros dedicamos m치s tiempo y energ칤a mental a los problemas complejos que a los sencillos, HRM aprende a modular sus ciclos de razonamiento en funci칩n de la dificultad intr칤nseca del problema al que se enfrenta.
<img alt="ragionamento_gerarchico_hrm.jpg" src="https://raw.githubusercontent.com/matteobaccan/CorsoAIBook/main/articoli/11 - AI La rivoluzione HRM /ragionamento_gerarchico_hrm.jpg"/>
<em><a href="https://sapient.inc/">Imagen extra칤da de Sapient.inc HRM</a></em></p>
<h2>David contra Goliat: los n칰meros que conmocionan</h2>
<p>Los resultados obtenidos por HRM en los benchmarks de razonamiento m치s dif칤ciles son el tipo de cifras que hacen arquear las cejas incluso a los expertos m치s esc칠pticos del sector. Estamos hablando de un modelo con apenas 27 millones de par치metros que no solo compite con gigantes de miles de millones de par치metros, sino que los supera sistem치ticamente en tareas que requieren un razonamiento profundo y abstracto.</p>
<p>En el <a href="https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning/">benchmark ARC-AGI</a>, considerado una de las pruebas m치s fiables para medir las capacidades de razonamiento abstracto y generalizaci칩n de la inteligencia artificial, HRM obtuvo una puntuaci칩n del 40,3%, superando a modelos mucho m치s grandes como o3-mini-high de OpenAI (34,5%) y Claude 3.7 Sonnet (21,2%). No se trata de peque침as diferencias estad칤sticamente insignificantes: estamos hablando de brechas de rendimiento sustanciales que, en el mundo de la IA, equivalen a saltos generacionales.</p>
<p>Pero es en las tareas de razonamiento m치s extremas donde HRM demuestra realmente su superioridad arquitect칩nica. En las pruebas de Sudoku de nivel extremo y en los laberintos complejos, las diferencias se vuelven abismales. HRM resolvi칩 el 55% de los Sudokus m치s dif칤ciles, mientras que los modelos basados en la cadena de pensamiento obtuvieron un rotundo 0%. El mismo resultado para los laberintos de cuadr칤cula de 30x30: HRM encontr칩 el camino 칩ptimo en el 74,5% de los casos, mientras que sus competidores se quedaron en el punto de partida con un 0%.</p>
<p>Es la versi칩n IA del adagio de Yoda: "El tama침o no importa. M칤rame. 쯄e juzgas por mi tama침o?". Solo que en este caso, la Fuerza es la arquitectura jer치rquica y Luke Skywalker son los modelos de miles de millones de par치metros que siguen estrell치ndose en el pantano.</p>
<p>No son solo n칰meros en una tabla: representan la diferencia entre una inteligencia artificial que puede enfrentarse a problemas complejos del mundo real y una que se atasca ante desaf칤os que requieren m치s que un razonamiento superficial. Es la diferencia entre un asistente que puede ayudarte a navegar por decisiones complejas y uno que, como mucho, puede ayudarte a escribir correos electr칩nicos m치s elocuentes.</p>
<p>Pero quiz치s el dato m치s impresionante de todos se refiere a la eficiencia del entrenamiento. Mientras que los modelos de lenguaje tradicionales requieren enormes conjuntos de datos extra칤dos de todo Internet y meses de procesamiento en los superordenadores m치s potentes del mundo, HRM se entrena con solo mil ejemplos por tarea. Como declar칩 Guan Wang, uno de los fundadores de Sapient Intelligence, "podr칤as entrenarlo en Sudoku a nivel profesional en dos horas de GPU", una eficiencia que define literalmente como "rid칤cula" en el mejor sentido de la palabra.
<img alt="benchmark_hrm.jpg" src="https://raw.githubusercontent.com/matteobaccan/CorsoAIBook/main/articoli/11 - AI La rivoluzione HRM /benchmark_hrm.jpg"/>
<em><a href="https://sapient.inc/">Imagen extra칤da de Sapient.inc HRM</a></em></p>
<h2>M치s all치 de los benchmarks: una revoluci칩n estructural</h2>
<p>Los impresionantes resultados en las pruebas estandarizadas son solo la punta del iceberg. La verdadera revoluci칩n que aporta HRM reside en su capacidad para resolver problemas estructurales fundamentales que afectan a toda la generaci칩n actual de modelos basados en transformadores, problemas que hasta hace poco parec칤an una parte inevitable del panorama de la inteligencia artificial.</p>
<p>El primero y m치s significativo de estos problemas es la eficiencia de la memoria. Los transformadores tradicionales son notoriamente 치vidos de recursos, ya que requieren enormes cantidades de memoria para funcionar y a칰n m치s para ser entrenados. HRM, en cambio, utiliza actualizaciones de gradiente m치s locales, que son m치s f치ciles de calcular y "mucho m치s plausibles biol칩gicamente", evitando la famosa "retropropagaci칩n profunda en el tiempo" que es intensiva en memoria y computacionalmente lenta.</p>
<p>Esta eficiencia de memoria no es una simple mejora incremental: es un cambio de paradigma que abre escenarios completamente nuevos. Menos memoria significa poder ejecutar m치s modelos simult치neamente en el mismo hardware, entrenar m치s r치pido con menos recursos y, sobre todo, llevar la inteligencia artificial avanzada a dispositivos que hasta ayer eran impensables. Estamos hablando de ordenadores port치tiles comunes, dispositivos de borde, robots e incluso coches, todos lugares donde la IA podr칤a operar de forma aut칩noma sin depender de conexiones a Internet constantes o servidores remotos.</p>
<p>La empresa Sapient ya est치 probando HRM en aplicaciones del mundo real que demuestran esta versatilidad. En el sector sanitario, el modelo se utiliza para ayudar en el diagn칩stico de enfermedades rares, esas patolog칤as complejas que requieren exactamente el tipo de razonamiento profundo y matizado en el que HRM sobresale. En las previsiones clim치ticas estacionales, ha alcanzado tasas de precisi칩n del 97%, un resultado que en el mundo de la meteorolog칤a equivale casi a la ciencia ficci칩n.</p>
<p>Pero quiz치s el aspecto m치s alentador de HRM es el equipo que hay detr치s. No se trata de investigadores desconocidos que trabajan en garajes: el grupo incluye a ex ingenieros de DeepMind, Anthropic, DeepSeek e incluso del grupo XAI de Elon Musk. Son personas que han trabajado en la vanguardia de la inteligencia artificial durante a침os y que ahora apuestan todo por el dise침o inspirado en el cerebro de HRM. Cuando profesionales de este calibre abandonan las certezas de los grandes gigantes tecnol칩gicos para perseguir una visi칩n alternativa, merece la pena prestar atenci칩n.</p>
<p>Guan Wang, el CEO y fundador de Sapient Intelligence, no se anda con rodeos cuando habla del futuro de la inteligencia artificial. Su visi칩n es que la AGI, la inteligencia artificial general, consiste en dar a las m치quinas una inteligencia a nivel humano y superior. Y seg칰n Wang, la cadena de pensamiento es solo un "atajo", mientras que lo que han construido "puede pensar" en el verdadero sentido de la palabra.</p>
<h2>C칩digo abierto y transparencia: un regalo a la comunidad</h2>
<p>En una 칠poca en la que los grandes laboratorios de IA tienden a mantener secretos comerciales cada vez m치s estrictos sobre sus modelos m치s avanzados, la decisi칩n de Sapient Intelligence de hacer que HRM sea completamente de c칩digo abierto representa un gesto de transparencia casi revolucionario. Todo el proyecto est치 <a href="https://github.com/sapientinc/HRM">disponible en GitHub</a>, lo que permite a cualquiera en el mundo verificarlo, entrenar su propia versi칩n, modificarlo o construir sobre 칠l. Este nivel de apertura es raro para una innovaci칩n tan prometedora y estrat칠gicamente importante.</p>
<p>Por supuesto, HRM todav칤a tiene limitaciones que sus creadores reconocen abiertamente. Por ahora, el modelo tiene un enfoque m치s restringido que los grandes modelos de lenguaje generalistas: est치 construido para razonar, no para charlar amigablemente o escribir poes칤a rom치ntica. Pero es precisamente esta especializaci칩n lo que lo hace tan potente en su dominio. Es una de las pruebas de concepto m치s s칩lidas que el sector ha visto para demostrar que el futuro de la IA podr칤a no residir en modelos cada vez m치s grandes y generalistas, sino en arquitecturas m치s inteligentes y especializadas.</p>
<p>HRM no es el 칰nico experimento de este tipo en curso. El panorama de la investigaci칩n en IA est치 viviendo un momento de efervescencia creativa, con equipos de todo el mundo que exploran arquitecturas alternativas a los transformadores dominantes. Est치 Sakana con sus m치quinas de pensamiento continuo, los modelos LLM de 1 bit que prometen una eficiencia extrema y los modelos de razonamiento basados en la difusi칩n de Google. Pero hay una diferencia crucial: HRM "ya est치 funcionando" y superando a modelos mucho m치s grandes con una fracci칩n de los datos de entrenamiento y sin necesidad de un preentrenamiento masivo.</p>
<p>Esto sugiere que estamos asistiendo a un cambio de paradigma fundamental. El pr칩ximo gran salto en la inteligencia artificial probablemente no ser치 otro "clon de GPT escalado" a dimensiones a칰n m치s mastod칩nticas, sino algo similar a HRM: una nueva arquitectura que aporta un mejor razonamiento, un entrenamiento m치s r치pido y una implementaci칩n m치s econ칩mica, todo ello sin la necesidad de centros de datos llenos de GPU que consumen la electricidad de ciudades enteras.</p>
<h2>El futuro que realmente piensa</h2>
<p>De cara al futuro, la visi칩n que se desprende del trabajo de HRM es la de un futuro en el que la inteligencia artificial ya no estar치 confinada en los centros de datos de las grandes corporaciones tecnol칩gicas, sino que se convertir치 en una presencia omnipresente y accesible en nuestra vida cotidiana. Imagina agentes de IA que viven en nuestros ordenadores port치tiles, en los robots dom칠sticos, en los coches, incluso en los dispositivos port치tiles, todos capaces de un razonamiento sofisticado sin depender de conexiones a Internet constantes o de costosos servidores remotos.</p>
<p>Esta democratizaci칩n de la inteligencia artificial avanzada podr칤a tener profundas implicaciones en la forma en que trabajamos, aprendemos y resolvemos problemas. Un m칠dico en una cl칤nica rural podr칤a tener acceso a las mismas herramientas de diagn칩stico avanzado que un hospital metropolitano. Un ingeniero que trabaja en una obra de construcci칩n remota podr칤a obtener an치lisis estructurales complejos en tiempo real. Un investigador en un laboratorio con un presupuesto limitado podr칤a explorar hip칩tesis cient칤ficas complejas sin tener que competir por el acceso a los superordenadores.</p>
<p>Pero quiz치s el aspecto m치s fascinante de todos es la idea de que estos agentes de IA ya no se limitar치n a "hablar" con Internet o a regurgitar informaci칩n procesada en otros lugares. Empezar치n a "pensar de verdad", en el sentido m치s profundo del t칠rmino, desarrollando soluciones originales, formulando hip칩tesis creativas y quiz치s incluso desarrollando intuiciones que los humanos nunca habr칤amos considerado.</p>
<p>Como toda revoluci칩n tecnol칩gica, esta transformaci칩n traer치 consigo nuevos desaf칤os y cuestiones 칠ticas que deberemos afrontar. Pero si HRM y arquitecturas similares cumplen sus promesas, podr칤amos estar a las puertas de una era en la que la inteligencia artificial se convierta por fin en lo que su nombre promete: no solo un sofisticado sistema de procesamiento de informaci칩n, sino un verdadero socio intelectual capaz de un razonamiento aut칩nomo y creativo.</p>
<p>Como dir칤a Tony Stark, a veces la mejor soluci칩n no es construir una armadura m치s grande, sino construirla m치s inteligente. Y HRM podr칤a haber encontrado la manera de reemplazar la fuerza bruta computacional con algo mucho m치s elegante y eficiente.</p>
<p>El camino a칰n es largo y est치 lleno de inc칩gnitas, pero una cosa es cierta: el peque침o modelo de 27 millones de par치metros creado en una startup de Singapur ya ha demostrado que en el mundo de la inteligencia artificial, como suele ocurrir en la ciencia, la calidad puede realmente superar a la cantidad. Y quiz치s, al igual que en las mejores historias de David contra Goliat, es precisamente el m치s peque침o el que nos muestra el camino hacia el futuro.</p>

            <div class="footer-back-button">
                <a href="index.html" class="back-button">Torna indietro</a>
            </div>
        </div>

        <div class="pagination-controls">

        </div>
    </main>
    <footer>
        <p>A cargo de <a href="https://www.verbanianotizie.it/" target="_blank" rel="noopener noreferrer">Verbania Notizie</a></p>
        <p>
            <a href="mailto:info@verbanianotizie.it">Contacto</a> |
            <a href="#">Cookie</a> |
            <a href="#">Privacy Policy</a>
        </p>
    </footer>
</body>
</html>
